{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":33102,"databundleVersionId":3168850,"sourceType":"competition"}],"dockerImageVersionId":30527,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# ''\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-04T10:50:05.520260Z","iopub.execute_input":"2024-06-04T10:50:05.520547Z","iopub.status.idle":"2024-06-04T10:50:05.534288Z","shell.execute_reply.started":"2024-06-04T10:50:05.520522Z","shell.execute_reply":"2024-06-04T10:50:05.533315Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/tabular-playground-series-feb-2022/sample_submission.csv\n/kaggle/input/tabular-playground-series-feb-2022/train.csv\n/kaggle/input/tabular-playground-series-feb-2022/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\n\nif torch.cuda.is_available():\n    print('GPU is available.')\nelse:\n    print('GPU is not available.')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T10:50:16.101299Z","iopub.execute_input":"2024-06-04T10:50:16.102211Z","iopub.status.idle":"2024-06-04T10:50:19.843081Z","shell.execute_reply.started":"2024-06-04T10:50:16.102176Z","shell.execute_reply":"2024-06-04T10:50:19.842057Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"GPU is available.\n","output_type":"stream"}]},{"cell_type":"code","source":"# import cupy as cp","metadata":{"execution":{"iopub.status.busy":"2024-05-19T17:32:30.460304Z","iopub.execute_input":"2024-05-19T17:32:30.460669Z","iopub.status.idle":"2024-05-19T17:32:30.464784Z","shell.execute_reply.started":"2024-05-19T17:32:30.460638Z","shell.execute_reply":"2024-05-19T17:32:30.463841Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import torch\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T10:50:21.550567Z","iopub.execute_input":"2024-06-04T10:50:21.551139Z","iopub.status.idle":"2024-06-04T10:50:21.556107Z","shell.execute_reply.started":"2024-06-04T10:50:21.551109Z","shell.execute_reply":"2024-06-04T10:50:21.555099Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/tabular-playground-series-feb-2022/train.csv')\ntrain.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T10:50:24.492902Z","iopub.execute_input":"2024-06-04T10:50:24.493267Z","iopub.status.idle":"2024-06-04T10:50:51.400063Z","shell.execute_reply.started":"2024-06-04T10:50:24.493238Z","shell.execute_reply":"2024-06-04T10:50:51.398868Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   row_id     A0T0G0C10  A0T0G1C9  A0T0G2C8  A0T0G3C7  A0T0G4C6  A0T0G5C5  \\\n0       0 -9.536743e-07 -0.000010 -0.000043 -0.000114 -0.000200 -0.000240   \n1       1 -9.536743e-07 -0.000010 -0.000043  0.000886 -0.000200  0.000760   \n2       2 -9.536743e-07 -0.000002  0.000007  0.000129  0.000268  0.000270   \n3       3  4.632568e-08 -0.000006  0.000012  0.000245  0.000492  0.000522   \n4       4 -9.536743e-07 -0.000010 -0.000043 -0.000114 -0.000200 -0.000240   \n\n   A0T0G6C4  A0T0G7C3  A0T0G8C2  ...  A8T0G1C1  A8T0G2C0  A8T1G0C1  A8T1G1C0  \\\n0 -0.000200 -0.000114 -0.000043  ... -0.000086 -0.000043 -0.000086 -0.000086   \n1 -0.000200 -0.000114 -0.000043  ... -0.000086 -0.000043  0.000914  0.000914   \n2  0.000243  0.000125  0.000001  ...  0.000084  0.000048  0.000081  0.000106   \n3  0.000396  0.000197 -0.000003  ...  0.000151  0.000100  0.000180  0.000202   \n4 -0.000200 -0.000114 -0.000043  ... -0.000086 -0.000043 -0.000086 -0.000086   \n\n   A8T2G0C0  A9T0G0C1  A9T0G1C0  A9T1G0C0     A10T0G0C0  \\\n0 -0.000043 -0.000010 -0.000010 -0.000010 -9.536743e-07   \n1 -0.000043 -0.000010 -0.000010 -0.000010 -9.536743e-07   \n2  0.000072  0.000010  0.000008  0.000019  1.046326e-06   \n3  0.000153  0.000021  0.000015  0.000046 -9.536743e-07   \n4 -0.000043 -0.000010 -0.000010 -0.000010 -9.536743e-07   \n\n                   target  \n0  Streptococcus_pyogenes  \n1     Salmonella_enterica  \n2     Salmonella_enterica  \n3     Salmonella_enterica  \n4      Enterococcus_hirae  \n\n[5 rows x 288 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>A0T0G0C10</th>\n      <th>A0T0G1C9</th>\n      <th>A0T0G2C8</th>\n      <th>A0T0G3C7</th>\n      <th>A0T0G4C6</th>\n      <th>A0T0G5C5</th>\n      <th>A0T0G6C4</th>\n      <th>A0T0G7C3</th>\n      <th>A0T0G8C2</th>\n      <th>...</th>\n      <th>A8T0G1C1</th>\n      <th>A8T0G2C0</th>\n      <th>A8T1G0C1</th>\n      <th>A8T1G1C0</th>\n      <th>A8T2G0C0</th>\n      <th>A9T0G0C1</th>\n      <th>A9T0G1C0</th>\n      <th>A9T1G0C0</th>\n      <th>A10T0G0C0</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>-9.536743e-07</td>\n      <td>-0.000010</td>\n      <td>-0.000043</td>\n      <td>-0.000114</td>\n      <td>-0.000200</td>\n      <td>-0.000240</td>\n      <td>-0.000200</td>\n      <td>-0.000114</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-0.000010</td>\n      <td>-0.000010</td>\n      <td>-0.000010</td>\n      <td>-9.536743e-07</td>\n      <td>Streptococcus_pyogenes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>-9.536743e-07</td>\n      <td>-0.000010</td>\n      <td>-0.000043</td>\n      <td>0.000886</td>\n      <td>-0.000200</td>\n      <td>0.000760</td>\n      <td>-0.000200</td>\n      <td>-0.000114</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>0.000914</td>\n      <td>0.000914</td>\n      <td>-0.000043</td>\n      <td>-0.000010</td>\n      <td>-0.000010</td>\n      <td>-0.000010</td>\n      <td>-9.536743e-07</td>\n      <td>Salmonella_enterica</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>-9.536743e-07</td>\n      <td>-0.000002</td>\n      <td>0.000007</td>\n      <td>0.000129</td>\n      <td>0.000268</td>\n      <td>0.000270</td>\n      <td>0.000243</td>\n      <td>0.000125</td>\n      <td>0.000001</td>\n      <td>...</td>\n      <td>0.000084</td>\n      <td>0.000048</td>\n      <td>0.000081</td>\n      <td>0.000106</td>\n      <td>0.000072</td>\n      <td>0.000010</td>\n      <td>0.000008</td>\n      <td>0.000019</td>\n      <td>1.046326e-06</td>\n      <td>Salmonella_enterica</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>4.632568e-08</td>\n      <td>-0.000006</td>\n      <td>0.000012</td>\n      <td>0.000245</td>\n      <td>0.000492</td>\n      <td>0.000522</td>\n      <td>0.000396</td>\n      <td>0.000197</td>\n      <td>-0.000003</td>\n      <td>...</td>\n      <td>0.000151</td>\n      <td>0.000100</td>\n      <td>0.000180</td>\n      <td>0.000202</td>\n      <td>0.000153</td>\n      <td>0.000021</td>\n      <td>0.000015</td>\n      <td>0.000046</td>\n      <td>-9.536743e-07</td>\n      <td>Salmonella_enterica</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>-9.536743e-07</td>\n      <td>-0.000010</td>\n      <td>-0.000043</td>\n      <td>-0.000114</td>\n      <td>-0.000200</td>\n      <td>-0.000240</td>\n      <td>-0.000200</td>\n      <td>-0.000114</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-0.000010</td>\n      <td>-0.000010</td>\n      <td>-0.000010</td>\n      <td>-9.536743e-07</td>\n      <td>Enterococcus_hirae</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 288 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(train)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T10:51:08.468318Z","iopub.execute_input":"2024-06-04T10:51:08.468846Z","iopub.status.idle":"2024-06-04T10:51:08.505034Z","shell.execute_reply.started":"2024-06-04T10:51:08.468807Z","shell.execute_reply":"2024-06-04T10:51:08.504149Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"        row_id     A0T0G0C10      A0T0G1C9  A0T0G2C8  A0T0G3C7  A0T0G4C6  \\\n0            0 -9.536743e-07 -9.536743e-06 -0.000043 -0.000114 -0.000200   \n1            1 -9.536743e-07 -9.536743e-06 -0.000043  0.000886 -0.000200   \n2            2 -9.536743e-07 -1.536743e-06  0.000007  0.000129  0.000268   \n3            3  4.632568e-08 -5.536743e-06  0.000012  0.000245  0.000492   \n4            4 -9.536743e-07 -9.536743e-06 -0.000043 -0.000114 -0.000200   \n...        ...           ...           ...       ...       ...       ...   \n199995  199995 -9.536743e-07  4.632568e-07 -0.000003  0.000176  0.000350   \n199996  199996 -9.536743e-07 -9.536743e-06 -0.000043 -0.000114 -0.000200   \n199997  199997  4.632568e-08  1.463257e-06 -0.000005 -0.000031 -0.000019   \n199998  199998 -9.536743e-07 -9.536743e-06 -0.000043 -0.000114 -0.000200   \n199999  199999  1.046326e-06 -1.536743e-06  0.000069  0.000539  0.001329   \n\n        A0T0G5C5  A0T0G6C4  A0T0G7C3  A0T0G8C2  ...  A8T0G1C1  A8T0G2C0  \\\n0      -0.000240 -0.000200 -0.000114 -0.000043  ... -0.000086 -0.000043   \n1       0.000760 -0.000200 -0.000114 -0.000043  ... -0.000086 -0.000043   \n2       0.000270  0.000243  0.000125  0.000001  ...  0.000084  0.000048   \n3       0.000522  0.000396  0.000197 -0.000003  ...  0.000151  0.000100   \n4      -0.000240 -0.000200 -0.000114 -0.000043  ... -0.000086 -0.000043   \n...          ...       ...       ...       ...  ...       ...       ...   \n199995  0.000290  0.000200  0.000206 -0.000023  ...  0.000124  0.000057   \n199996 -0.000240 -0.000200 -0.000114 -0.000043  ... -0.000086 -0.000043   \n199997 -0.000037 -0.000037 -0.000015 -0.000005  ...  0.000115  0.000131   \n199998 -0.000240 -0.000200 -0.000114 -0.000043  ... -0.000086 -0.000043   \n199999  0.001657  0.001328  0.000520  0.000063  ...  0.000065  0.000053   \n\n        A8T1G0C1  A8T1G1C0  A8T2G0C0      A9T0G0C1  A9T0G1C0  A9T1G0C0  \\\n0      -0.000086 -0.000086 -0.000043 -9.536743e-06 -0.000010 -0.000010   \n1       0.000914  0.000914 -0.000043 -9.536743e-06 -0.000010 -0.000010   \n2       0.000081  0.000106  0.000072  1.046326e-05  0.000008  0.000019   \n3       0.000180  0.000202  0.000153  2.146326e-05  0.000015  0.000046   \n4      -0.000086 -0.000086 -0.000043 -9.536743e-06 -0.000010 -0.000010   \n...          ...       ...       ...           ...       ...       ...   \n199995  0.000104  0.000144  0.000027  4.632568e-07  0.000060  0.000020   \n199996  0.000914  0.000914 -0.000043 -9.536743e-06 -0.000010 -0.000010   \n199997  0.000110  0.000213  0.000094  1.646326e-05  0.000035  0.000021   \n199998  0.001914 -0.000086 -0.000043 -9.536743e-06 -0.000010 -0.000010   \n199999  0.000082  0.000102  0.000078  1.446326e-05  0.000013  0.000033   \n\n           A10T0G0C0                    target  \n0      -9.536743e-07    Streptococcus_pyogenes  \n1      -9.536743e-07       Salmonella_enterica  \n2       1.046326e-06       Salmonella_enterica  \n3      -9.536743e-07       Salmonella_enterica  \n4      -9.536743e-07        Enterococcus_hirae  \n...              ...                       ...  \n199995 -9.536743e-07       Salmonella_enterica  \n199996 -9.536743e-07    Streptococcus_pyogenes  \n199997  4.632568e-08  Streptococcus_pneumoniae  \n199998 -9.536743e-07     Staphylococcus_aureus  \n199999 -9.536743e-07     Klebsiella_pneumoniae  \n\n[200000 rows x 288 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"train.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-04T10:51:12.568143Z","iopub.execute_input":"2024-06-04T10:51:12.568564Z","iopub.status.idle":"2024-06-04T10:51:12.575207Z","shell.execute_reply.started":"2024-06-04T10:51:12.568531Z","shell.execute_reply":"2024-06-04T10:51:12.574199Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(200000, 288)"},"metadata":{}}]},{"cell_type":"code","source":"print('Train Shape: {}\\nMissing Data: {}\\nDuplicates: {}\\n'\\\n      .format(train.shape, train.isna().sum().sum(), train.duplicated().sum()))","metadata":{"execution":{"iopub.status.busy":"2024-06-04T10:51:15.668175Z","iopub.execute_input":"2024-06-04T10:51:15.668582Z","iopub.status.idle":"2024-06-04T10:51:17.737622Z","shell.execute_reply.started":"2024-06-04T10:51:15.668539Z","shell.execute_reply":"2024-06-04T10:51:17.736590Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Train Shape: (200000, 288)\nMissing Data: 0\nDuplicates: 0\n\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train.columns)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T10:51:20.078242Z","iopub.execute_input":"2024-06-04T10:51:20.079165Z","iopub.status.idle":"2024-06-04T10:51:20.084430Z","shell.execute_reply.started":"2024-06-04T10:51:20.079130Z","shell.execute_reply":"2024-06-04T10:51:20.083322Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Index(['row_id', 'A0T0G0C10', 'A0T0G1C9', 'A0T0G2C8', 'A0T0G3C7', 'A0T0G4C6',\n       'A0T0G5C5', 'A0T0G6C4', 'A0T0G7C3', 'A0T0G8C2',\n       ...\n       'A8T0G1C1', 'A8T0G2C0', 'A8T1G0C1', 'A8T1G1C0', 'A8T2G0C0', 'A9T0G0C1',\n       'A9T0G1C0', 'A9T1G0C0', 'A10T0G0C0', 'target'],\n      dtype='object', length=288)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train.target)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T10:51:22.980035Z","iopub.execute_input":"2024-06-04T10:51:22.981049Z","iopub.status.idle":"2024-06-04T10:51:22.988347Z","shell.execute_reply.started":"2024-06-04T10:51:22.981002Z","shell.execute_reply":"2024-06-04T10:51:22.987290Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"0           Streptococcus_pyogenes\n1              Salmonella_enterica\n2              Salmonella_enterica\n3              Salmonella_enterica\n4               Enterococcus_hirae\n                    ...           \n199995         Salmonella_enterica\n199996      Streptococcus_pyogenes\n199997    Streptococcus_pneumoniae\n199998       Staphylococcus_aureus\n199999       Klebsiella_pneumoniae\nName: target, Length: 200000, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"# Extract the target column (assuming the column is named 'target' in this example)\ntarget_column = train['target']","metadata":{"execution":{"iopub.status.busy":"2024-06-04T10:51:26.068651Z","iopub.execute_input":"2024-06-04T10:51:26.069052Z","iopub.status.idle":"2024-06-04T10:51:26.074021Z","shell.execute_reply.started":"2024-06-04T10:51:26.069025Z","shell.execute_reply":"2024-06-04T10:51:26.072973Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"target_column_numpy = np.array(target_column)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T10:51:28.468161Z","iopub.execute_input":"2024-06-04T10:51:28.468900Z","iopub.status.idle":"2024-06-04T10:51:28.474296Z","shell.execute_reply.started":"2024-06-04T10:51:28.468866Z","shell.execute_reply":"2024-06-04T10:51:28.473282Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Dropping the target column\ntrain=train.drop(columns=['target']) ","metadata":{"execution":{"iopub.status.busy":"2024-06-04T10:51:31.217765Z","iopub.execute_input":"2024-06-04T10:51:31.218475Z","iopub.status.idle":"2024-06-04T10:51:31.356688Z","shell.execute_reply.started":"2024-06-04T10:51:31.218445Z","shell.execute_reply":"2024-06-04T10:51:31.355539Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\n# Example data (replace this with your actual data)\ntrain = np.array(train)\n\n# Function to perform Min-Max scaling\ndef min_max_scaling(train):\n    # Create MinMaxScaler object\n    scaler = MinMaxScaler()\n    \n    # Fit the scaler to the data and transform the data\n    scaled_data = scaler.fit_transform(train)\n    \n    # Get the minimum and maximum values for each feature\n    min_vals = scaler.data_min_\n    max_vals = scaler.data_max_\n    \n    return scaled_data, min_vals, max_vals\n\n# Apply Min-Max scaling\nscaled_data, min_vals, max_vals = min_max_scaling(train)\n\n# Print the scaled data, minimum, and maximum values for each feature\nprint(\"\\nScaled Data (Min-Max scaled between 0 and 1):\\n\", scaled_data)\n# print(\"\\nMin Values for each feature:\\n\", min_vals)\n# print(\"\\nMax Values for each feature:\\n\", max_vals)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T10:51:34.827766Z","iopub.execute_input":"2024-06-04T10:51:34.828134Z","iopub.status.idle":"2024-06-04T10:51:35.962242Z","shell.execute_reply.started":"2024-06-04T10:51:34.828103Z","shell.execute_reply":"2024-06-04T10:51:35.961098Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"\nScaled Data (Min-Max scaled between 0 and 1):\n [[0.000000e+00 0.000000e+00 0.000000e+00 ... 0.000000e+00 0.000000e+00\n  0.000000e+00]\n [5.000025e-06 0.000000e+00 0.000000e+00 ... 0.000000e+00 0.000000e+00\n  0.000000e+00]\n [1.000005e-05 0.000000e+00 8.000000e-04 ... 1.800000e-03 1.450000e-03\n  2.000000e-03]\n ...\n [9.999900e-01 1.000000e-04 1.100000e-03 ... 4.500000e-03 1.550000e-03\n  1.000000e-03]\n [9.999950e-01 0.000000e+00 0.000000e+00 ... 0.000000e+00 0.000000e+00\n  0.000000e+00]\n [1.000000e+00 2.000000e-04 8.000000e-04 ... 2.300000e-03 2.150000e-03\n  0.000000e+00]]\n","output_type":"stream"}]},{"cell_type":"code","source":"scaled_data","metadata":{"execution":{"iopub.status.busy":"2024-06-04T10:51:40.007919Z","iopub.execute_input":"2024-06-04T10:51:40.008643Z","iopub.status.idle":"2024-06-04T10:51:40.016481Z","shell.execute_reply.started":"2024-06-04T10:51:40.008606Z","shell.execute_reply":"2024-06-04T10:51:40.015420Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"array([[0.000000e+00, 0.000000e+00, 0.000000e+00, ..., 0.000000e+00,\n        0.000000e+00, 0.000000e+00],\n       [5.000025e-06, 0.000000e+00, 0.000000e+00, ..., 0.000000e+00,\n        0.000000e+00, 0.000000e+00],\n       [1.000005e-05, 0.000000e+00, 8.000000e-04, ..., 1.800000e-03,\n        1.450000e-03, 2.000000e-03],\n       ...,\n       [9.999900e-01, 1.000000e-04, 1.100000e-03, ..., 4.500000e-03,\n        1.550000e-03, 1.000000e-03],\n       [9.999950e-01, 0.000000e+00, 0.000000e+00, ..., 0.000000e+00,\n        0.000000e+00, 0.000000e+00],\n       [1.000000e+00, 2.000000e-04, 8.000000e-04, ..., 2.300000e-03,\n        2.150000e-03, 0.000000e+00]])"},"metadata":{}}]},{"cell_type":"code","source":"scaled_data.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-04T10:51:42.648520Z","iopub.execute_input":"2024-06-04T10:51:42.649023Z","iopub.status.idle":"2024-06-04T10:51:42.656838Z","shell.execute_reply.started":"2024-06-04T10:51:42.648980Z","shell.execute_reply":"2024-06-04T10:51:42.655728Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(200000, 287)"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\nfrom sklearn.decomposition import PCA\n# This line imports the PCA class from the scikit-learn library, which is used for dimensionality reduction \n# using Principal Component Analysis.\n\n# Assuming X_train_scaled is your scaled training data\n# You can use X_train_formatted if you've converted it to human-readable format X_train_formatted\n\n# Initialize the PCA model with the desired number of components\nn_components = 33  # Adjust this value as needed, desired number of component.\n\npca = PCA(n_components=n_components)\n# This initializes a PCA model with the specified number of components.\n\n# Fit the PCA model to your scaled data\npca.fit(scaled_data)   \n# This fits the PCA model to the scaled data\n\n# Transform the data to its principal components\nprincipal_compo = pca.transform(scaled_data)\n# This line transforms the scaled data into its principal components using the trained PCA model.\n\n# Create a DataFrame for the PCA results using common columns\npca_df = pd.DataFrame(data=principal_compo, columns=[f'PC{i}' for i in range(1, 34)])\n# This creates a DataFrame (pca_df) to store the principal components. Each column is labeled with a prefix 'PC' followed \n# by the component number.\n# Printing the PCA results\nprint(pca_df)\n\n# Now, X_train_pca contains your training data reduced to the specified number of principal components\n# You can use X_train_pca for classification","metadata":{"execution":{"iopub.status.busy":"2024-06-04T10:51:45.702908Z","iopub.execute_input":"2024-06-04T10:51:45.703757Z","iopub.status.idle":"2024-06-04T10:51:49.824936Z","shell.execute_reply.started":"2024-06-04T10:51:45.703723Z","shell.execute_reply":"2024-06-04T10:51:49.823457Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"             PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n0      -0.195312  1.450241 -0.493021 -0.572657 -0.297635  0.197056  0.409163   \n1      -0.455772  0.023449 -0.499954 -0.147319  0.226927  0.058256 -0.082608   \n2      -0.455364 -0.176181 -0.501369  0.009695 -0.088106 -0.045754 -0.005828   \n3      -0.514005 -0.202394 -0.502223  0.088732 -0.101302  0.066164 -0.007542   \n4       0.498484  1.020506 -0.501141  0.310236 -0.013758 -0.050944 -0.443493   \n...          ...       ...       ...       ...       ...       ...       ...   \n199995 -0.481202 -0.183816  0.498148  0.051616 -0.089788 -0.002521 -0.010091   \n199996 -0.196881 -0.019007  0.500695 -0.205747  0.337804 -0.063212 -0.172516   \n199997 -0.212165 -0.158487  0.500078 -0.081012 -0.065431 -0.176712 -0.001372   \n199998 -0.364806  0.009943  0.501534 -0.485663  0.894588  0.268233  0.036862   \n199999 -0.871026 -0.253236  0.495066  0.280512 -0.152344  0.362414 -0.034231   \n\n             PC8       PC9      PC10  ...      PC24      PC25      PC26  \\\n0      -0.055585  0.132642 -0.030612  ...  0.031262  0.069201  0.015426   \n1      -0.255160 -0.024285 -0.059206  ...  0.027401 -0.023583  0.026651   \n2       0.039749 -0.008650 -0.046942  ... -0.003321  0.003882  0.000351   \n3       0.020212  0.002167  0.002285  ...  0.001753  0.006343  0.008681   \n4       0.146483  0.391403  0.099162  ... -0.029679 -0.098234 -0.139168   \n...          ...       ...       ...  ...       ...       ...       ...   \n199995  0.040611 -0.002719 -0.022311  ... -0.001978  0.015256 -0.008527   \n199996 -0.316229 -0.015809 -0.073452  ...  0.036769 -0.048644  0.017761   \n199997  0.050187 -0.012688 -0.063844  ...  0.002286 -0.002492 -0.007664   \n199998  0.354088  0.001979  0.033943  ...  0.002640  0.002402 -0.015101   \n199999  0.010121  0.009884  0.037142  ... -0.005165 -0.024149 -0.012419   \n\n            PC27      PC28      PC29      PC30      PC31      PC32      PC33  \n0       0.021976 -0.060552  0.099383  0.029592 -0.064177  0.008736  0.052071  \n1      -0.010969  0.094163 -0.002571 -0.015285  0.015643  0.050902 -0.007622  \n2       0.002519 -0.002791 -0.002763 -0.000576  0.006577  0.003019  0.007856  \n3      -0.001757 -0.000106  0.004722  0.002596 -0.003717  0.004000  0.003676  \n4      -0.007271  0.017293  0.037579 -0.106984  0.242398  0.049406  0.006874  \n...          ...       ...       ...       ...       ...       ...       ...  \n199995  0.005745 -0.001162  0.001809  0.004942  0.001078 -0.002611  0.002084  \n199996 -0.015422  0.027617 -0.036287  0.023712  0.022265 -0.023399 -0.068157  \n199997  0.003975 -0.003910 -0.004963 -0.003420  0.010346  0.003688  0.005862  \n199998  0.004543 -0.008223  0.012396 -0.020572 -0.010330  0.008032  0.006026  \n199999  0.015928 -0.006394  0.026058 -0.006136 -0.010416  0.017591  0.002778  \n\n[200000 rows x 33 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"pca_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-04T10:51:56.108733Z","iopub.execute_input":"2024-06-04T10:51:56.109059Z","iopub.status.idle":"2024-06-04T10:51:56.133663Z","shell.execute_reply.started":"2024-06-04T10:51:56.109035Z","shell.execute_reply":"2024-06-04T10:51:56.132663Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"        PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n0 -0.195312  1.450241 -0.493021 -0.572657 -0.297635  0.197056  0.409163   \n1 -0.455772  0.023449 -0.499954 -0.147319  0.226927  0.058256 -0.082608   \n2 -0.455364 -0.176181 -0.501369  0.009695 -0.088106 -0.045754 -0.005828   \n3 -0.514005 -0.202394 -0.502223  0.088732 -0.101302  0.066164 -0.007542   \n4  0.498484  1.020506 -0.501141  0.310236 -0.013758 -0.050944 -0.443493   \n\n        PC8       PC9      PC10  ...      PC24      PC25      PC26      PC27  \\\n0 -0.055585  0.132642 -0.030612  ...  0.031262  0.069201  0.015426  0.021976   \n1 -0.255160 -0.024285 -0.059206  ...  0.027401 -0.023583  0.026651 -0.010969   \n2  0.039749 -0.008650 -0.046942  ... -0.003321  0.003882  0.000351  0.002519   \n3  0.020212  0.002167  0.002285  ...  0.001753  0.006343  0.008681 -0.001757   \n4  0.146483  0.391403  0.099162  ... -0.029679 -0.098234 -0.139168 -0.007271   \n\n       PC28      PC29      PC30      PC31      PC32      PC33  \n0 -0.060552  0.099383  0.029592 -0.064177  0.008736  0.052071  \n1  0.094163 -0.002571 -0.015285  0.015643  0.050902 -0.007622  \n2 -0.002791 -0.002763 -0.000576  0.006577  0.003019  0.007856  \n3 -0.000106  0.004722  0.002596 -0.003717  0.004000  0.003676  \n4  0.017293  0.037579 -0.106984  0.242398  0.049406  0.006874  \n\n[5 rows x 33 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PC1</th>\n      <th>PC2</th>\n      <th>PC3</th>\n      <th>PC4</th>\n      <th>PC5</th>\n      <th>PC6</th>\n      <th>PC7</th>\n      <th>PC8</th>\n      <th>PC9</th>\n      <th>PC10</th>\n      <th>...</th>\n      <th>PC24</th>\n      <th>PC25</th>\n      <th>PC26</th>\n      <th>PC27</th>\n      <th>PC28</th>\n      <th>PC29</th>\n      <th>PC30</th>\n      <th>PC31</th>\n      <th>PC32</th>\n      <th>PC33</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.195312</td>\n      <td>1.450241</td>\n      <td>-0.493021</td>\n      <td>-0.572657</td>\n      <td>-0.297635</td>\n      <td>0.197056</td>\n      <td>0.409163</td>\n      <td>-0.055585</td>\n      <td>0.132642</td>\n      <td>-0.030612</td>\n      <td>...</td>\n      <td>0.031262</td>\n      <td>0.069201</td>\n      <td>0.015426</td>\n      <td>0.021976</td>\n      <td>-0.060552</td>\n      <td>0.099383</td>\n      <td>0.029592</td>\n      <td>-0.064177</td>\n      <td>0.008736</td>\n      <td>0.052071</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.455772</td>\n      <td>0.023449</td>\n      <td>-0.499954</td>\n      <td>-0.147319</td>\n      <td>0.226927</td>\n      <td>0.058256</td>\n      <td>-0.082608</td>\n      <td>-0.255160</td>\n      <td>-0.024285</td>\n      <td>-0.059206</td>\n      <td>...</td>\n      <td>0.027401</td>\n      <td>-0.023583</td>\n      <td>0.026651</td>\n      <td>-0.010969</td>\n      <td>0.094163</td>\n      <td>-0.002571</td>\n      <td>-0.015285</td>\n      <td>0.015643</td>\n      <td>0.050902</td>\n      <td>-0.007622</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.455364</td>\n      <td>-0.176181</td>\n      <td>-0.501369</td>\n      <td>0.009695</td>\n      <td>-0.088106</td>\n      <td>-0.045754</td>\n      <td>-0.005828</td>\n      <td>0.039749</td>\n      <td>-0.008650</td>\n      <td>-0.046942</td>\n      <td>...</td>\n      <td>-0.003321</td>\n      <td>0.003882</td>\n      <td>0.000351</td>\n      <td>0.002519</td>\n      <td>-0.002791</td>\n      <td>-0.002763</td>\n      <td>-0.000576</td>\n      <td>0.006577</td>\n      <td>0.003019</td>\n      <td>0.007856</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.514005</td>\n      <td>-0.202394</td>\n      <td>-0.502223</td>\n      <td>0.088732</td>\n      <td>-0.101302</td>\n      <td>0.066164</td>\n      <td>-0.007542</td>\n      <td>0.020212</td>\n      <td>0.002167</td>\n      <td>0.002285</td>\n      <td>...</td>\n      <td>0.001753</td>\n      <td>0.006343</td>\n      <td>0.008681</td>\n      <td>-0.001757</td>\n      <td>-0.000106</td>\n      <td>0.004722</td>\n      <td>0.002596</td>\n      <td>-0.003717</td>\n      <td>0.004000</td>\n      <td>0.003676</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.498484</td>\n      <td>1.020506</td>\n      <td>-0.501141</td>\n      <td>0.310236</td>\n      <td>-0.013758</td>\n      <td>-0.050944</td>\n      <td>-0.443493</td>\n      <td>0.146483</td>\n      <td>0.391403</td>\n      <td>0.099162</td>\n      <td>...</td>\n      <td>-0.029679</td>\n      <td>-0.098234</td>\n      <td>-0.139168</td>\n      <td>-0.007271</td>\n      <td>0.017293</td>\n      <td>0.037579</td>\n      <td>-0.106984</td>\n      <td>0.242398</td>\n      <td>0.049406</td>\n      <td>0.006874</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 33 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"pca_df['target'] = target_column","metadata":{"execution":{"iopub.status.busy":"2024-06-04T10:51:58.617927Z","iopub.execute_input":"2024-06-04T10:51:58.618597Z","iopub.status.idle":"2024-06-04T10:51:58.624446Z","shell.execute_reply.started":"2024-06-04T10:51:58.618562Z","shell.execute_reply":"2024-06-04T10:51:58.623414Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"pca_df","metadata":{"execution":{"iopub.status.busy":"2024-06-04T10:52:03.157941Z","iopub.execute_input":"2024-06-04T10:52:03.158304Z","iopub.status.idle":"2024-06-04T10:52:03.252696Z","shell.execute_reply.started":"2024-06-04T10:52:03.158275Z","shell.execute_reply":"2024-06-04T10:52:03.251730Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"             PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n0      -0.195312  1.450241 -0.493021 -0.572657 -0.297635  0.197056  0.409163   \n1      -0.455772  0.023449 -0.499954 -0.147319  0.226927  0.058256 -0.082608   \n2      -0.455364 -0.176181 -0.501369  0.009695 -0.088106 -0.045754 -0.005828   \n3      -0.514005 -0.202394 -0.502223  0.088732 -0.101302  0.066164 -0.007542   \n4       0.498484  1.020506 -0.501141  0.310236 -0.013758 -0.050944 -0.443493   \n...          ...       ...       ...       ...       ...       ...       ...   \n199995 -0.481202 -0.183816  0.498148  0.051616 -0.089788 -0.002521 -0.010091   \n199996 -0.196881 -0.019007  0.500695 -0.205747  0.337804 -0.063212 -0.172516   \n199997 -0.212165 -0.158487  0.500078 -0.081012 -0.065431 -0.176712 -0.001372   \n199998 -0.364806  0.009943  0.501534 -0.485663  0.894588  0.268233  0.036862   \n199999 -0.871026 -0.253236  0.495066  0.280512 -0.152344  0.362414 -0.034231   \n\n             PC8       PC9      PC10  ...      PC25      PC26      PC27  \\\n0      -0.055585  0.132642 -0.030612  ...  0.069201  0.015426  0.021976   \n1      -0.255160 -0.024285 -0.059206  ... -0.023583  0.026651 -0.010969   \n2       0.039749 -0.008650 -0.046942  ...  0.003882  0.000351  0.002519   \n3       0.020212  0.002167  0.002285  ...  0.006343  0.008681 -0.001757   \n4       0.146483  0.391403  0.099162  ... -0.098234 -0.139168 -0.007271   \n...          ...       ...       ...  ...       ...       ...       ...   \n199995  0.040611 -0.002719 -0.022311  ...  0.015256 -0.008527  0.005745   \n199996 -0.316229 -0.015809 -0.073452  ... -0.048644  0.017761 -0.015422   \n199997  0.050187 -0.012688 -0.063844  ... -0.002492 -0.007664  0.003975   \n199998  0.354088  0.001979  0.033943  ...  0.002402 -0.015101  0.004543   \n199999  0.010121  0.009884  0.037142  ... -0.024149 -0.012419  0.015928   \n\n            PC28      PC29      PC30      PC31      PC32      PC33  \\\n0      -0.060552  0.099383  0.029592 -0.064177  0.008736  0.052071   \n1       0.094163 -0.002571 -0.015285  0.015643  0.050902 -0.007622   \n2      -0.002791 -0.002763 -0.000576  0.006577  0.003019  0.007856   \n3      -0.000106  0.004722  0.002596 -0.003717  0.004000  0.003676   \n4       0.017293  0.037579 -0.106984  0.242398  0.049406  0.006874   \n...          ...       ...       ...       ...       ...       ...   \n199995 -0.001162  0.001809  0.004942  0.001078 -0.002611  0.002084   \n199996  0.027617 -0.036287  0.023712  0.022265 -0.023399 -0.068157   \n199997 -0.003910 -0.004963 -0.003420  0.010346  0.003688  0.005862   \n199998 -0.008223  0.012396 -0.020572 -0.010330  0.008032  0.006026   \n199999 -0.006394  0.026058 -0.006136 -0.010416  0.017591  0.002778   \n\n                          target  \n0         Streptococcus_pyogenes  \n1            Salmonella_enterica  \n2            Salmonella_enterica  \n3            Salmonella_enterica  \n4             Enterococcus_hirae  \n...                          ...  \n199995       Salmonella_enterica  \n199996    Streptococcus_pyogenes  \n199997  Streptococcus_pneumoniae  \n199998     Staphylococcus_aureus  \n199999     Klebsiella_pneumoniae  \n\n[200000 rows x 34 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PC1</th>\n      <th>PC2</th>\n      <th>PC3</th>\n      <th>PC4</th>\n      <th>PC5</th>\n      <th>PC6</th>\n      <th>PC7</th>\n      <th>PC8</th>\n      <th>PC9</th>\n      <th>PC10</th>\n      <th>...</th>\n      <th>PC25</th>\n      <th>PC26</th>\n      <th>PC27</th>\n      <th>PC28</th>\n      <th>PC29</th>\n      <th>PC30</th>\n      <th>PC31</th>\n      <th>PC32</th>\n      <th>PC33</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.195312</td>\n      <td>1.450241</td>\n      <td>-0.493021</td>\n      <td>-0.572657</td>\n      <td>-0.297635</td>\n      <td>0.197056</td>\n      <td>0.409163</td>\n      <td>-0.055585</td>\n      <td>0.132642</td>\n      <td>-0.030612</td>\n      <td>...</td>\n      <td>0.069201</td>\n      <td>0.015426</td>\n      <td>0.021976</td>\n      <td>-0.060552</td>\n      <td>0.099383</td>\n      <td>0.029592</td>\n      <td>-0.064177</td>\n      <td>0.008736</td>\n      <td>0.052071</td>\n      <td>Streptococcus_pyogenes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.455772</td>\n      <td>0.023449</td>\n      <td>-0.499954</td>\n      <td>-0.147319</td>\n      <td>0.226927</td>\n      <td>0.058256</td>\n      <td>-0.082608</td>\n      <td>-0.255160</td>\n      <td>-0.024285</td>\n      <td>-0.059206</td>\n      <td>...</td>\n      <td>-0.023583</td>\n      <td>0.026651</td>\n      <td>-0.010969</td>\n      <td>0.094163</td>\n      <td>-0.002571</td>\n      <td>-0.015285</td>\n      <td>0.015643</td>\n      <td>0.050902</td>\n      <td>-0.007622</td>\n      <td>Salmonella_enterica</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.455364</td>\n      <td>-0.176181</td>\n      <td>-0.501369</td>\n      <td>0.009695</td>\n      <td>-0.088106</td>\n      <td>-0.045754</td>\n      <td>-0.005828</td>\n      <td>0.039749</td>\n      <td>-0.008650</td>\n      <td>-0.046942</td>\n      <td>...</td>\n      <td>0.003882</td>\n      <td>0.000351</td>\n      <td>0.002519</td>\n      <td>-0.002791</td>\n      <td>-0.002763</td>\n      <td>-0.000576</td>\n      <td>0.006577</td>\n      <td>0.003019</td>\n      <td>0.007856</td>\n      <td>Salmonella_enterica</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.514005</td>\n      <td>-0.202394</td>\n      <td>-0.502223</td>\n      <td>0.088732</td>\n      <td>-0.101302</td>\n      <td>0.066164</td>\n      <td>-0.007542</td>\n      <td>0.020212</td>\n      <td>0.002167</td>\n      <td>0.002285</td>\n      <td>...</td>\n      <td>0.006343</td>\n      <td>0.008681</td>\n      <td>-0.001757</td>\n      <td>-0.000106</td>\n      <td>0.004722</td>\n      <td>0.002596</td>\n      <td>-0.003717</td>\n      <td>0.004000</td>\n      <td>0.003676</td>\n      <td>Salmonella_enterica</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.498484</td>\n      <td>1.020506</td>\n      <td>-0.501141</td>\n      <td>0.310236</td>\n      <td>-0.013758</td>\n      <td>-0.050944</td>\n      <td>-0.443493</td>\n      <td>0.146483</td>\n      <td>0.391403</td>\n      <td>0.099162</td>\n      <td>...</td>\n      <td>-0.098234</td>\n      <td>-0.139168</td>\n      <td>-0.007271</td>\n      <td>0.017293</td>\n      <td>0.037579</td>\n      <td>-0.106984</td>\n      <td>0.242398</td>\n      <td>0.049406</td>\n      <td>0.006874</td>\n      <td>Enterococcus_hirae</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>199995</th>\n      <td>-0.481202</td>\n      <td>-0.183816</td>\n      <td>0.498148</td>\n      <td>0.051616</td>\n      <td>-0.089788</td>\n      <td>-0.002521</td>\n      <td>-0.010091</td>\n      <td>0.040611</td>\n      <td>-0.002719</td>\n      <td>-0.022311</td>\n      <td>...</td>\n      <td>0.015256</td>\n      <td>-0.008527</td>\n      <td>0.005745</td>\n      <td>-0.001162</td>\n      <td>0.001809</td>\n      <td>0.004942</td>\n      <td>0.001078</td>\n      <td>-0.002611</td>\n      <td>0.002084</td>\n      <td>Salmonella_enterica</td>\n    </tr>\n    <tr>\n      <th>199996</th>\n      <td>-0.196881</td>\n      <td>-0.019007</td>\n      <td>0.500695</td>\n      <td>-0.205747</td>\n      <td>0.337804</td>\n      <td>-0.063212</td>\n      <td>-0.172516</td>\n      <td>-0.316229</td>\n      <td>-0.015809</td>\n      <td>-0.073452</td>\n      <td>...</td>\n      <td>-0.048644</td>\n      <td>0.017761</td>\n      <td>-0.015422</td>\n      <td>0.027617</td>\n      <td>-0.036287</td>\n      <td>0.023712</td>\n      <td>0.022265</td>\n      <td>-0.023399</td>\n      <td>-0.068157</td>\n      <td>Streptococcus_pyogenes</td>\n    </tr>\n    <tr>\n      <th>199997</th>\n      <td>-0.212165</td>\n      <td>-0.158487</td>\n      <td>0.500078</td>\n      <td>-0.081012</td>\n      <td>-0.065431</td>\n      <td>-0.176712</td>\n      <td>-0.001372</td>\n      <td>0.050187</td>\n      <td>-0.012688</td>\n      <td>-0.063844</td>\n      <td>...</td>\n      <td>-0.002492</td>\n      <td>-0.007664</td>\n      <td>0.003975</td>\n      <td>-0.003910</td>\n      <td>-0.004963</td>\n      <td>-0.003420</td>\n      <td>0.010346</td>\n      <td>0.003688</td>\n      <td>0.005862</td>\n      <td>Streptococcus_pneumoniae</td>\n    </tr>\n    <tr>\n      <th>199998</th>\n      <td>-0.364806</td>\n      <td>0.009943</td>\n      <td>0.501534</td>\n      <td>-0.485663</td>\n      <td>0.894588</td>\n      <td>0.268233</td>\n      <td>0.036862</td>\n      <td>0.354088</td>\n      <td>0.001979</td>\n      <td>0.033943</td>\n      <td>...</td>\n      <td>0.002402</td>\n      <td>-0.015101</td>\n      <td>0.004543</td>\n      <td>-0.008223</td>\n      <td>0.012396</td>\n      <td>-0.020572</td>\n      <td>-0.010330</td>\n      <td>0.008032</td>\n      <td>0.006026</td>\n      <td>Staphylococcus_aureus</td>\n    </tr>\n    <tr>\n      <th>199999</th>\n      <td>-0.871026</td>\n      <td>-0.253236</td>\n      <td>0.495066</td>\n      <td>0.280512</td>\n      <td>-0.152344</td>\n      <td>0.362414</td>\n      <td>-0.034231</td>\n      <td>0.010121</td>\n      <td>0.009884</td>\n      <td>0.037142</td>\n      <td>...</td>\n      <td>-0.024149</td>\n      <td>-0.012419</td>\n      <td>0.015928</td>\n      <td>-0.006394</td>\n      <td>0.026058</td>\n      <td>-0.006136</td>\n      <td>-0.010416</td>\n      <td>0.017591</td>\n      <td>0.002778</td>\n      <td>Klebsiella_pneumoniae</td>\n    </tr>\n  </tbody>\n</table>\n<p>200000 rows × 34 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-06-04T10:52:06.868173Z","iopub.execute_input":"2024-06-04T10:52:06.869047Z","iopub.status.idle":"2024-06-04T10:52:06.873065Z","shell.execute_reply.started":"2024-06-04T10:52:06.869016Z","shell.execute_reply":"2024-06-04T10:52:06.872039Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"y = pca_df['target']\nX = pca_df.drop(columns=['target'])","metadata":{"execution":{"iopub.status.busy":"2024-06-04T10:52:10.307715Z","iopub.execute_input":"2024-06-04T10:52:10.308451Z","iopub.status.idle":"2024-06-04T10:52:10.334034Z","shell.execute_reply.started":"2024-06-04T10:52:10.308417Z","shell.execute_reply":"2024-06-04T10:52:10.332883Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Convert y to a pandas Series\ny = pd.Series(y)\n# Convert X to a pandas DataFrame\nX = pd.DataFrame(X)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:00:05.594844Z","iopub.execute_input":"2024-06-04T13:00:05.595731Z","iopub.status.idle":"2024-06-04T13:00:05.600302Z","shell.execute_reply.started":"2024-06-04T13:00:05.595697Z","shell.execute_reply":"2024-06-04T13:00:05.599161Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"y.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-04T10:52:17.178142Z","iopub.execute_input":"2024-06-04T10:52:17.178563Z","iopub.status.idle":"2024-06-04T10:52:17.185631Z","shell.execute_reply.started":"2024-06-04T10:52:17.178528Z","shell.execute_reply":"2024-06-04T10:52:17.184543Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(200000,)"},"metadata":{}}]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2024-06-04T10:52:20.017937Z","iopub.execute_input":"2024-06-04T10:52:20.018587Z","iopub.status.idle":"2024-06-04T10:52:20.026345Z","shell.execute_reply.started":"2024-06-04T10:52:20.018553Z","shell.execute_reply":"2024-06-04T10:52:20.025432Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"0           Streptococcus_pyogenes\n1              Salmonella_enterica\n2              Salmonella_enterica\n3              Salmonella_enterica\n4               Enterococcus_hirae\n                    ...           \n199995         Salmonella_enterica\n199996      Streptococcus_pyogenes\n199997    Streptococcus_pneumoniae\n199998       Staphylococcus_aureus\n199999       Klebsiella_pneumoniae\nName: target, Length: 200000, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2024-06-04T10:52:22.877591Z","iopub.execute_input":"2024-06-04T10:52:22.878215Z","iopub.status.idle":"2024-06-04T10:52:22.884326Z","shell.execute_reply.started":"2024-06-04T10:52:22.878185Z","shell.execute_reply":"2024-06-04T10:52:22.883287Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"(200000, 33)"},"metadata":{}}]},{"cell_type":"code","source":"#                          ---------------------------Fifth Model --------------------------------------","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#                       ----------------------CNN classifier----------------","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from cuml.cluster import KMeans as cuKMeans  # Import cuML KMeans for GPU acceleration\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv1D, Dense, Flatten, MaxPooling1D\nfrom tensorflow.keras.utils import to_categorical","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:24.653466Z","iopub.execute_input":"2024-06-04T11:53:24.654384Z","iopub.status.idle":"2024-06-04T11:53:24.659421Z","shell.execute_reply.started":"2024-06-04T11:53:24.654339Z","shell.execute_reply":"2024-06-04T11:53:24.658646Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Ensure the target variable is categorical\ny = pd.Categorical(y)\ny_encoded = y.codes  # Convert to integer codes\nnum_classes = len(y.categories)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:29.127945Z","iopub.execute_input":"2024-06-04T11:53:29.128901Z","iopub.status.idle":"2024-06-04T11:53:29.134208Z","shell.execute_reply.started":"2024-06-04T11:53:29.128863Z","shell.execute_reply":"2024-06-04T11:53:29.133088Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Perform StratifiedShuffleSplit cross-validation\nsss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\ntrain_accuracies = []\ntest_accuracies = []","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:31.912960Z","iopub.execute_input":"2024-06-04T11:53:31.913341Z","iopub.status.idle":"2024-06-04T11:53:31.918697Z","shell.execute_reply.started":"2024-06-04T11:53:31.913311Z","shell.execute_reply":"2024-06-04T11:53:31.917655Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom cuml.cluster import KMeans as cuKMeans  # Import cuML KMeans for GPU acceleration\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.optimizers import Adamax\nfrom tensorflow.keras.initializers import he_normal\n\n# Function to get the predominant class and its average record for each cluster\ndef get_representative_record(cluster_df):\n    # Get the predominant class\n    predominant_class = cluster_df['target'].mode()[0]\n    \n    # Filter records of the predominant class\n    predominant_class_records = cluster_df[cluster_df['target'] == predominant_class].drop(columns=['cluster', 'target'])\n    \n    # Compute the average record for the predominant class\n    representative_record = predominant_class_records.mean()\n    representative_record['target'] = predominant_class\n    \n    return representative_record\n\n# Define the multi-layered dense neural network model\ndef create_dense_nn(input_shape, num_classes):\n    model = Sequential()\n    model.add(Dense(512, activation='relu', kernel_initializer=he_normal(), input_shape=input_shape, kernel_regularizer=l2(0.001)))\n    model.add(Dense(256, activation='relu', kernel_initializer=he_normal(), kernel_regularizer=l2(0.001)))\n    model.add(Dense(64, activation='relu', kernel_initializer=he_normal(), kernel_regularizer=l2(0.001)))\n    model.add(Dense(512, activation='relu', kernel_initializer=he_normal(), kernel_regularizer=l2(0.001)))\n    model.add(Dropout(0.5))\n    model.add(Dense(128, activation='relu', kernel_initializer=he_normal(), kernel_regularizer=l2(0.001)))\n    model.add(Dense(64, activation='relu', kernel_initializer=he_normal(), kernel_regularizer=l2(0.001)))\n    model.add(Dense(512, activation='relu', kernel_initializer=he_normal(), kernel_regularizer=l2(0.001)))\n    model.add(Dropout(0.5))\n    model.add(Dense(128, activation='relu', kernel_initializer=he_normal(), kernel_regularizer=l2(0.001)))\n    model.add(Dense(64, activation='relu', kernel_initializer=he_normal(), kernel_regularizer=l2(0.001)))\n    model.add(Dense(num_classes, activation='softmax'))\n    model.compile(optimizer=Adamax(), loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n\nfor train_index, test_index in sss.split(X, y_encoded):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n    \n#     print(\"Before KMeans\")\n    \n    # Apply KMeans clustering on the training set using cuML\n    kmeans = cuKMeans(n_clusters=10000)\n    kmeans.fit(X_train.values)  # Convert to NumPy array\n    \n    X_train_clustered = X_train.copy()  # Avoid SettingWithCopyWarning by working on a copy\n    X_train_clustered['cluster'] = kmeans.labels_\n    X_train_clustered['target'] = y_train\n    \n    # Generate the reduced training dataset\n    reduced_train_data = X_train_clustered.groupby('cluster').apply(get_representative_record).reset_index(drop=True)\n    \n    # Prepare data for model training\n    X_train_reduced = reduced_train_data.drop(columns=['target']).values  # Convert to NumPy array\n    y_train_reduced = reduced_train_data['target'].values  # Convert to NumPy array\n    \n    # One-hot encode the labels\n    y_train_reduced_categorical = to_categorical(y_train_reduced, num_classes=num_classes)\n    \n    # Create the dense neural network model\n    cnn_model = create_dense_nn(input_shape=(X_train_reduced.shape[1],), num_classes=num_classes)\n    \n    # Train the model on the reduced training set\n    cnn_model.fit(X_train_reduced, y_train_reduced_categorical, epochs=100, batch_size=32, verbose=0)  # Set verbose=0\n    \n    # Predict on the training set\n    y_train_pred = cnn_model.predict(X_train_reduced)\n    y_train_pred_classes = np.argmax(y_train_pred, axis=1)\n    train_accuracy = accuracy_score(y_train_reduced, y_train_pred_classes)\n    train_accuracies.append(train_accuracy)\n    \n    # One-hot encode the test labels\n    y_test_categorical = to_categorical(y_test, num_classes=num_classes)\n    \n    # Predict on the original test set\n    y_test_pred = cnn_model.predict(X_test.values)\n    y_test_pred_classes = np.argmax(y_test_pred, axis=1)\n    test_accuracy = accuracy_score(y_test, y_test_pred_classes)\n    test_accuracies.append(test_accuracy)\n    \n    print(f'Fold training accuracy: {train_accuracy:.4f}')\n    print(f'Fold test accuracy: {test_accuracy:.4f}')\n#     break\n\n# Calculate the average accuracies\naverage_train_accuracy = np.mean(train_accuracies)\naverage_test_accuracy = np.mean(test_accuracies)\nprint(f'Average training accuracy: {average_train_accuracy:.4f}')\nprint(f'Average test accuracy: {average_test_accuracy:.4f}') ","metadata":{"execution":{"iopub.status.busy":"2024-06-04T11:53:36.768347Z","iopub.execute_input":"2024-06-04T11:53:36.768738Z","iopub.status.idle":"2024-06-04T12:45:04.367540Z","shell.execute_reply.started":"2024-06-04T11:53:36.768706Z","shell.execute_reply":"2024-06-04T12:45:04.366451Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"313/313 [==============================] - 1s 2ms/step\n625/625 [==============================] - 1s 2ms/step\nFold training accuracy: 0.9844\nFold test accuracy: 0.8563\n313/313 [==============================] - 1s 2ms/step\n625/625 [==============================] - 1s 2ms/step\nFold training accuracy: 0.9882\nFold test accuracy: 0.8526\n313/313 [==============================] - 1s 2ms/step\n625/625 [==============================] - 1s 2ms/step\nFold training accuracy: 0.9895\nFold test accuracy: 0.8589\n313/313 [==============================] - 1s 2ms/step\n625/625 [==============================] - 1s 2ms/step\nFold training accuracy: 0.9828\nFold test accuracy: 0.8359\n313/313 [==============================] - 1s 2ms/step\n625/625 [==============================] - 1s 2ms/step\nFold training accuracy: 0.9800\nFold test accuracy: 0.8245\n313/313 [==============================] - 1s 2ms/step\n625/625 [==============================] - 1s 2ms/step\nFold training accuracy: 0.9849\nFold test accuracy: 0.8575\n313/313 [==============================] - 1s 2ms/step\n625/625 [==============================] - 1s 2ms/step\nFold training accuracy: 0.9853\nFold test accuracy: 0.8589\n313/313 [==============================] - 1s 2ms/step\n625/625 [==============================] - 1s 2ms/step\nFold training accuracy: 0.9793\nFold test accuracy: 0.8556\n313/313 [==============================] - 1s 2ms/step\n625/625 [==============================] - 1s 2ms/step\nFold training accuracy: 0.9854\nFold test accuracy: 0.8549\n313/313 [==============================] - 1s 2ms/step\n625/625 [==============================] - 1s 2ms/step\nFold training accuracy: 0.9861\nFold test accuracy: 0.8433\nAverage training accuracy: 0.9846\nAverage test accuracy: 0.8498\n","output_type":"stream"}]},{"cell_type":"code","source":"#                          ---------------------------Fourth Model --------------------------------------","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#                       ----------------------AdaBoost classifier----------------","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from cuml.cluster import KMeans as cuKMeans  # Import cuML's KMeans for GPU acceleration\nfrom sklearn.ensemble import AdaBoostClassifier  # Import AdaBoost for classification\nfrom sklearn.model_selection import StratifiedShuffleSplit  # Import StratifiedShuffleSplit for cross-validation\nfrom sklearn.metrics import accuracy_score  # Import accuracy_score for evaluation\nimport numpy as np  # Import NumPy for numerical operations\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T23:19:47.402757Z","iopub.execute_input":"2024-06-03T23:19:47.403128Z","iopub.status.idle":"2024-06-03T23:19:47.408884Z","shell.execute_reply.started":"2024-06-03T23:19:47.403099Z","shell.execute_reply":"2024-06-03T23:19:47.407735Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n\nbase_estimator = DecisionTreeClassifier(max_depth=5)  # You can adjust max_depth\n# Step 4: Initialize the AdaBoost Classifier\nmodel_4 = AdaBoostClassifier(estimator=base_estimator,n_estimators=50,learning_rate=1)\n# Initialize the AdaBoost model\n# model_4 = AdaBoostClassifier()\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T23:19:51.442093Z","iopub.execute_input":"2024-06-03T23:19:51.442817Z","iopub.status.idle":"2024-06-03T23:19:51.447653Z","shell.execute_reply.started":"2024-06-03T23:19:51.442786Z","shell.execute_reply":"2024-06-03T23:19:51.446646Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# Perform StratifiedShuffleSplit cross-validation\nsss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\ntrain_accuracies = []\ntest_accuracies = []","metadata":{"execution":{"iopub.status.busy":"2024-06-03T23:19:58.807249Z","iopub.execute_input":"2024-06-03T23:19:58.807592Z","iopub.status.idle":"2024-06-03T23:19:58.812194Z","shell.execute_reply.started":"2024-06-03T23:19:58.807564Z","shell.execute_reply":"2024-06-03T23:19:58.811210Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"AdaBoost  Results:-\")\n\n# Function to get the predominant class and its average record for each cluster\ndef get_representative_record(cluster_df):\n    # Get the predominant class\n    predominant_class = cluster_df['target'].mode()[0]\n    \n    # Filter records of the predominant class\n    predominant_class_records = cluster_df[cluster_df['target'] == predominant_class].drop(columns=['cluster', 'target'])\n    \n    # Compute the average record for the predominant class\n    representative_record = predominant_class_records.mean()\n    representative_record['target'] = predominant_class\n    \n    return representative_record\nfor train_index, test_index in sss.split(X, y):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    \n#     print(f'Before kmean:{X_train.shape}')\n    # Apply KMeans clustering on the training set using cuML\n    kmeans = cuKMeans(n_clusters=10000)\n    kmeans.fit(X_train.values)  # Convert to NumPy array\n    \n    X_train_clustered = X_train.copy()  # Avoid SettingWithCopyWarning by working on a copy\n    X_train_clustered['cluster'] = kmeans.labels_\n    X_train_clustered['target'] = y_train.values\n    \n    # Generate the reduced training dataset\n    reduced_train_data = X_train_clustered.groupby('cluster').apply(get_representative_record).reset_index(drop=True)\n    \n#     print(f'After kmean:{X_train_reduced.shape}')\n\n    # Prepare data for model training\n    X_train_reduced = reduced_train_data.drop(columns=['target']).values  # Convert to NumPy array\n    y_train_reduced = reduced_train_data['target'].values  # Convert to NumPy array\n    \n#     print(\"After KMeans\")\n#     print(X_train_reduced.shape)\n    \n    # Train the model on the reduced training set\n    model_4.fit(X_train_reduced, y_train_reduced)\n    \n    # Predict on the training set\n    y_train_pred = model_4.predict(X_train_reduced)\n    train_accuracy = accuracy_score(y_train_reduced, y_train_pred)\n    train_accuracies.append(train_accuracy)\n    \n    # Predict on the original test set\n    y_test_pred = model_4.predict(X_test.values)  # Convert to NumPy array\n    test_accuracy = accuracy_score(y_test, y_test_pred)\n    test_accuracies.append(test_accuracy)\n    \n    print(f'Fold training accuracy for adaboost: {train_accuracy:.4f}')\n    print(f'Fold test accuracy for adaboost: {test_accuracy:.4f}')\n    print(\"-------------------------------------\")\n#     break\n    \n# Calculate the average accuracies\naverage_train_accuracy = np.mean(train_accuracies)\naverage_test_accuracy = np.mean(test_accuracies)\nprint(f'Average training accuracy for adaboost: {average_train_accuracy:.4f}')\nprint(f'Average test accuracy for adaboost: {average_test_accuracy:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-06-03T23:20:31.581756Z","iopub.execute_input":"2024-06-03T23:20:31.582490Z","iopub.status.idle":"2024-06-03T23:50:11.427604Z","shell.execute_reply.started":"2024-06-03T23:20:31.582460Z","shell.execute_reply":"2024-06-03T23:50:11.426495Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"AdaBoost  Results:-\nFold training accuracy for adaboost: 0.6002\nFold test accuracy for adaboost: 0.5486\n-------------------------------------\nFold training accuracy for adaboost: 0.5819\nFold test accuracy for adaboost: 0.4870\n-------------------------------------\nFold training accuracy for adaboost: 0.5843\nFold test accuracy for adaboost: 0.5719\n-------------------------------------\nFold training accuracy for adaboost: 0.6121\nFold test accuracy for adaboost: 0.5754\n-------------------------------------\nFold training accuracy for adaboost: 0.5916\nFold test accuracy for adaboost: 0.5727\n-------------------------------------\nFold training accuracy for adaboost: 0.5830\nFold test accuracy for adaboost: 0.5853\n-------------------------------------\nFold training accuracy for adaboost: 0.5783\nFold test accuracy for adaboost: 0.5100\n-------------------------------------\nFold training accuracy for adaboost: 0.5962\nFold test accuracy for adaboost: 0.5311\n-------------------------------------\nFold training accuracy for adaboost: 0.5868\nFold test accuracy for adaboost: 0.5660\n-------------------------------------\nFold training accuracy for adaboost: 0.5889\nFold test accuracy for adaboost: 0.4880\n-------------------------------------\nAverage training accuracy for adaboost: 0.5903\nAverage test accuracy for adaboost: 0.5436\n","output_type":"stream"}]},{"cell_type":"code","source":"#                          ---------------------------Third Model --------------------------------------","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#                        ----------------------Naive Bayes classifier----------------","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom cuml.cluster import KMeans as cuKMeans  # Import cuML KMeans for GPU acceleration","metadata":{"execution":{"iopub.status.busy":"2024-06-04T06:37:20.541708Z","iopub.execute_input":"2024-06-04T06:37:20.542717Z","iopub.status.idle":"2024-06-04T06:37:20.564390Z","shell.execute_reply.started":"2024-06-04T06:37:20.542680Z","shell.execute_reply":"2024-06-04T06:37:20.563482Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# Initialize the Naive Bayes classifier\nmodel_3 = GaussianNB()","metadata":{"execution":{"iopub.status.busy":"2024-06-04T06:37:26.216261Z","iopub.execute_input":"2024-06-04T06:37:26.216623Z","iopub.status.idle":"2024-06-04T06:37:26.221354Z","shell.execute_reply.started":"2024-06-04T06:37:26.216596Z","shell.execute_reply":"2024-06-04T06:37:26.220408Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# from sklearn.model_selection import StratifiedShuffleSplit\n\n# Define the StratifiedShuffleSplit cross-validator\nsss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\n\n# Lists to store results\ntrain_accuracies = []\ntest_accuracies = []","metadata":{"execution":{"iopub.status.busy":"2024-06-04T06:37:31.346580Z","iopub.execute_input":"2024-06-04T06:37:31.347349Z","iopub.status.idle":"2024-06-04T06:37:31.351821Z","shell.execute_reply.started":"2024-06-04T06:37:31.347318Z","shell.execute_reply":"2024-06-04T06:37:31.350785Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"print(\"Naive bayes Result\")\n# Function to get the predominant class and its average record for each cluster\ndef get_representative_record(cluster_df):\n    # Get the predominant class\n    predominant_class = cluster_df['target'].mode()[0]\n    \n    # Filter records of the predominant class\n    predominant_class_records = cluster_df[cluster_df['target'] == predominant_class].drop(columns=['cluster', 'target'])\n    \n    # Compute the average record for the predominant class\n    representative_record = predominant_class_records.mean()\n    representative_record['target'] = predominant_class\n    \n    return representative_record\nfor train_index, test_index in sss.split(X, y):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    \n#     print(\"Before KMeans\")\n#     print(X_train.shape)\n    \n    # Apply KMeans clustering on the training set using cuML\n    kmeans = cuKMeans(n_clusters=10000)\n    kmeans.fit(X_train.values)  # Convert to NumPy array\n    \n    # Create a DataFrame with cluster labels\n    X_train_clustered = X_train.copy()  # Avoid SettingWithCopyWarning by working on a copy\n    X_train_clustered['cluster'] = kmeans.labels_\n    X_train_clustered['target'] = y_train.values\n    \n    # Generate the reduced training dataset\n    reduced_train_data = X_train_clustered.groupby('cluster').apply(get_representative_record).reset_index(drop=True)\n    \n    # Prepare data for model training\n    X_train_reduced = reduced_train_data.drop(columns=['target']).values  # Convert to NumPy array\n    y_train_reduced = reduced_train_data['target'].values  # Convert to NumPy array\n    \n#     print(\"After KMeans\")\n#     print(X_train_reduced.shape)\n    \n    # Train the model on the reduced training set\n    model_3.fit(X_train_reduced, y_train_reduced)\n    \n    # Predict on the training set\n    y_train_pred = model_3.predict(X_train_reduced)\n    train_accuracy = accuracy_score(y_train_reduced, y_train_pred)\n    train_accuracies.append(train_accuracy)\n    \n    # Predict on the original test set\n    y_test_pred = model_3.predict(X_test.values)  # Convert to NumPy array\n    test_accuracy = accuracy_score(y_test, y_test_pred)\n    test_accuracies.append(test_accuracy)\n    \n    print(f'Fold training accuracy for Naive : {train_accuracy:.2f}')\n    print(f'Fold test accuracy for Naive: {test_accuracy:.2f}')\n    print(\"---------------------------\")\n#     break\n\n# Calculate the average accuracies\naverage_train_accuracy = np.mean(train_accuracies)\naverage_test_accuracy = np.mean(test_accuracies)\nprint(f'Average training accuracy Naive: {average_train_accuracy:.4f}')\nprint(f'Average test accuracy for Naive: {average_test_accuracy:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-04T06:37:55.545194Z","iopub.execute_input":"2024-06-04T06:37:55.545568Z","iopub.status.idle":"2024-06-04T07:05:08.024573Z","shell.execute_reply.started":"2024-06-04T06:37:55.545540Z","shell.execute_reply":"2024-06-04T07:05:08.023598Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Naive bayes Result\nFold training accuracy for Naive : 0.51\nFold test accuracy for Naive: 0.47\n---------------------------\nFold training accuracy for Naive : 0.51\nFold test accuracy for Naive: 0.45\n---------------------------\nFold training accuracy for Naive : 0.52\nFold test accuracy for Naive: 0.48\n---------------------------\nFold training accuracy for Naive : 0.51\nFold test accuracy for Naive: 0.46\n---------------------------\nFold training accuracy for Naive : 0.51\nFold test accuracy for Naive: 0.49\n---------------------------\nFold training accuracy for Naive : 0.52\nFold test accuracy for Naive: 0.49\n---------------------------\nFold training accuracy for Naive : 0.51\nFold test accuracy for Naive: 0.46\n---------------------------\nFold training accuracy for Naive : 0.51\nFold test accuracy for Naive: 0.49\n---------------------------\nFold training accuracy for Naive : 0.52\nFold test accuracy for Naive: 0.47\n---------------------------\nFold training accuracy for Naive : 0.51\nFold test accuracy for Naive: 0.47\n---------------------------\nAverage training accuracy Naive: 0.5135\nAverage test accuracy for Naive: 0.4737\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'Average test accuracy: {average_test_accuracy:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T14:57:11.569003Z","iopub.execute_input":"2024-05-19T14:57:11.569389Z","iopub.status.idle":"2024-05-19T14:57:11.575282Z","shell.execute_reply.started":"2024-05-19T14:57:11.569359Z","shell.execute_reply":"2024-05-19T14:57:11.574122Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Average test accuracy: 0.4609\n","output_type":"stream"}]},{"cell_type":"code","source":"                         ---------------------------Second Model --------------------------------------","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"                                           # -----------SVM---------------","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.cluster import KMeans\nimport numpy as np\nimport cudf\nimport cuml\n\nfrom sklearn.svm import SVC","metadata":{"execution":{"iopub.status.busy":"2024-06-03T18:10:14.770373Z","iopub.execute_input":"2024-06-03T18:10:14.771170Z","iopub.status.idle":"2024-06-03T18:10:14.775822Z","shell.execute_reply.started":"2024-06-03T18:10:14.771135Z","shell.execute_reply":"2024-06-03T18:10:14.774802Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"# Define the model\nmodel_2 = SVC(kernel='linear', C=1.0)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T18:10:17.958706Z","iopub.execute_input":"2024-06-03T18:10:17.959420Z","iopub.status.idle":"2024-06-03T18:10:17.964044Z","shell.execute_reply.started":"2024-06-03T18:10:17.959378Z","shell.execute_reply":"2024-06-03T18:10:17.963130Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\n\n# Define the StratifiedShuffleSplit cross-validator\nsss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\n\n# Lists to store results\ntrain_accuracies = []\ntest_accuracies = []","metadata":{"execution":{"iopub.status.busy":"2024-06-03T18:10:21.268896Z","iopub.execute_input":"2024-06-03T18:10:21.269886Z","iopub.status.idle":"2024-06-03T18:10:21.274728Z","shell.execute_reply.started":"2024-06-03T18:10:21.269848Z","shell.execute_reply":"2024-06-03T18:10:21.273721Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"print(\"SVM Results\")\nfrom cuml.cluster import KMeans as cuKMeans  # Import cuML KMeans for GPU acceleration\n# Function to get the predominant class and its average record for each cluster\ndef get_representative_record(cluster_df):\n    # Get the predominant class\n    predominant_class = cluster_df['target'].mode()[0]\n    \n    # Filter records of the predominant class\n    predominant_class_records = cluster_df[cluster_df['target'] == predominant_class].drop(columns=['cluster', 'target'])\n    \n    # Compute the average record for the predominant class\n    representative_record = predominant_class_records.mean()\n    representative_record['target'] = predominant_class\n    \n    return representative_record\n  \n# Perform StratifiedShuffleSplit cross-validation\nfor train_index, test_index in sss.split(X, y):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    \n#     print(\"Before Kmean\")\n#     print(X_train.shape)\n    \n    # Apply KMeans clustering on the training set using cuML\n     # Define the number of clusters\n    kmeans = cuKMeans(n_clusters=10000)\n    kmeans.fit(X_train.values)  # Convert to NumPy array  <-- Change: Convert DataFrame to NumPy array\n\n    \n    X_train_clustered = X_train.copy()  # Avoid SettingWithCopyWarning by working on a copy\n    X_train_clustered['cluster'] = kmeans.labels_\n    X_train_clustered['target'] = y_train.values\n    \n    # Generate the reduced training dataset\n    reduced_train_data = X_train_clustered.groupby('cluster').apply(get_representative_record).reset_index(drop=True)\n    \n    # Prepare data for model training\n    X_train_reduced = reduced_train_data.drop(columns=['target']).values # Convert to NumPy array  <-- Change: Convert Series to NumPy array\n    y_train_reduced = reduced_train_data['target'].values # Convert to NumPy array  <-- Change: Convert Series to NumPy array\n    \n#     print(\"After kmean\")\n#     print(X_train_reduced.shape)\n    # Train the model on the reduced training set\n    model_2.fit(X_train_reduced, y_train_reduced)\n    \n    # Predict on the training set\n    y_train_pred = model_2.predict(X_train_reduced)\n    train_accuracy = accuracy_score(y_train_reduced, y_train_pred)\n    train_accuracies.append(train_accuracy)\n    \n    # Predict on the original test set\n    y_test_pred = model_2.predict(X_test.values) # Convert to NumPy array  <-- Change: Convert DataFrame to NumPy array\n    test_accuracy = accuracy_score(y_test, y_test_pred)\n    test_accuracies.append(test_accuracy)\n    \n    print(f'Fold model_2 training  accuracy for SVM: {train_accuracy:.4f}')\n    print(f'Fold model_2 test accuracy for SVM: {test_accuracy:.4f}')\n    print(\"---------------------------\")\n#     break\n    \n\n# Calculate the average accuracies\naverage_train_accuracy = np.mean(train_accuracies)\naverage_test_accuracy = np.mean(test_accuracies)\nprint(f'Average training accuracy for SVM: {average_train_accuracy:.4f}')\nprint(f'Average test accuracy for SVM: {average_test_accuracy:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-06-03T18:10:25.830973Z","iopub.execute_input":"2024-06-03T18:10:25.831600Z","iopub.status.idle":"2024-06-03T18:39:31.704003Z","shell.execute_reply.started":"2024-06-03T18:10:25.831569Z","shell.execute_reply":"2024-06-03T18:39:31.702850Z"},"trusted":true},"execution_count":93,"outputs":[{"name":"stdout","text":"SVM Results\nFold model_2 training  accuracy for SVM: 0.6307\nFold model_2 test accuracy for SVM: 0.5786\n---------------------------\nFold model_2 training  accuracy for SVM: 0.6305\nFold model_2 test accuracy for SVM: 0.5793\n---------------------------\nFold model_2 training  accuracy for SVM: 0.6351\nFold model_2 test accuracy for SVM: 0.5897\n---------------------------\nFold model_2 training  accuracy for SVM: 0.6272\nFold model_2 test accuracy for SVM: 0.5837\n---------------------------\nFold model_2 training  accuracy for SVM: 0.6331\nFold model_2 test accuracy for SVM: 0.5870\n---------------------------\nFold model_2 training  accuracy for SVM: 0.6341\nFold model_2 test accuracy for SVM: 0.5974\n---------------------------\nFold model_2 training  accuracy for SVM: 0.6277\nFold model_2 test accuracy for SVM: 0.5870\n---------------------------\nFold model_2 training  accuracy for SVM: 0.6300\nFold model_2 test accuracy for SVM: 0.5843\n---------------------------\nFold model_2 training  accuracy for SVM: 0.6292\nFold model_2 test accuracy for SVM: 0.5855\n---------------------------\nFold model_2 training  accuracy for SVM: 0.6301\nFold model_2 test accuracy for SVM: 0.5914\n---------------------------\nAverage training accuracy for SVM: 0.6308\nAverage test accuracy for SVM: 0.5864\n","output_type":"stream"}]},{"cell_type":"code","source":"print(f'Average training accuracy for SVM: {average_train_accuracy:.4f}')\nprint(f'Average test accuracy for SVM: {average_test_accuracy:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-05-19T15:50:04.799878Z","iopub.execute_input":"2024-05-19T15:50:04.800811Z","iopub.status.idle":"2024-05-19T15:50:04.805660Z","shell.execute_reply.started":"2024-05-19T15:50:04.800772Z","shell.execute_reply":"2024-05-19T15:50:04.804643Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Average training accuracy for SVM: 0.6302\nAverage test accuracy for SVM: 0.5861\n","output_type":"stream"}]},{"cell_type":"code","source":"                         ---------------------------First Model --------------------------------------","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#                            ----------------------Random Forest-----------------------","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.cluster import KMeans\nimport cudf\nimport cuml","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\n\n# Perform StratifiedShuffleSplit cross-validation\nsss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\ntrain_accuracies = []\ntest_accuracies = []","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:00:19.900058Z","iopub.execute_input":"2024-06-04T13:00:19.900478Z","iopub.status.idle":"2024-06-04T13:00:19.905849Z","shell.execute_reply.started":"2024-06-04T13:00:19.900446Z","shell.execute_reply":"2024-06-04T13:00:19.904742Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"model_1 = RandomForestClassifier(class_weight=\"balanced\",n_estimators=1000, max_depth = 9, min_samples_split=10,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:00:27.680071Z","iopub.execute_input":"2024-06-04T13:00:27.680486Z","iopub.status.idle":"2024-06-04T13:00:27.685759Z","shell.execute_reply.started":"2024-06-04T13:00:27.680454Z","shell.execute_reply":"2024-06-04T13:00:27.684670Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"\n# from cuml.ensemble import RandomForestClassifier as cuRFClassifier  # Import cuML RandomForest for GPU acceleration\nfrom cuml.cluster import KMeans as cuKMeans  # Import cuML KMeans for GPU acceleration\n\n# Function to get the predominant class and its average record for each cluster\ndef get_representative_record(cluster_df):\n    # Get the predominant class\n    predominant_class = cluster_df['target'].mode()[0]\n    \n    # Filter records of the predominant class\n    predominant_class_records = cluster_df[cluster_df['target'] == predominant_class].drop(columns=['cluster', 'target'])\n    \n    # Compute the average record for the predominant class\n    representative_record = predominant_class_records.mean()\n    representative_record['target'] = predominant_class\n    \n    return representative_record\n  \n# Perform StratifiedShuffleSplit cross-validation\nfor train_index, test_index in sss.split(X, y):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    \n    # Apply KMeans clustering on the training set using cuML\n     # Define the number of clusters\n    kmeans = cuKMeans(n_clusters=10000)\n    kmeans.fit(X_train.values)  # Convert to NumPy array  <-- Change: Convert DataFrame to NumPy array\n\n    X_train_clustered = X_train.copy()  # Avoid SettingWithCopyWarning by working on a copy\n    X_train_clustered['cluster'] = kmeans.labels_\n    X_train_clustered['target'] = y_train.values\n    \n    # Generate the reduced training dataset\n    reduced_train_data = X_train_clustered.groupby('cluster').apply(get_representative_record).reset_index(drop=True)\n    \n    # Prepare data for model training\n    X_train_reduced = reduced_train_data.drop(columns=['target']).values # Convert to NumPy array  <-- Change: Convert Series to NumPy array\n    y_train_reduced = reduced_train_data['target'].values # Convert to NumPy array  <-- Change: Convert Series to NumPy array\n    \n    # Train the model on the reduced training set\n    model_1.fit(X_train_reduced, y_train_reduced)\n    \n    # Predict on the training set\n    y_train_pred = model_1.predict(X_train_reduced)\n    train_accuracy = accuracy_score(y_train_reduced, y_train_pred)\n    train_accuracies.append(train_accuracy)\n    \n    # Predict on the original test set\n    y_test_pred = model_1.predict(X_test.values) # Convert to NumPy array  <-- Change: Convert DataFrame to NumPy array\n    test_accuracy = accuracy_score(y_test, y_test_pred)\n    test_accuracies.append(test_accuracy)\n    \n    print(f'Fold training accuracy for Random Forest : {train_accuracy:.4f}')\n    print(f'Fold test accuracy for Random Forest: {test_accuracy:.4f}')\n    print(\"------------------------------\")\n#     break\n    \n# Calculate the average accuracies\naverage_train_accuracy = np.mean(train_accuracies)\naverage_test_accuracy = np.mean(test_accuracies)\nprint(f'Average training accuracy for RF: {average_train_accuracy:.4f}')\nprint(f'Average test accuracy for RF: {average_test_accuracy:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-06-04T13:00:37.252271Z","iopub.execute_input":"2024-06-04T13:00:37.253348Z","iopub.status.idle":"2024-06-04T13:34:46.687291Z","shell.execute_reply.started":"2024-06-04T13:00:37.253293Z","shell.execute_reply":"2024-06-04T13:34:46.686209Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Fold training accuracy for Random Forest : 0.9068\nFold test accuracy for Random Forest: 0.7662\n------------------------------\nFold training accuracy for Random Forest : 0.9072\nFold test accuracy for Random Forest: 0.7540\n------------------------------\nFold training accuracy for Random Forest : 0.9059\nFold test accuracy for Random Forest: 0.7692\n------------------------------\nFold training accuracy for Random Forest : 0.9011\nFold test accuracy for Random Forest: 0.7544\n------------------------------\nFold training accuracy for Random Forest : 0.9031\nFold test accuracy for Random Forest: 0.7547\n------------------------------\nFold training accuracy for Random Forest : 0.9060\nFold test accuracy for Random Forest: 0.7549\n------------------------------\nFold training accuracy for Random Forest : 0.9057\nFold test accuracy for Random Forest: 0.7571\n------------------------------\nFold training accuracy for Random Forest : 0.9072\nFold test accuracy for Random Forest: 0.7496\n------------------------------\nFold training accuracy for Random Forest : 0.9086\nFold test accuracy for Random Forest: 0.7732\n------------------------------\nFold training accuracy for Random Forest : 0.9054\nFold test accuracy for Random Forest: 0.7742\n------------------------------\nAverage training accuracy for RF: 0.9057\nAverage test accuracy for RF: 0.7608\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#                  -------------------------------------------End---------------------------------------------------------------------","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# modeltr =RandomForestClassifier(n_estimators=1000, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T03:31:50.822014Z","iopub.execute_input":"2024-05-19T03:31:50.822865Z","iopub.status.idle":"2024-05-19T03:31:50.828365Z","shell.execute_reply.started":"2024-05-19T03:31:50.822830Z","shell.execute_reply":"2024-05-19T03:31:50.827436Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"\n# # from cuml.ensemble import RandomForestClassifier as cuRFClassifier  # Import cuML RandomForest for GPU acceleration\n# from cuml.cluster import KMeans as cuKMeans  # Import cuML KMeans for GPU acceleration\n\n# # model = cuRFClassifier(n_estimators=100, max_depth = 6, min_samples_split=5)\n# model = model = RandomForestClassifier(n_estimators=100,max_depth = 6,min_samples_split=5)\n# # (n_estimators=100, max_depth = 6, min_samples_split=5)\n\n# # Function to get the predominant class and its average record for each cluster\n# def get_representative_record(cluster_df):\n#     # Get the predominant class\n#     predominant_class = cluster_df['target'].mode()[0]\n    \n#     # Filter records of the predominant class\n#     predominant_class_records = cluster_df[cluster_df['target'] == predominant_class].drop(columns=['cluster', 'target'])\n    \n#     # Compute the average record for the predominant class\n#     representative_record = predominant_class_records.mean()\n#     representative_record['target'] = predominant_class\n    \n#     return representative_record\n  \n# # Perform StratifiedShuffleSplit cross-validation\n# for train_index, test_index in sss.split(X, y):\n#     X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n#     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    \n#     print(\"Before Kmean\")\n    \n#     # Apply KMeans clustering on the training set using cuML\n#      # Define the number of clusters\n#     kmeans = cuKMeans(n_clusters=10000)\n#     kmeans.fit(X_train.values)  # Convert to NumPy array  <-- Change: Convert DataFrame to NumPy array\n    \n# #     # Create a DataFrame with cluster labels\n# #     X_train_clustered = X_train.copy()  # Avoid SettingWithCopyWarning by working on a copy\n# #     X_train_clustered.loc[:, 'cluster'] = kmeans.labels_\n# #     X_train_clustered.loc[:, 'target'] = y_train.values\n    \n#     X_train_clustered = X_train.copy()  # Avoid SettingWithCopyWarning by working on a copy\n#     X_train_clustered['cluster'] = kmeans.labels_\n#     X_train_clustered['target'] = y_train.values\n    \n#     # Generate the reduced training dataset\n#     reduced_train_data = X_train_clustered.groupby('cluster').apply(get_representative_record).reset_index(drop=True)\n    \n#     # Prepare data for model training\n#     X_train_reduced = reduced_train_data.drop(columns=['target']).values # Convert to NumPy array  <-- Change: Convert Series to NumPy array\n#     y_train_reduced = reduced_train_data['target'].values # Convert to NumPy array  <-- Change: Convert Series to NumPy array\n    \n#     print(\"After kmean\")\n#     print(X_train_reduced.shape)\n#     # Train the model on the reduced training set\n#     modeltr.fit(X_train_reduced, y_train_reduced)\n    \n#     # Predict on the training set\n#     y_train_pred = modeltr.predict(X_train_reduced)\n#     train_accuracy = accuracy_score(y_train_reduced, y_train_pred)\n#     train_accuracies.append(train_accuracy)\n    \n#     # Predict on the original test set\n#     y_test_pred = modeltr.predict(X_test.values) # Convert to NumPy array  <-- Change: Convert DataFrame to NumPy array\n#     test_accuracy = accuracy_score(y_test, y_test_pred)\n#     test_accuracies.append(test_accuracy)\n    \n#     print(f'Fold training accuracy : {train_accuracy:.4f}')\n#     print(f'Fold test accuracy: {test_accuracy:.4f}')\n    \n    \n\n# # Calculate the average accuracies\n# average_train_accuracy = np.mean(train_accuracies)\n# average_test_accuracy = np.mean(test_accuracies)\n# print(f'Average training accuracy: {average_train_accuracy:.4f}')\n# print(f'Average test accuracy: {average_test_accuracy:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T04:01:18.175270Z","iopub.execute_input":"2024-05-19T04:01:18.175624Z","iopub.status.idle":"2024-05-19T04:37:37.079628Z","shell.execute_reply.started":"2024-05-19T04:01:18.175597Z","shell.execute_reply":"2024-05-19T04:37:37.078569Z"},"trusted":true},"execution_count":99,"outputs":[{"name":"stdout","text":"Before Kmean\nAfter kmean\n(10000, 33)\nFold training accuracy : 1.0000\nFold test accuracy: 0.8556\nBefore Kmean\nAfter kmean\n(10000, 33)\nFold training accuracy : 1.0000\nFold test accuracy: 0.8587\nBefore Kmean\nAfter kmean\n(10000, 33)\nFold training accuracy : 1.0000\nFold test accuracy: 0.8495\nBefore Kmean\nAfter kmean\n(10000, 33)\nFold training accuracy : 1.0000\nFold test accuracy: 0.8545\nBefore Kmean\nAfter kmean\n(10000, 33)\nFold training accuracy : 1.0000\nFold test accuracy: 0.8591\nBefore Kmean\nAfter kmean\n(10000, 33)\nFold training accuracy : 1.0000\nFold test accuracy: 0.8555\nBefore Kmean\nAfter kmean\n(10000, 33)\nFold training accuracy : 1.0000\nFold test accuracy: 0.8568\nBefore Kmean\nAfter kmean\n(10000, 33)\nFold training accuracy : 1.0000\nFold test accuracy: 0.8617\nBefore Kmean\nAfter kmean\n(10000, 33)\nFold training accuracy : 1.0000\nFold test accuracy: 0.8554\nBefore Kmean\nAfter kmean\n(10000, 33)\nFold training accuracy : 1.0000\nFold test accuracy: 0.8529\nAverage training accuracy: 0.9464\nAverage test accuracy: 0.5837\n","output_type":"stream"}]},{"cell_type":"code","source":"#                             2nd att","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.cluster import KMeans","metadata":{"execution":{"iopub.status.busy":"2024-05-29T14:51:23.428758Z","iopub.execute_input":"2024-05-29T14:51:23.429121Z","iopub.status.idle":"2024-05-29T14:51:23.435599Z","shell.execute_reply.started":"2024-05-29T14:51:23.429092Z","shell.execute_reply":"2024-05-29T14:51:23.434597Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Perform StratifiedShuffleSplit cross-validation\nsss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\ntrain_accuracies = []\ntest_accuracies = []","metadata":{"execution":{"iopub.status.busy":"2024-05-29T14:51:54.554701Z","iopub.execute_input":"2024-05-29T14:51:54.555074Z","iopub.status.idle":"2024-05-29T14:51:54.561135Z","shell.execute_reply.started":"2024-05-29T14:51:54.555043Z","shell.execute_reply":"2024-05-29T14:51:54.560040Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# import pandas as pd\n# from sklearn.model_selection import StratifiedShuffleSplit\n# from sklearn.ensemble import RandomForestClassifier\n# from sklearn.metrics import accuracy_score\n# from sklearn.cluster import KMeans\n\n\n# from cuml.ensemble import RandomForestClassifier as cuRFClassifier  # Import cuML RandomForest for GPU acceleration\nfrom cuml.cluster import KMeans as cuKMeans  # Import cuML KMeans for GPU acceleration\n\n# model = cuRFClassifier(n_estimators=100, max_depth = 6, min_samples_split=5)\n\n# (n_estimators=100, max_depth = 6, min_samples_split=5)\n\n# Function to get the predominant class and its average record for each cluster\ndef get_representative_record(cluster_df):\n    # Get the predominant class\n    predominant_class = cluster_df['target'].mode()[0]\n    \n    # Filter records of the predominant class\n    predominant_class_records = cluster_df[cluster_df['target'] == predominant_class].drop(columns=['cluster', 'target'])\n    \n    # Compute the average record for the predominant class\n    representative_record = predominant_class_records.mean()\n    representative_record['target'] = predominant_class\n    \n    return representative_record\n\n# model_1 = RandomForestClassifier( n_estimators=1000)\nmodel_1 = RandomForestClassifier(  class_weight=\"balanced\", \n    n_estimators=100, \n#     max_depth=6, \n    min_samples_split=10, \n    random_state=42\n)\n\n\n  \n# Perform StratifiedShuffleSplit cross-validation\nfor train_index, test_index in sss.split(X, y):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    \n#     print(\"----------------------------------\")\n    \n    # Apply KMeans clustering on the training set using cuML\n     # Define the number of clusters\n    kmeans = cuKMeans(n_clusters=10000)\n    kmeans.fit(X_train.values)  # Convert to NumPy array  <-- Change: Convert DataFrame to NumPy array\n\n    X_train_clustered = X_train.copy()  # Avoid SettingWithCopyWarning by working on a copy\n    X_train_clustered['cluster'] = kmeans.labels_\n    X_train_clustered['target'] = y_train.values\n    \n    # Generate the reduced training dataset\n    reduced_train_data = X_train_clustered.groupby('cluster').apply(get_representative_record).reset_index(drop=True)\n    \n    # Prepare data for model training\n    X_train_reduced = reduced_train_data.drop(columns=['target']).values # Convert to NumPy array  <-- Change: Convert Series to NumPy array\n    y_train_reduced = reduced_train_data['target'].values # Convert to NumPy array  <-- Change: Convert Series to NumPy array\n    \n#     print(\"After kmean\")\n#     print(X_train_reduced.shape)\n    \n    # Train the model on the reduced training set\n    model_1.fit(X_train_reduced, y_train_reduced)\n    \n    # Predict on the training set\n    y_train_pred = model_1.predict(X_train_reduced)\n    train_accuracy = accuracy_score(y_train_reduced, y_train_pred)\n    train_accuracies.append(train_accuracy)\n    \n    # Predict on the original test set\n    y_test_pred = model_1.predict(X_test.values) # Convert to NumPy array  <-- Change: Convert DataFrame to NumPy array\n    test_accuracy = accuracy_score(y_test, y_test_pred)\n    test_accuracies.append(test_accuracy)\n    \n    print(f'Fold training accuracy for Random Forest : {train_accuracy:.4f}')\n    print(f'Fold test accuracy for Random Forest: {test_accuracy:.4f}')\n    print(\"------------------------------\")\n#     break\n    \n\n# Calculate the average accuracies\naverage_train_accuracy = np.mean(train_accuracies)\naverage_test_accuracy = np.mean(test_accuracies)\nprint(f'Average training accuracy for Random Forest : {average_train_accuracy:.4f}')\nprint(f'Average test accuracy for Random Forest: {average_test_accuracy:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-01T08:04:39.349377Z","iopub.execute_input":"2024-06-01T08:04:39.349746Z","iopub.status.idle":"2024-06-01T08:31:47.429467Z","shell.execute_reply.started":"2024-06-01T08:04:39.349717Z","shell.execute_reply":"2024-06-01T08:31:47.428550Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Fold training accuracy for Random Forest : 0.9992\nFold test accuracy for Random Forest: 0.8246\n------------------------------\nFold training accuracy for Random Forest : 0.9996\nFold test accuracy for Random Forest: 0.8275\n------------------------------\nFold training accuracy for Random Forest : 0.9990\nFold test accuracy for Random Forest: 0.8284\n------------------------------\nFold training accuracy for Random Forest : 0.9993\nFold test accuracy for Random Forest: 0.8328\n------------------------------\nFold training accuracy for Random Forest : 0.9995\nFold test accuracy for Random Forest: 0.8270\n------------------------------\nFold training accuracy for Random Forest : 0.9989\nFold test accuracy for Random Forest: 0.8370\n------------------------------\nFold training accuracy for Random Forest : 0.9992\nFold test accuracy for Random Forest: 0.8257\n------------------------------\nFold training accuracy for Random Forest : 0.9992\nFold test accuracy for Random Forest: 0.8526\n------------------------------\nFold training accuracy for Random Forest : 0.9992\nFold test accuracy for Random Forest: 0.8469\n------------------------------\nFold training accuracy for Random Forest : 0.9994\nFold test accuracy for Random Forest: 0.8407\n------------------------------\nAverage training accuracy for Random Forest : 0.9992\nAverage test accuracy for Random Forest: 0.8343\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.cluster import KMeans\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:52:36.669252Z","iopub.execute_input":"2024-05-20T07:52:36.669881Z","iopub.status.idle":"2024-05-20T07:52:36.925687Z","shell.execute_reply.started":"2024-05-20T07:52:36.669846Z","shell.execute_reply":"2024-05-20T07:52:36.924711Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\n\n# Define the StratifiedShuffleSplit cross-validator\nsss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\n\n# Lists to store results\ntrain_accuracies = []\ntest_accuracies = []","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:53:25.819165Z","iopub.execute_input":"2024-05-20T07:53:25.820045Z","iopub.status.idle":"2024-05-20T07:53:25.824641Z","shell.execute_reply.started":"2024-05-20T07:53:25.820010Z","shell.execute_reply":"2024-05-20T07:53:25.823731Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"modeltr =RandomForestClassifier(n_estimators=1000,max_depth = 6)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T07:54:05.577592Z","iopub.execute_input":"2024-05-20T07:54:05.577986Z","iopub.status.idle":"2024-05-20T07:54:05.582743Z","shell.execute_reply.started":"2024-05-20T07:54:05.577952Z","shell.execute_reply":"2024-05-20T07:54:05.581723Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# modeltr =RandomForestClassifier(class_weight=\"balanced\",n_estimators=1000,max_depth = 6,min_samples_split=5 ) random_state=42","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:32:25.243829Z","iopub.execute_input":"2024-05-19T05:32:25.244229Z","iopub.status.idle":"2024-05-19T05:32:25.250405Z","shell.execute_reply.started":"2024-05-19T05:32:25.244199Z","shell.execute_reply":"2024-05-19T05:32:25.249489Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"\n# from cuml.ensemble import RandomForestClassifier as cuRFClassifier  # Import cuML RandomForest for GPU acceleration\nfrom cuml.cluster import KMeans as cuKMeans  # Import cuML KMeans for GPU acceleration\n\n# model = cuRFClassifier(n_estimators=100, max_depth = 6, min_samples_split=5)\nmodeltr = RandomForestClassifier(n_estimators=1000,max_depth = 3,min_samples_split=5)\n# (n_estimators=100, max_depth = 6, min_samples_split=5)\nprint(\"before loop\")\n\n# Function to get the predominant class and its average record for each cluster\ndef get_representative_record(cluster_df):\n    # Get the predominant class\n    predominant_class = cluster_df['target'].mode()[0]\n    \n    # Filter records of the predominant class\n    predominant_class_records = cluster_df[cluster_df['target'] == predominant_class].drop(columns=['cluster', 'target'])\n    \n    # Compute the average record for the predominant class\n    representative_record = predominant_class_records.mean()\n    representative_record['target'] = predominant_class\n    \n    return representative_record\n  \n# Perform StratifiedShuffleSplit cross-validation\nfor train_index, test_index in sss.split(X, y):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    \n    print(\"Before Kmean\")\n    \n    # Apply KMeans clustering on the training set using cuML\n     # Define the number of clusters\n    kmeans = cuKMeans(n_clusters=10000,random_state=42)\n    kmeans.fit(X_train.values)  # Convert to NumPy array  <-- Change: Convert DataFrame to NumPy array\n    \n#     # Create a DataFrame with cluster labels\n#     X_train_clustered = X_train.copy()  # Avoid SettingWithCopyWarning by working on a copy\n#     X_train_clustered.loc[:, 'cluster'] = kmeans.labels_\n#     X_train_clustered.loc[:, 'target'] = y_train.values\n    \n    X_train_clustered = X_train.copy()  # Avoid SettingWithCopyWarning by working on a copy\n    X_train_clustered['cluster'] = kmeans.labels_\n    X_train_clustered['target'] = y_train.values\n    \n    # Generate the reduced training dataset\n    reduced_train_data = X_train_clustered.groupby('cluster').apply(get_representative_record).reset_index(drop=True)\n    \n    # Prepare data for model training\n    X_train_reduced = reduced_train_data.drop(columns=['target']).values # Convert to NumPy array  <-- Change: Convert Series to NumPy array\n    y_train_reduced = reduced_train_data['target'].values # Convert to NumPy array  <-- Change: Convert Series to NumPy array\n    \n    print(\"After kmean\")\n    print(X_train_reduced.shape)\n    # Train the model on the reduced training set\n    modeltr.fit(X_train_reduced, y_train_reduced)\n    \n    # Predict on the training set\n    y_train_pred = modeltr.predict(X_train_reduced)\n    train_accuracy = accuracy_score(y_train_reduced, y_train_pred)\n#     train_accuracies.append(train_accuracy)\n    \n    # Predict on the original test set\n    y_test_pred = modeltr.predict(X_test.values) # Convert to NumPy array  <-- Change: Convert DataFrame to NumPy array\n    test_accuracy = accuracy_score(y_test, y_test_pred)\n#     test_accuracies.append(test_accuracy)\n    \n    print(f'Fold training accuracy : {train_accuracy:.2f}')\n    print(f'Fold test accuracy: {test_accuracy:.2f}')\n    break\n    \n    \n\n# Calculate the average accuracies\n# average_train_accuracy = np.mean(train_accuracies)\n# average_test_accuracy = np.mean(test_accuracies)\n# print(f'Average training accuracy: {average_train_accuracy:.4f}')\n# print(f'Average test accuracy: {average_test_accuracy:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-20T08:24:18.435431Z","iopub.execute_input":"2024-05-20T08:24:18.436385Z","iopub.status.idle":"2024-05-20T08:27:17.893710Z","shell.execute_reply.started":"2024-05-20T08:24:18.436348Z","shell.execute_reply":"2024-05-20T08:27:17.892788Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"before loop\nBefore Kmean\nAfter kmean\n(10000, 33)\nFold training accuracy : 0.47\nFold test accuracy: 0.51\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\n# Function to get the predominant class and its average record for each cluster\ndef get_representative_record(cluster_df):\n    # Get the predominant class\n    predominant_class = cluster_df['target'].mode()[0]\n    \n    # Filter records of the predominant class\n    predominant_class_records = cluster_df[cluster_df['target'] == predominant_class].drop(columns=['cluster', 'target'])\n    \n    # Compute the average record for the predominant class\n    representative_record = predominant_class_records.mean()\n    representative_record['target'] = predominant_class\n    \n    return representative_record\n  \n# Perform StratifiedShuffleSplit cross-validation\nfor train_index, test_index in sss.split(X, y):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    \n    print(\"Before Kmean\")\n    print(X_train.shape)\n    \n    # Apply KMeans clustering on the training set using cuML\n     # Define the number of clusters\n    kmeans = cuKMeans(n_clusters=10000)\n    kmeans.fit(X_train.values)  # Convert to NumPy array  <-- Change: Convert DataFrame to NumPy array\n    \n#     # Create a DataFrame with cluster labels\n#     X_train_clustered = X_train.copy()  # Avoid SettingWithCopyWarning by working on a copy\n#     X_train_clustered.loc[:, 'cluster'] = kmeans.labels_\n#     X_train_clustered.loc[:, 'target'] = y_train.values\n    \n    X_train_clustered = X_train.copy()  # Avoid SettingWithCopyWarning by working on a copy\n    X_train_clustered['cluster'] = kmeans.labels_\n    X_train_clustered['target'] = y_train.values\n    \n    # Generate the reduced training dataset\n    reduced_train_data = X_train_clustered.groupby('cluster').apply(get_representative_record).reset_index(drop=True)\n    \n    # Prepare data for model training\n    X_train_reduced = reduced_train_data.drop(columns=['target']).values # Convert to NumPy array  <-- Change: Convert Series to NumPy array\n    y_train_reduced = reduced_train_data['target'].values # Convert to NumPy array  <-- Change: Convert Series to NumPy array\n    \n    print(\"After kmean\")\n    print(X_train_reduced.shape)\n    # Train the model on the reduced training set\n    modeltr.fit(X_train_reduced, y_train_reduced)\n    \n    # Predict on the training set\n    y_train_pred = modeltr.predict(X_train_reduced)\n    train_accuracy = accuracy_score(y_train_reduced, y_train_pred)\n    train_accuracies.append(train_accuracy)\n    \n    # Predict on the original test set\n    y_test_pred = modeltr.predict(X_test.values) # Convert to NumPy array  <-- Change: Convert DataFrame to NumPy array\n    test_accuracy = accuracy_score(y_test, y_test_pred)\n    test_accuracies.append(test_accuracy)\n    \n    print(f'Fold training accuracy : {train_accuracy:.4f}')\n    print(f'Fold test accuracy: {test_accuracy:.4f}')\n    break","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:42:01.663298Z","iopub.execute_input":"2024-05-19T05:42:01.664256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# conda install -c rapidsai -c nvidia -c conda-forge cuml=21.06 python=3.8 cudatoolkit=11.0\n","metadata":{"execution":{"iopub.status.busy":"2024-06-01T13:32:55.132223Z","iopub.execute_input":"2024-06-01T13:32:55.132484Z","iopub.status.idle":"2024-06-01T13:32:55.140440Z","shell.execute_reply.started":"2024-06-01T13:32:55.132460Z","shell.execute_reply":"2024-06-01T13:32:55.139560Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from cuml.cluster import KMeans as cuKMeans  # Import cuML KMeans for GPU acceleration\n","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:31:13.216847Z","iopub.execute_input":"2024-05-18T23:31:13.217249Z","iopub.status.idle":"2024-05-18T23:31:15.894702Z","shell.execute_reply.started":"2024-05-18T23:31:13.217214Z","shell.execute_reply":"2024-05-18T23:31:15.893886Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Function to get the predominant class and its average record for each cluster\ndef get_representative_record(cluster_df):\n    # Get the predominant class\n    predominant_class = cluster_df['target'].mode()[0]\n    \n    # Filter records of the predominant class\n    predominant_class_records = cluster_df[cluster_df['target'] == predominant_class].drop(columns=['cluster', 'target'])\n    \n    # Compute the average record for the predominant class\n    representative_record = predominant_class_records.mean()\n    representative_record['target'] = predominant_class\n    \n    return representative_record\n\n# Perform StratifiedShuffleSplit cross-validation\nfor train_index, test_index in sss.split(X, y):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    \n    # Apply KMeans clustering on the training set using cuML\n    n_clusters = 100  # Define the number of clusters\n    kmeans = cuKMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n    kmeans.fit(X_train)\n    \n    # Create a DataFrame with cluster labels\n    X_train = X_train.copy()  # Avoid SettingWithCopyWarning by working on a copy\n    X_train.loc[:, 'cluster'] = kmeans.labels_\n    X_train.loc[:, 'target'] = y_train.values\n    \n    # Generate the reduced training dataset\n    reduced_train_data = X_train.groupby('cluster').apply(get_representative_record).reset_index(drop=True)\n    \n    # Prepare data for model training\n    X_train_reduced = reduced_train_data.drop(columns=['target'])\n    y_train_reduced = reduced_train_data['target']\n    \n    # Train the model on the reduced training set\n    model.fit(X_train_reduced, y_train_reduced)\n    \n    # Predict on the training set\n    y_train_pred = model.predict(X_train_reduced)\n    train_accuracy = accuracy_score(y_train_reduced, y_train_pred)\n    train_accuracies.append(train_accuracy)\n    \n    # Use KMeans to predict clusters for the test set and use those cluster centers\n    test_clusters = kmeans.predict(X_test)\n    X_test_clustered = pd.DataFrame(kmeans.cluster_centers_[test_clusters], columns=X_test.columns)\n    \n    # Predict on the test set using the clustered test data\n    y_test_pred = model.predict(X_test_clustered)\n    test_accuracy = accuracy_score(y_test, y_test_pred)\n    test_accuracies.append(test_accuracy)\n    \n    print(f'Fold training accuracy: {train_accuracy:.4f}')\n    print(f'Fold test accuracy: {test_accuracy:.4f}')\n\n# Calculate the average accuracies\naverage_train_accuracy = np.mean(train_accuracies)\naverage_test_accuracy = np.mean(test_accuracies)\nprint(f'Average training accuracy: {average_train_accuracy:.4f}')\nprint(f'Average test accuracy: {average_test_accuracy:.4f}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Using SVM algorithm\nfrom sklearn.metrics import accuracy_score\n# import numpy as np\nfrom sklearn.svm import SVC\n","metadata":{"execution":{"iopub.status.busy":"2024-05-18T21:20:31.381099Z","iopub.execute_input":"2024-05-18T21:20:31.381808Z","iopub.status.idle":"2024-05-18T21:20:31.386056Z","shell.execute_reply.started":"2024-05-18T21:20:31.381774Z","shell.execute_reply":"2024-05-18T21:20:31.385108Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# Define the model\nmodel2  = SVC(kernel='linear', C=1.0,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T21:20:50.066733Z","iopub.execute_input":"2024-05-18T21:20:50.067345Z","iopub.status.idle":"2024-05-18T21:20:50.071681Z","shell.execute_reply.started":"2024-05-18T21:20:50.067310Z","shell.execute_reply":"2024-05-18T21:20:50.070677Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\n# Define the StratifiedShuffleSplit cross-validator\nsss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=42)\n\n# Lists to store results\ntrain_accuracies = []\ntest_accuracies = []","metadata":{"execution":{"iopub.status.busy":"2024-05-18T21:21:29.059536Z","iopub.execute_input":"2024-05-18T21:21:29.059874Z","iopub.status.idle":"2024-05-18T21:21:29.064898Z","shell.execute_reply.started":"2024-05-18T21:21:29.059849Z","shell.execute_reply":"2024-05-18T21:21:29.063754Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3.*******************************  AdaBoost Algorithm  ****************************88","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 3: Initialize the base estimator (Decision Tree)\nbase_estimator = DecisionTreeClassifier()  # You can adjust max_depth\n# Step 4: Initialize the AdaBoost Classifier\nmodel = AdaBoostClassifier(base_estimator=base_estimator)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for train_index, test_index in sss.split(X, y):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    \n    # Apply KMeans clustering\n    kmeans = KMeans(n_clusters=100, random_state=42)\n    kmeans.fit(X_train)\n    \n    # Add cluster labels as a new feature to the training and test sets\n    X_train_clustered = pd.concat([X_train.reset_index(drop=True), pd.Series(kmeans.labels_, name='cluster')], axis=1)\n    X_test_clustered = pd.concat([X_test.reset_index(drop=True), pd.Series(kmeans.predict(X_test), name='cluster')], axis=1)\n    \n    # Train the model\n    model.fit(X_train_clustered, y_train)\n    \n    # Predict on the training set\n    y_train_pred = model.predict(X_train_clustered)\n    train_accuracy = accuracy_score(y_train, y_train_pred)\n    train_accuracies.append(train_accuracy)\n    \n    # Predict on the test set\n    y_test_pred = model.predict(X_test_clustered)\n    test_accuracy = accuracy_score(y_test, y_test_pred)\n    test_accuracies.append(test_accuracy)\n    \n    print(f'Fold training accuracy: {train_accuracy:.4f}')\n    print(f'Fold test accuracy: {test_accuracy:.4f}')\n\n# Calculate the average accuracies\naverage_train_accuracy = np.mean(train_accuracies)\naverage_test_accuracy = np.mean(test_accuracies)\nprint(f'Average training accuracy: {average_train_accuracy:.4f}')\nprint(f'Average test accuracy: {average_test_accuracy:.4f}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#   Using cuda \n\n\n\n# Perform StratifiedShuffleSplit cross-validation\nfor train_index, test_index in sss.split(X, y):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    \n#     print(X_train.shape)\n#     print(X_test.shape)\n\n # Convert pandas DataFrame to cudf DataFrame\n    X_train_cudf = cudf.DataFrame.from_pandas(X_train)\n    X_test_cudf = cudf.DataFrame.from_pandas(X_test)\n\n     # Apply KMeans clustering    \n    kmeans = cuml.KMeans(n_clusters=1000, random_state=42,n_init=10)\n    kmeans.fit(X_train_cudf)\n#     kmeans.fit(X_train)\n    \n#      # Add cluster labels as a new feature to the training and test sets\n#     X_train_clustered = np.hstack((X_train, kmeans.labels_.reshape(-1, 1)))\n#     X_test_clustered = np.hstack((X_test, kmeans.predict(X_test).reshape(-1, 1)))\n    \n         # Add cluster labels as a new feature to the training and test sets\nX_train_clustered = pd.concat([X_train.reset_index(drop=True), pd.Series(kmeans.labels_, name='cluster')], axis=1)\n    X_test_clustered = pd.concat([X_test.reset_index(drop=True), pd.Series(kmeans.predict(X_test), name='cluster')], axis=1)\n    \n    \n    # Train the model\n    model.fit(X_train_clustered, y_train)\n    \n     \n    # Predict on the training set\n    y_train_pred = model.predict(X_train_clustered)\n    train_accuracy = accuracy_score(y_train, y_train_pred)\n    train_percent=train_accuracy*100\n    train_accuracies.append(train_accuracy)\n    \n    # Predict on the test set\n    y_test_pred = model.predict(X_test_clustered)\n    test_accuracy = accuracy_score(y_test, y_test_pred)\n    test_percent=test_accuracy*100\n    test_accuracies.append(test_accuracy)\n    \n    print(f'Fold training accuracy: {train_percent:.2f}%')\n    print(f'Fold test accuracy: {test_percent:.2f}%')\n    \n# Calculate the average accuracies\naverage_train_accuracy = np.mean(train_accuracies)\naverage_test_accuracy = np.mean(test_accuracies)\nprint(f'Average training accuracy: {average_train_accuracy:.4f}')\nprint(f'Average test accuracy: {average_test_accuracy:.4f}')\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-05-18T14:25:30.187704Z","iopub.execute_input":"2024-05-18T14:25:30.188653Z","iopub.status.idle":"2024-05-18T14:25:30.436922Z","shell.execute_reply.started":"2024-05-18T14:25:30.188616Z","shell.execute_reply":"2024-05-18T14:25:30.435506Z"},"trusted":true},"execution_count":33,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndentationError\u001b[0m                          Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/compilerop.py:86\u001b[0m, in \u001b[0;36mCachingCompiler.ast_parse\u001b[0;34m(self, source, filename, symbol)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mast_parse\u001b[39m(\u001b[38;5;28mself\u001b[39m, source, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<unknown>\u001b[39m\u001b[38;5;124m'\u001b[39m, symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexec\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     82\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Parse code to an AST with the current compiler flags active.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    Arguments are exactly the same as ast.parse (in the standard library),\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    and are passed to the built-in compile function.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mPyCF_ONLY_AST\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n","\u001b[0;31mIndentationError\u001b[0m: unexpected indent (855458921.py, line 24)"],"ename":"IndentationError","evalue":"unexpected indent (855458921.py, line 24)","output_type":"error"}]},{"cell_type":"code","source":"# Perform StratifiedShuffleSplit cross-validation\nfor train_index, test_index in sss.split(X, y):\n    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n    \n    print(X_train.shape)\n    print(X_test.shape)\n#      # Apply KMeans clustering\n#     kmeans = KMeans(n_clusters=100, random_state=42,n_init=10)\n#     kmeans.fit(X_train)\n    \n# #      # Add cluster labels as a new feature to the training and test sets\n# #     X_train_clustered = np.hstack((X_train, kmeans.labels_.reshape(-1, 1)))\n# #     X_test_clustered = np.hstack((X_test, kmeans.predict(X_test).reshape(-1, 1)))\n    \n#      # Add cluster labels as a new feature to the training and test sets\n#     X_train_clustered = pd.concat([X_train.reset_index(drop=True), pd.Series(kmeans.labels_, name='cluster')], axis=1)\n#     X_test_clustered = pd.concat([X_test.reset_index(drop=True), pd.Series(kmeans.predict(X_test), name='cluster')], axis=1)\n    \n    \n#     # Train the model\n#     model.fit(X_train_clustered, y_train)\n    \n     \n#     # Predict on the training set\n#     y_train_pred = model.predict(X_train_clustered)\n#     train_accuracy = accuracy_score(y_train, y_train_pred)\n#     train_percent=train_accuracy*100\n#     train_accuracies.append(train_accuracy)\n    \n#     # Predict on the test set\n#     y_test_pred = model.predict(X_test_clustered)\n#     test_accuracy = accuracy_score(y_test, y_test_pred)\n#     test_percent=test_accuracy*100\n#     test_accuracies.append(test_accuracy)\n    \n#     print(f'Fold training accuracy: {train_percent:.2f}%')\n#     print(f'Fold test accuracy: {test_percent:.2f}%')\n    \n# # Calculate the average accuracies\n# average_train_accuracy = np.mean(train_accuracies)\n# average_test_accuracy = np.mean(test_accuracies)\n# print(f'Average training accuracy: {average_train_accuracy:.4f}')\n# print(f'Average test accuracy: {average_test_accuracy:.4f}')\n    \n    \n    \n","metadata":{"execution":{"iopub.status.busy":"2024-05-18T12:40:22.948447Z","iopub.execute_input":"2024-05-18T12:40:22.948858Z","iopub.status.idle":"2024-05-18T12:40:24.197017Z","shell.execute_reply.started":"2024-05-18T12:40:22.948810Z","shell.execute_reply":"2024-05-18T12:40:24.196055Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"(180000, 33)\n(20000, 33)\n(180000, 33)\n(20000, 33)\n(180000, 33)\n(20000, 33)\n(180000, 33)\n(20000, 33)\n(180000, 33)\n(20000, 33)\n(180000, 33)\n(20000, 33)\n(180000, 33)\n(20000, 33)\n(180000, 33)\n(20000, 33)\n(180000, 33)\n(20000, 33)\n(180000, 33)\n(20000, 33)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:02:40.446329Z","iopub.execute_input":"2023-12-18T16:02:40.447014Z","iopub.status.idle":"2023-12-18T16:02:40.450930Z","shell.execute_reply.started":"2023-12-18T16:02:40.446987Z","shell.execute_reply":"2023-12-18T16:02:40.450085Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# test=pd.read_csv('/kaggle/input/tabular-playground-series-feb-2022/test.csv')\n# test.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:03:25.167928Z","iopub.execute_input":"2023-12-18T16:03:25.168271Z","iopub.status.idle":"2023-12-18T16:03:25.172471Z","shell.execute_reply.started":"2023-12-18T16:03:25.168245Z","shell.execute_reply":"2023-12-18T16:03:25.171507Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# test.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:03:27.869813Z","iopub.execute_input":"2023-12-18T16:03:27.870152Z","iopub.status.idle":"2023-12-18T16:03:27.874193Z","shell.execute_reply.started":"2023-12-18T16:03:27.870124Z","shell.execute_reply":"2023-12-18T16:03:27.873267Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print(train.columns)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:03:33.457593Z","iopub.execute_input":"2023-12-18T16:03:33.457941Z","iopub.status.idle":"2023-12-18T16:03:33.462872Z","shell.execute_reply.started":"2023-12-18T16:03:33.457915Z","shell.execute_reply":"2023-12-18T16:03:33.461897Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Index(['row_id', 'A0T0G0C10', 'A0T0G1C9', 'A0T0G2C8', 'A0T0G3C7', 'A0T0G4C6',\n       'A0T0G5C5', 'A0T0G6C4', 'A0T0G7C3', 'A0T0G8C2',\n       ...\n       'A8T0G1C1', 'A8T0G2C0', 'A8T1G0C1', 'A8T1G1C0', 'A8T2G0C0', 'A9T0G0C1',\n       'A9T0G1C0', 'A9T1G0C0', 'A10T0G0C0', 'target'],\n      dtype='object', length=288)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(train.target)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:03:37.167201Z","iopub.execute_input":"2023-12-18T16:03:37.167579Z","iopub.status.idle":"2023-12-18T16:03:37.174061Z","shell.execute_reply.started":"2023-12-18T16:03:37.167527Z","shell.execute_reply":"2023-12-18T16:03:37.173152Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"0           Streptococcus_pyogenes\n1              Salmonella_enterica\n2              Salmonella_enterica\n3              Salmonella_enterica\n4               Enterococcus_hirae\n                    ...           \n199995         Salmonella_enterica\n199996      Streptococcus_pyogenes\n199997    Streptococcus_pneumoniae\n199998       Staphylococcus_aureus\n199999       Klebsiella_pneumoniae\nName: target, Length: 200000, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"# from sklearn.decomposition import PCA","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.504054Z","iopub.status.idle":"2023-12-05T18:59:51.504796Z","shell.execute_reply.started":"2023-12-05T18:59:51.504613Z","shell.execute_reply":"2023-12-05T18:59:51.504635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_column.head","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:04:01.468438Z","iopub.execute_input":"2023-12-18T16:04:01.468840Z","iopub.status.idle":"2023-12-18T16:04:01.477735Z","shell.execute_reply.started":"2023-12-18T16:04:01.468811Z","shell.execute_reply":"2023-12-18T16:04:01.476483Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"<bound method NDFrame.head of 0           Streptococcus_pyogenes\n1              Salmonella_enterica\n2              Salmonella_enterica\n3              Salmonella_enterica\n4               Enterococcus_hirae\n                    ...           \n199995         Salmonella_enterica\n199996      Streptococcus_pyogenes\n199997    Streptococcus_pneumoniae\n199998       Staphylococcus_aureus\n199999       Klebsiella_pneumoniae\nName: target, Length: 200000, dtype: object>"},"metadata":{}}]},{"cell_type":"code","source":"# target_column.shape\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T10:45:29.434047Z","iopub.execute_input":"2023-12-18T10:45:29.434405Z","iopub.status.idle":"2023-12-18T10:45:29.440421Z","shell.execute_reply.started":"2023-12-18T10:45:29.434375Z","shell.execute_reply":"2023-12-18T10:45:29.439492Z"},"trusted":true},"execution_count":80,"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"(200000,)"},"metadata":{}}]},{"cell_type":"code","source":"# target_column_numpy = np.array(target_column)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T10:45:37.774084Z","iopub.execute_input":"2023-12-18T10:45:37.774939Z","iopub.status.idle":"2023-12-18T10:45:37.778833Z","shell.execute_reply.started":"2023-12-18T10:45:37.774903Z","shell.execute_reply":"2023-12-18T10:45:37.777799Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"# target_column_numpy","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:04:07.862626Z","iopub.execute_input":"2023-12-18T16:04:07.862989Z","iopub.status.idle":"2023-12-18T16:04:07.867060Z","shell.execute_reply.started":"2023-12-18T16:04:07.862960Z","shell.execute_reply":"2023-12-18T16:04:07.865932Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"\n\n# target_column = train['target']\ntrain=train.drop(columns=['target']) ","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:04:23.062529Z","iopub.execute_input":"2023-12-18T16:04:23.062896Z","iopub.status.idle":"2023-12-18T16:04:23.202954Z","shell.execute_reply.started":"2023-12-18T16:04:23.062869Z","shell.execute_reply":"2023-12-18T16:04:23.201892Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:04:26.852513Z","iopub.execute_input":"2023-12-18T16:04:26.853280Z","iopub.status.idle":"2023-12-18T16:04:26.910088Z","shell.execute_reply.started":"2023-12-18T16:04:26.853244Z","shell.execute_reply":"2023-12-18T16:04:26.909141Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"        row_id     A0T0G0C10      A0T0G1C9  A0T0G2C8  A0T0G3C7  A0T0G4C6  \\\n0            0 -9.536743e-07 -9.536743e-06 -0.000043 -0.000114 -0.000200   \n1            1 -9.536743e-07 -9.536743e-06 -0.000043  0.000886 -0.000200   \n2            2 -9.536743e-07 -1.536743e-06  0.000007  0.000129  0.000268   \n3            3  4.632568e-08 -5.536743e-06  0.000012  0.000245  0.000492   \n4            4 -9.536743e-07 -9.536743e-06 -0.000043 -0.000114 -0.000200   \n...        ...           ...           ...       ...       ...       ...   \n199995  199995 -9.536743e-07  4.632568e-07 -0.000003  0.000176  0.000350   \n199996  199996 -9.536743e-07 -9.536743e-06 -0.000043 -0.000114 -0.000200   \n199997  199997  4.632568e-08  1.463257e-06 -0.000005 -0.000031 -0.000019   \n199998  199998 -9.536743e-07 -9.536743e-06 -0.000043 -0.000114 -0.000200   \n199999  199999  1.046326e-06 -1.536743e-06  0.000069  0.000539  0.001329   \n\n        A0T0G5C5  A0T0G6C4  A0T0G7C3  A0T0G8C2  ...  A8T0G0C2  A8T0G1C1  \\\n0      -0.000240 -0.000200 -0.000114 -0.000043  ... -0.000043 -0.000086   \n1       0.000760 -0.000200 -0.000114 -0.000043  ... -0.000043 -0.000086   \n2       0.000270  0.000243  0.000125  0.000001  ...  0.000042  0.000084   \n3       0.000522  0.000396  0.000197 -0.000003  ...  0.000068  0.000151   \n4      -0.000240 -0.000200 -0.000114 -0.000043  ... -0.000043 -0.000086   \n...          ...       ...       ...       ...  ...       ...       ...   \n199995  0.000290  0.000200  0.000206 -0.000023  ...  0.000017  0.000124   \n199996 -0.000240 -0.000200 -0.000114 -0.000043  ... -0.000043 -0.000086   \n199997 -0.000037 -0.000037 -0.000015 -0.000005  ...  0.000028  0.000115   \n199998 -0.000240 -0.000200 -0.000114 -0.000043  ... -0.000043 -0.000086   \n199999  0.001657  0.001328  0.000520  0.000063  ...  0.000033  0.000065   \n\n        A8T0G2C0  A8T1G0C1  A8T1G1C0  A8T2G0C0      A9T0G0C1  A9T0G1C0  \\\n0      -0.000043 -0.000086 -0.000086 -0.000043 -9.536743e-06 -0.000010   \n1      -0.000043  0.000914  0.000914 -0.000043 -9.536743e-06 -0.000010   \n2       0.000048  0.000081  0.000106  0.000072  1.046326e-05  0.000008   \n3       0.000100  0.000180  0.000202  0.000153  2.146326e-05  0.000015   \n4      -0.000043 -0.000086 -0.000086 -0.000043 -9.536743e-06 -0.000010   \n...          ...       ...       ...       ...           ...       ...   \n199995  0.000057  0.000104  0.000144  0.000027  4.632568e-07  0.000060   \n199996 -0.000043  0.000914  0.000914 -0.000043 -9.536743e-06 -0.000010   \n199997  0.000131  0.000110  0.000213  0.000094  1.646326e-05  0.000035   \n199998 -0.000043  0.001914 -0.000086 -0.000043 -9.536743e-06 -0.000010   \n199999  0.000053  0.000082  0.000102  0.000078  1.446326e-05  0.000013   \n\n        A9T1G0C0     A10T0G0C0  \n0      -0.000010 -9.536743e-07  \n1      -0.000010 -9.536743e-07  \n2       0.000019  1.046326e-06  \n3       0.000046 -9.536743e-07  \n4      -0.000010 -9.536743e-07  \n...          ...           ...  \n199995  0.000020 -9.536743e-07  \n199996 -0.000010 -9.536743e-07  \n199997  0.000021  4.632568e-08  \n199998 -0.000010 -9.536743e-07  \n199999  0.000033 -9.536743e-07  \n\n[200000 rows x 287 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>A0T0G0C10</th>\n      <th>A0T0G1C9</th>\n      <th>A0T0G2C8</th>\n      <th>A0T0G3C7</th>\n      <th>A0T0G4C6</th>\n      <th>A0T0G5C5</th>\n      <th>A0T0G6C4</th>\n      <th>A0T0G7C3</th>\n      <th>A0T0G8C2</th>\n      <th>...</th>\n      <th>A8T0G0C2</th>\n      <th>A8T0G1C1</th>\n      <th>A8T0G2C0</th>\n      <th>A8T1G0C1</th>\n      <th>A8T1G1C0</th>\n      <th>A8T2G0C0</th>\n      <th>A9T0G0C1</th>\n      <th>A9T0G1C0</th>\n      <th>A9T1G0C0</th>\n      <th>A10T0G0C0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>-9.536743e-07</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000043</td>\n      <td>-0.000114</td>\n      <td>-0.000200</td>\n      <td>-0.000240</td>\n      <td>-0.000200</td>\n      <td>-0.000114</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000010</td>\n      <td>-0.000010</td>\n      <td>-9.536743e-07</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>-9.536743e-07</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000043</td>\n      <td>0.000886</td>\n      <td>-0.000200</td>\n      <td>0.000760</td>\n      <td>-0.000200</td>\n      <td>-0.000114</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>0.000914</td>\n      <td>0.000914</td>\n      <td>-0.000043</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000010</td>\n      <td>-0.000010</td>\n      <td>-9.536743e-07</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>-9.536743e-07</td>\n      <td>-1.536743e-06</td>\n      <td>0.000007</td>\n      <td>0.000129</td>\n      <td>0.000268</td>\n      <td>0.000270</td>\n      <td>0.000243</td>\n      <td>0.000125</td>\n      <td>0.000001</td>\n      <td>...</td>\n      <td>0.000042</td>\n      <td>0.000084</td>\n      <td>0.000048</td>\n      <td>0.000081</td>\n      <td>0.000106</td>\n      <td>0.000072</td>\n      <td>1.046326e-05</td>\n      <td>0.000008</td>\n      <td>0.000019</td>\n      <td>1.046326e-06</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>4.632568e-08</td>\n      <td>-5.536743e-06</td>\n      <td>0.000012</td>\n      <td>0.000245</td>\n      <td>0.000492</td>\n      <td>0.000522</td>\n      <td>0.000396</td>\n      <td>0.000197</td>\n      <td>-0.000003</td>\n      <td>...</td>\n      <td>0.000068</td>\n      <td>0.000151</td>\n      <td>0.000100</td>\n      <td>0.000180</td>\n      <td>0.000202</td>\n      <td>0.000153</td>\n      <td>2.146326e-05</td>\n      <td>0.000015</td>\n      <td>0.000046</td>\n      <td>-9.536743e-07</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>-9.536743e-07</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000043</td>\n      <td>-0.000114</td>\n      <td>-0.000200</td>\n      <td>-0.000240</td>\n      <td>-0.000200</td>\n      <td>-0.000114</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000010</td>\n      <td>-0.000010</td>\n      <td>-9.536743e-07</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>199995</th>\n      <td>199995</td>\n      <td>-9.536743e-07</td>\n      <td>4.632568e-07</td>\n      <td>-0.000003</td>\n      <td>0.000176</td>\n      <td>0.000350</td>\n      <td>0.000290</td>\n      <td>0.000200</td>\n      <td>0.000206</td>\n      <td>-0.000023</td>\n      <td>...</td>\n      <td>0.000017</td>\n      <td>0.000124</td>\n      <td>0.000057</td>\n      <td>0.000104</td>\n      <td>0.000144</td>\n      <td>0.000027</td>\n      <td>4.632568e-07</td>\n      <td>0.000060</td>\n      <td>0.000020</td>\n      <td>-9.536743e-07</td>\n    </tr>\n    <tr>\n      <th>199996</th>\n      <td>199996</td>\n      <td>-9.536743e-07</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000043</td>\n      <td>-0.000114</td>\n      <td>-0.000200</td>\n      <td>-0.000240</td>\n      <td>-0.000200</td>\n      <td>-0.000114</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>0.000914</td>\n      <td>0.000914</td>\n      <td>-0.000043</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000010</td>\n      <td>-0.000010</td>\n      <td>-9.536743e-07</td>\n    </tr>\n    <tr>\n      <th>199997</th>\n      <td>199997</td>\n      <td>4.632568e-08</td>\n      <td>1.463257e-06</td>\n      <td>-0.000005</td>\n      <td>-0.000031</td>\n      <td>-0.000019</td>\n      <td>-0.000037</td>\n      <td>-0.000037</td>\n      <td>-0.000015</td>\n      <td>-0.000005</td>\n      <td>...</td>\n      <td>0.000028</td>\n      <td>0.000115</td>\n      <td>0.000131</td>\n      <td>0.000110</td>\n      <td>0.000213</td>\n      <td>0.000094</td>\n      <td>1.646326e-05</td>\n      <td>0.000035</td>\n      <td>0.000021</td>\n      <td>4.632568e-08</td>\n    </tr>\n    <tr>\n      <th>199998</th>\n      <td>199998</td>\n      <td>-9.536743e-07</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000043</td>\n      <td>-0.000114</td>\n      <td>-0.000200</td>\n      <td>-0.000240</td>\n      <td>-0.000200</td>\n      <td>-0.000114</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>0.001914</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000010</td>\n      <td>-0.000010</td>\n      <td>-9.536743e-07</td>\n    </tr>\n    <tr>\n      <th>199999</th>\n      <td>199999</td>\n      <td>1.046326e-06</td>\n      <td>-1.536743e-06</td>\n      <td>0.000069</td>\n      <td>0.000539</td>\n      <td>0.001329</td>\n      <td>0.001657</td>\n      <td>0.001328</td>\n      <td>0.000520</td>\n      <td>0.000063</td>\n      <td>...</td>\n      <td>0.000033</td>\n      <td>0.000065</td>\n      <td>0.000053</td>\n      <td>0.000082</td>\n      <td>0.000102</td>\n      <td>0.000078</td>\n      <td>1.446326e-05</td>\n      <td>0.000013</td>\n      <td>0.000033</td>\n      <td>-9.536743e-07</td>\n    </tr>\n  </tbody>\n</table>\n<p>200000 rows × 287 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n# Example data (replace this with your actual data)\ntrain = np.array(train)\n\n# Function to perform Min-Max scaling\ndef min_max_scaling(train):\n    # Calculate the minimum and maximum values for each feature\n    min_vals = np.min(train, axis=0)\n    max_vals = np.max(train, axis=0)\n    \n    # Apply the Min-Max scaling formula\n    scaled_data = (train - min_vals) / (max_vals - min_vals)\n    \n    return scaled_data, min_vals, max_vals\n\n# Apply Min-Max scaling\nscaled_data, min_vals, max_vals = min_max_scaling(train)\n\n# print(\"Original Data:\\n\", data)\nprint(\"\\nScaled Data (Min-Max scaled between 0 and 1):\\n\", scaled_data)\nprint(\"\\nMin Values for each feature:\\n\", min_vals)\nprint(\"\\nMax Values for each feature:\\n\", max_vals)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:04:51.257876Z","iopub.execute_input":"2023-12-18T16:04:51.258229Z","iopub.status.idle":"2023-12-18T16:04:51.946883Z","shell.execute_reply.started":"2023-12-18T16:04:51.258202Z","shell.execute_reply":"2023-12-18T16:04:51.945924Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"\nScaled Data (Min-Max scaled between 0 and 1):\n [[0.000000e+00 0.000000e+00 0.000000e+00 ... 0.000000e+00 0.000000e+00\n  0.000000e+00]\n [5.000025e-06 0.000000e+00 0.000000e+00 ... 0.000000e+00 0.000000e+00\n  0.000000e+00]\n [1.000005e-05 0.000000e+00 8.000000e-04 ... 1.800000e-03 1.450000e-03\n  2.000000e-03]\n ...\n [9.999900e-01 1.000000e-04 1.100000e-03 ... 4.500000e-03 1.550000e-03\n  1.000000e-03]\n [9.999950e-01 0.000000e+00 0.000000e+00 ... 0.000000e+00 0.000000e+00\n  0.000000e+00]\n [1.000000e+00 2.000000e-04 8.000000e-04 ... 2.300000e-03 2.150000e-03\n  0.000000e+00]]\n\nMin Values for each feature:\n [ 0.00000000e+00 -9.53674316e-07 -9.53674316e-06 -4.29153442e-05\n -1.14440918e-04 -2.00271606e-04 -2.40325928e-04 -2.00271606e-04\n -1.14440918e-04 -4.29153442e-05 -9.53674316e-06 -9.53674316e-07\n -9.53674316e-06 -8.58306885e-05 -3.43322754e-04 -8.01086426e-04\n -1.20162964e-03 -1.20162964e-03 -8.01086426e-04 -3.43322754e-04\n -8.58306885e-05 -9.53674316e-06 -4.29153442e-05 -3.43322754e-04\n -1.20162964e-03 -2.40325928e-03 -3.00407410e-03 -2.40325928e-03\n -1.20162964e-03 -3.43322754e-04 -4.29153442e-05 -1.14440918e-04\n -8.01086426e-04 -2.40325928e-03 -4.00543213e-03 -4.00543213e-03\n -2.40325928e-03 -8.01086426e-04 -1.14440918e-04 -2.00271606e-04\n -1.20162964e-03 -3.00407410e-03 -4.00543213e-03 -3.00407410e-03\n -1.20162964e-03 -2.00271606e-04 -2.40325928e-04 -1.20162964e-03\n -2.40325928e-03 -2.40325928e-03 -1.20162964e-03 -2.40325928e-04\n -2.00271606e-04 -8.01086426e-04 -1.20162964e-03 -8.01086426e-04\n -2.00271606e-04 -1.14440918e-04 -3.43322754e-04 -3.43322754e-04\n -1.14440918e-04 -4.29153442e-05 -8.58306885e-05 -4.29153442e-05\n -9.53674316e-06 -9.53674316e-06 -9.53674316e-07 -9.53674316e-06\n -8.58306885e-05 -3.43322754e-04 -8.01086426e-04 -1.20162964e-03\n -1.20162964e-03 -8.01086426e-04 -3.43322754e-04 -8.58306885e-05\n -9.53674316e-06 -8.58306885e-05 -6.86645508e-04 -2.40325928e-03\n -4.80651855e-03 -6.00814819e-03 -4.80651855e-03 -2.40325928e-03\n -6.86645508e-04 -8.58306885e-05 -3.43322754e-04 -2.40325928e-03\n -7.20977783e-03 -1.20162964e-02 -1.20162964e-02 -7.20977783e-03\n -2.40325928e-03 -3.43322754e-04 -8.01086426e-04 -4.80651855e-03\n -1.20162964e-02 -1.60217285e-02 -1.20162964e-02 -4.80651855e-03\n -8.01086426e-04 -1.20162964e-03 -6.00814819e-03 -1.20162964e-02\n -1.20162964e-02 -6.00814819e-03 -1.20162964e-03 -1.20162964e-03\n -4.80651855e-03 -7.20977783e-03 -4.80651855e-03 -1.20162964e-03\n -8.01086426e-04 -2.40325928e-03 -2.40325928e-03 -8.01086426e-04\n -3.43322754e-04 -6.86645508e-04 -3.43322754e-04 -8.58306885e-05\n -8.58306885e-05 -9.53674316e-06 -4.29153442e-05 -3.43322754e-04\n -1.20162964e-03 -2.40325928e-03 -3.00407410e-03 -2.40325928e-03\n -1.20162964e-03 -3.43322754e-04 -4.29153442e-05 -3.43322754e-04\n -2.40325928e-03 -7.20977783e-03 -1.20162964e-02 -1.20162964e-02\n -7.20977783e-03 -2.40325928e-03 -3.43322754e-04 -1.20162964e-03\n -7.20977783e-03 -1.80244446e-02 -2.40325928e-02 -1.80244446e-02\n -7.20977783e-03 -1.20162964e-03 -2.40325928e-03 -1.20162964e-02\n -2.40325928e-02 -2.40325928e-02 -1.20162964e-02 -2.40325928e-03\n -3.00407410e-03 -1.20162964e-02 -1.80244446e-02 -1.20162964e-02\n -3.00407410e-03 -2.40325928e-03 -7.20977783e-03 -7.20977783e-03\n -2.40325928e-03 -1.20162964e-03 -2.40325928e-03 -1.20162964e-03\n -3.43322754e-04 -3.43322754e-04 -4.29153442e-05 -1.14440918e-04\n -8.01086426e-04 -2.40325928e-03 -4.00543213e-03 -4.00543213e-03\n -2.40325928e-03 -8.01086426e-04 -1.14440918e-04 -8.01086426e-04\n -4.80651855e-03 -1.20162964e-02 -1.60217285e-02 -1.20162964e-02\n -4.80651855e-03 -8.01086426e-04 -2.40325928e-03 -1.20162964e-02\n -2.40325928e-02 -2.40325928e-02 -1.20162964e-02 -2.40325928e-03\n -4.00543213e-03 -1.60217285e-02 -2.40325928e-02 -1.60217285e-02\n -4.00543213e-03 -4.00543213e-03 -1.20162964e-02 -1.20162964e-02\n -4.00543213e-03 -2.40325928e-03 -4.80651855e-03 -2.40325928e-03\n -8.01086426e-04 -8.01086426e-04 -1.14440918e-04 -2.00271606e-04\n -1.20162964e-03 -3.00407410e-03 -4.00543213e-03 -3.00407410e-03\n -1.20162964e-03 -2.00271606e-04 -1.20162964e-03 -6.00814819e-03\n -1.20162964e-02 -1.20162964e-02 -6.00814819e-03 -1.20162964e-03\n -3.00407410e-03 -1.20162964e-02 -1.80244446e-02 -1.20162964e-02\n -3.00407410e-03 -4.00543213e-03 -1.20162964e-02 -1.20162964e-02\n -4.00543213e-03 -3.00407410e-03 -6.00814819e-03 -3.00407410e-03\n -1.20162964e-03 -1.20162964e-03 -2.00271606e-04 -2.40325928e-04\n -1.20162964e-03 -2.40325928e-03 -2.40325928e-03 -1.20162964e-03\n -2.40325928e-04 -1.20162964e-03 -4.80651855e-03 -7.20977783e-03\n -4.80651855e-03 -1.20162964e-03 -2.40325928e-03 -7.20977783e-03\n -7.20977783e-03 -2.40325928e-03 -2.40325928e-03 -4.80651855e-03\n -2.40325928e-03 -1.20162964e-03 -1.20162964e-03 -2.40325928e-04\n -2.00271606e-04 -8.01086426e-04 -1.20162964e-03 -8.01086426e-04\n -2.00271606e-04 -8.01086426e-04 -2.40325928e-03 -2.40325928e-03\n -8.01086426e-04 -1.20162964e-03 -2.40325928e-03 -1.20162964e-03\n -8.01086426e-04 -8.01086426e-04 -2.00271606e-04 -1.14440918e-04\n -3.43322754e-04 -3.43322754e-04 -1.14440918e-04 -3.43322754e-04\n -6.86645508e-04 -3.43322754e-04 -3.43322754e-04 -3.43322754e-04\n -1.14440918e-04 -4.29153442e-05 -8.58306885e-05 -4.29153442e-05\n -8.58306885e-05 -8.58306885e-05 -4.29153442e-05 -9.53674316e-06\n -9.53674316e-06 -9.53674316e-06 -9.53674316e-07]\n\nMax Values for each feature:\n [1.99999000e+05 9.99904633e-03 9.99046326e-03 9.95708466e-03\n 9.88555908e-03 1.97997284e-02 1.97596741e-02 1.97997284e-02\n 9.88555908e-03 9.95708466e-03 9.99046326e-03 9.99046326e-04\n 9.90463257e-04 9.91416931e-03 1.96566772e-02 2.91989136e-02\n 3.87983704e-02 2.87983704e-02 2.91989136e-02 2.96566772e-02\n 9.91416931e-03 9.90463257e-04 9.95708466e-03 9.65667725e-03\n 2.87983704e-02 2.75967407e-02 3.69959259e-02 2.75967407e-02\n 2.87983704e-02 1.96566772e-02 9.95708466e-03 9.88555908e-03\n 1.91989136e-02 3.75967407e-02 3.59945679e-02 2.59945679e-02\n 3.75967407e-02 1.91989136e-02 9.88555908e-03 9.79972839e-03\n 1.87983704e-02 2.69959259e-02 3.59945679e-02 2.69959259e-02\n 1.87983704e-02 9.79972839e-03 1.97596741e-02 2.87983704e-02\n 3.75967407e-02 2.75967407e-02 2.87983704e-02 9.75967407e-03\n 1.97997284e-02 1.91989136e-02 2.87983704e-02 2.91989136e-02\n 1.97997284e-02 1.98855591e-02 1.96566772e-02 1.96566772e-02\n 1.98855591e-02 1.99570847e-02 1.99141693e-02 1.99570847e-02\n 9.99046326e-03 9.99046326e-03 9.99904633e-03 9.99046326e-03\n 9.91416931e-03 1.96566772e-02 2.91989136e-02 4.87983704e-02\n 2.87983704e-02 1.91989136e-02 9.65667725e-03 9.91416931e-03\n 9.90463257e-04 9.91416931e-03 9.31335449e-03 4.75967407e-02\n 4.51934814e-02 6.39918518e-02 5.51934814e-02 2.75967407e-02\n 1.93133545e-02 9.91416931e-03 1.96566772e-02 1.75967407e-02\n 5.27902222e-02 5.79837036e-02 5.79837036e-02 5.27902222e-02\n 2.75967407e-02 1.96566772e-02 1.91989136e-02 2.51934814e-02\n 3.79837036e-02 5.39782715e-02 4.79837036e-02 3.51934814e-02\n 1.91989136e-02 1.87983704e-02 3.39918518e-02 4.79837036e-02\n 3.79837036e-02 3.39918518e-02 2.87983704e-02 2.87983704e-02\n 3.51934814e-02 5.27902222e-02 3.51934814e-02 4.87983704e-02\n 4.91989136e-02 4.75967407e-02 3.75967407e-02 2.91989136e-02\n 2.96566772e-02 3.93133545e-02 3.96566772e-02 1.99141693e-02\n 1.99141693e-02 1.99904633e-02 9.95708466e-03 1.96566772e-02\n 2.87983704e-02 3.75967407e-02 3.69959259e-02 3.75967407e-02\n 1.87983704e-02 9.65667725e-03 9.95708466e-03 1.96566772e-02\n 2.75967407e-02 5.27902222e-02 6.79837036e-02 4.79837036e-02\n 4.27902222e-02 1.75967407e-02 9.65667725e-03 1.87983704e-02\n 3.27902222e-02 6.19755554e-02 5.59674072e-02 6.19755554e-02\n 3.27902222e-02 1.87983704e-02 2.75967407e-02 3.79837036e-02\n 6.59674072e-02 3.59674072e-02 3.79837036e-02 2.75967407e-02\n 3.69959259e-02 5.79837036e-02 5.19755554e-02 5.79837036e-02\n 2.69959259e-02 3.75967407e-02 5.27902222e-02 6.27902222e-02\n 3.75967407e-02 4.87983704e-02 5.75967407e-02 3.87983704e-02\n 2.96566772e-02 3.96566772e-02 1.99570847e-02 9.88555908e-03\n 1.91989136e-02 2.75967407e-02 4.59945679e-02 4.59945679e-02\n 2.75967407e-02 1.91989136e-02 9.88555908e-03 1.91989136e-02\n 3.51934814e-02 4.79837036e-02 7.39782715e-02 5.79837036e-02\n 3.51934814e-02 1.91989136e-02 2.75967407e-02 4.79837036e-02\n 6.59674072e-02 6.59674072e-02 3.79837036e-02 3.75967407e-02\n 3.59945679e-02 8.39782715e-02 5.59674072e-02 5.39782715e-02\n 2.59945679e-02 5.59945679e-02 7.79837036e-02 8.79837036e-02\n 5.59945679e-02 5.75967407e-02 6.51934814e-02 4.75967407e-02\n 3.91989136e-02 4.91989136e-02 2.98855591e-02 9.79972839e-03\n 2.87983704e-02 3.69959259e-02 3.59945679e-02 2.69959259e-02\n 1.87983704e-02 9.79972839e-03 1.87983704e-02 3.39918518e-02\n 4.79837036e-02 5.79837036e-02 4.39918518e-02 1.87983704e-02\n 3.69959259e-02 5.79837036e-02 6.19755554e-02 5.79837036e-02\n 2.69959259e-02 4.59945679e-02 5.79837036e-02 9.79837036e-02\n 4.59945679e-02 5.69959259e-02 7.39918518e-02 4.69959259e-02\n 4.87983704e-02 3.87983704e-02 2.97997284e-02 1.97596741e-02\n 2.87983704e-02 4.75967407e-02 3.75967407e-02 1.87983704e-02\n 9.75967407e-03 2.87983704e-02 3.51934814e-02 4.27902222e-02\n 5.51934814e-02 2.87983704e-02 4.75967407e-02 5.27902222e-02\n 6.27902222e-02 5.75967407e-02 5.75967407e-02 8.51934814e-02\n 4.75967407e-02 6.87983704e-02 4.87983704e-02 5.97596741e-02\n 9.79972839e-03 1.91989136e-02 2.87983704e-02 2.91989136e-02\n 1.97997284e-02 3.91989136e-02 4.75967407e-02 3.75967407e-02\n 2.91989136e-02 3.87983704e-02 5.75967407e-02 3.87983704e-02\n 4.91989136e-02 4.91989136e-02 3.97997284e-02 1.98855591e-02\n 1.96566772e-02 2.96566772e-02 1.98855591e-02 3.96566772e-02\n 3.93133545e-02 2.96566772e-02 3.96566772e-02 3.96566772e-02\n 2.98855591e-02 1.99570847e-02 1.99141693e-02 1.99570847e-02\n 1.99141693e-02 1.99141693e-02 1.99570847e-02 9.99046326e-03\n 9.99046326e-03 1.99904633e-02 9.99046326e-04]\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# import numpy as np\n\n# # Convert a list of lists to a NumPy array\n# X_train = np.array(train)\n# # Assuming X_train is your training data\n# # X_train should be a 2D NumPy array\n\n# # Initialize an empty array to store the scaled data\n# X_train_scaled = np.zeros_like(X_train)\n\n\n# # Iterate through each row of X_train\n# for i in range(X_train.shape[0]):\n#     row = X_train[i, :]  # Get the current row\n#     min_val = np.min(row)  # Calculate the minimum value in the row\n#     max_val = np.max(row)  # Calculate the maximum value in the row\n\n#     # Avoid division by zero\n#     if max_val != min_val:\n#         scaled_row = (row - min_val) / (max_val - min_val)\n#     else:\n#         scaled_row = np.zeros_like(row)  # If max and min are the same, set all values to 0\n#          # Debugging: Print scaled_row for each row\n# #     print(f\"Scaled Row {i}: {scaled_row}\")\n\n#     X_train_scaled[i, :] = scaled_row  # Store the scaled row in the result array\n\n# Now, X_train_scaled contains your normalized training data with each row scaled individually between 0 and 1\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T11:35:14.815852Z","iopub.execute_input":"2023-12-18T11:35:14.816197Z","iopub.status.idle":"2023-12-18T11:35:19.802891Z","shell.execute_reply.started":"2023-12-18T11:35:14.816171Z","shell.execute_reply":"2023-12-18T11:35:19.802075Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# X_train_scaled","metadata":{"execution":{"iopub.status.busy":"2023-12-15T18:55:34.607765Z","iopub.execute_input":"2023-12-15T18:55:34.608488Z","iopub.status.idle":"2023-12-15T18:55:34.615862Z","shell.execute_reply.started":"2023-12-15T18:55:34.608454Z","shell.execute_reply":"2023-12-15T18:55:34.613878Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# print(X_train_scaled)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:05:16.367145Z","iopub.execute_input":"2023-12-18T16:05:16.367495Z","iopub.status.idle":"2023-12-18T16:05:16.371394Z","shell.execute_reply.started":"2023-12-18T16:05:16.367467Z","shell.execute_reply":"2023-12-18T16:05:16.370556Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\n\n# # Assuming X_train_scaled is your scaled dataset\n# # Create an empty array for the formatted data\n# X_train_formatted = np.empty_like(X_train_scaled, dtype=np.float64)\n\n# # Iterate through each row and column of X_train_scaled\n# for i in range(X_train_scaled.shape[0]):\n#     for j in range(X_train_scaled.shape[1]):\n#         scaled_value = X_train_scaled[i, j]\n#         formatted_value = \"{:.5f}\".format(scaled_value)\n#         X_train_formatted[i, j] = float(formatted_value)\n\n# Now, X_train_formatted contains your scaled dataset with all values formatted as decimals\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T11:35:38.152365Z","iopub.execute_input":"2023-12-18T11:35:38.152719Z","iopub.status.idle":"2023-12-18T11:37:29.459653Z","shell.execute_reply.started":"2023-12-18T11:35:38.152691Z","shell.execute_reply":"2023-12-18T11:37:29.458829Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# print(X_train_formatted)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:05:31.868822Z","iopub.execute_input":"2023-12-18T16:05:31.869192Z","iopub.status.idle":"2023-12-18T16:05:31.873702Z","shell.execute_reply.started":"2023-12-18T16:05:31.869162Z","shell.execute_reply":"2023-12-18T16:05:31.872484Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Convert a list of lists to a NumPy array\n# X_test = np.array(test)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T10:00:17.297862Z","iopub.execute_input":"2023-12-18T10:00:17.298207Z","iopub.status.idle":"2023-12-18T10:00:17.302497Z","shell.execute_reply.started":"2023-12-18T10:00:17.298180Z","shell.execute_reply":"2023-12-18T10:00:17.301517Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# X_test","metadata":{"execution":{"iopub.status.busy":"2023-12-18T10:00:21.973110Z","iopub.execute_input":"2023-12-18T10:00:21.973820Z","iopub.status.idle":"2023-12-18T10:00:21.977605Z","shell.execute_reply.started":"2023-12-18T10:00:21.973786Z","shell.execute_reply":"2023-12-18T10:00:21.976652Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# X_train = X_train.astype(np.float64)\n# X_test = X_test.astype(np.float64)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T10:00:26.294417Z","iopub.execute_input":"2023-12-18T10:00:26.294870Z","iopub.status.idle":"2023-12-18T10:00:26.299359Z","shell.execute_reply.started":"2023-12-18T10:00:26.294832Z","shell.execute_reply":"2023-12-18T10:00:26.298307Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# X_test","metadata":{"execution":{"iopub.status.busy":"2023-12-18T10:00:29.751529Z","iopub.execute_input":"2023-12-18T10:00:29.752358Z","iopub.status.idle":"2023-12-18T10:00:29.756156Z","shell.execute_reply.started":"2023-12-18T10:00:29.752322Z","shell.execute_reply":"2023-12-18T10:00:29.755175Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\n\n# # Assuming X_train is your training data (a 2D NumPy array)\n# # and X_test is your test data (a 2D NumPy array)\n\n# # Initialize an empty array for scaled test data\n# X_test_scaled = np.zeros_like(X_test)\n\n# # Iterate through each row of X_test\n# for i in range(X_test.shape[0]):\n#     row = X_test[i, :]  # Get the current row\n#     min_val = np.min(X_train[i, :])  # Calculate the minimum value in the corresponding training data row\n#     max_val = np.max(X_train[i, :])  # Calculate the maximum value in the corresponding training data row\n\n#     # Scale the row to have values between 0 and 1 using training data's min and max\n#     if max_val != min_val:\n#         scaled_row = (row - min_val) / (max_val - min_val)\n#     else:\n#         scaled_row = np.zeros_like(row)  # If max and min are the same, set all values to 0\n\n#     X_test_scaled[i, :] = scaled_row  # Store the scaled row in the result array\n\n# # Now, X_test_scaled contains your scaled test data with each row scaled using training data's min and max\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T05:58:26.375061Z","iopub.status.idle":"2023-12-18T05:58:26.375377Z","shell.execute_reply.started":"2023-12-18T05:58:26.375221Z","shell.execute_reply":"2023-12-18T05:58:26.375235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_test_scaled","metadata":{"execution":{"iopub.status.busy":"2023-12-18T10:00:57.526788Z","iopub.execute_input":"2023-12-18T10:00:57.527520Z","iopub.status.idle":"2023-12-18T10:00:57.531375Z","shell.execute_reply.started":"2023-12-18T10:00:57.527485Z","shell.execute_reply":"2023-12-18T10:00:57.530468Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# X_train_formatted.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-18T10:01:02.248952Z","iopub.execute_input":"2023-12-18T10:01:02.249282Z","iopub.status.idle":"2023-12-18T10:01:02.253897Z","shell.execute_reply.started":"2023-12-18T10:01:02.249255Z","shell.execute_reply":"2023-12-18T10:01:02.252892Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"                                                  #  PCA of train data","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.535803Z","iopub.status.idle":"2023-12-05T18:59:51.536180Z","shell.execute_reply.started":"2023-12-05T18:59:51.535977Z","shell.execute_reply":"2023-12-05T18:59:51.535994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2023-12-18T14:31:01.003630Z","iopub.execute_input":"2023-12-18T14:31:01.004594Z","iopub.status.idle":"2023-12-18T14:31:01.061415Z","shell.execute_reply.started":"2023-12-18T14:31:01.004544Z","shell.execute_reply":"2023-12-18T14:31:01.060410Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"        row_id     A0T0G0C10      A0T0G1C9  A0T0G2C8  A0T0G3C7  A0T0G4C6  \\\n0            0 -9.536743e-07 -9.536743e-06 -0.000043 -0.000114 -0.000200   \n1            1 -9.536743e-07 -9.536743e-06 -0.000043  0.000886 -0.000200   \n2            2 -9.536743e-07 -1.536743e-06  0.000007  0.000129  0.000268   \n3            3  4.632568e-08 -5.536743e-06  0.000012  0.000245  0.000492   \n4            4 -9.536743e-07 -9.536743e-06 -0.000043 -0.000114 -0.000200   \n...        ...           ...           ...       ...       ...       ...   \n199995  199995 -9.536743e-07  4.632568e-07 -0.000003  0.000176  0.000350   \n199996  199996 -9.536743e-07 -9.536743e-06 -0.000043 -0.000114 -0.000200   \n199997  199997  4.632568e-08  1.463257e-06 -0.000005 -0.000031 -0.000019   \n199998  199998 -9.536743e-07 -9.536743e-06 -0.000043 -0.000114 -0.000200   \n199999  199999  1.046326e-06 -1.536743e-06  0.000069  0.000539  0.001329   \n\n        A0T0G5C5  A0T0G6C4  A0T0G7C3  A0T0G8C2  ...  A8T0G0C2  A8T0G1C1  \\\n0      -0.000240 -0.000200 -0.000114 -0.000043  ... -0.000043 -0.000086   \n1       0.000760 -0.000200 -0.000114 -0.000043  ... -0.000043 -0.000086   \n2       0.000270  0.000243  0.000125  0.000001  ...  0.000042  0.000084   \n3       0.000522  0.000396  0.000197 -0.000003  ...  0.000068  0.000151   \n4      -0.000240 -0.000200 -0.000114 -0.000043  ... -0.000043 -0.000086   \n...          ...       ...       ...       ...  ...       ...       ...   \n199995  0.000290  0.000200  0.000206 -0.000023  ...  0.000017  0.000124   \n199996 -0.000240 -0.000200 -0.000114 -0.000043  ... -0.000043 -0.000086   \n199997 -0.000037 -0.000037 -0.000015 -0.000005  ...  0.000028  0.000115   \n199998 -0.000240 -0.000200 -0.000114 -0.000043  ... -0.000043 -0.000086   \n199999  0.001657  0.001328  0.000520  0.000063  ...  0.000033  0.000065   \n\n        A8T0G2C0  A8T1G0C1  A8T1G1C0  A8T2G0C0      A9T0G0C1  A9T0G1C0  \\\n0      -0.000043 -0.000086 -0.000086 -0.000043 -9.536743e-06 -0.000010   \n1      -0.000043  0.000914  0.000914 -0.000043 -9.536743e-06 -0.000010   \n2       0.000048  0.000081  0.000106  0.000072  1.046326e-05  0.000008   \n3       0.000100  0.000180  0.000202  0.000153  2.146326e-05  0.000015   \n4      -0.000043 -0.000086 -0.000086 -0.000043 -9.536743e-06 -0.000010   \n...          ...       ...       ...       ...           ...       ...   \n199995  0.000057  0.000104  0.000144  0.000027  4.632568e-07  0.000060   \n199996 -0.000043  0.000914  0.000914 -0.000043 -9.536743e-06 -0.000010   \n199997  0.000131  0.000110  0.000213  0.000094  1.646326e-05  0.000035   \n199998 -0.000043  0.001914 -0.000086 -0.000043 -9.536743e-06 -0.000010   \n199999  0.000053  0.000082  0.000102  0.000078  1.446326e-05  0.000013   \n\n        A9T1G0C0     A10T0G0C0  \n0      -0.000010 -9.536743e-07  \n1      -0.000010 -9.536743e-07  \n2       0.000019  1.046326e-06  \n3       0.000046 -9.536743e-07  \n4      -0.000010 -9.536743e-07  \n...          ...           ...  \n199995  0.000020 -9.536743e-07  \n199996 -0.000010 -9.536743e-07  \n199997  0.000021  4.632568e-08  \n199998 -0.000010 -9.536743e-07  \n199999  0.000033 -9.536743e-07  \n\n[200000 rows x 287 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>A0T0G0C10</th>\n      <th>A0T0G1C9</th>\n      <th>A0T0G2C8</th>\n      <th>A0T0G3C7</th>\n      <th>A0T0G4C6</th>\n      <th>A0T0G5C5</th>\n      <th>A0T0G6C4</th>\n      <th>A0T0G7C3</th>\n      <th>A0T0G8C2</th>\n      <th>...</th>\n      <th>A8T0G0C2</th>\n      <th>A8T0G1C1</th>\n      <th>A8T0G2C0</th>\n      <th>A8T1G0C1</th>\n      <th>A8T1G1C0</th>\n      <th>A8T2G0C0</th>\n      <th>A9T0G0C1</th>\n      <th>A9T0G1C0</th>\n      <th>A9T1G0C0</th>\n      <th>A10T0G0C0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>-9.536743e-07</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000043</td>\n      <td>-0.000114</td>\n      <td>-0.000200</td>\n      <td>-0.000240</td>\n      <td>-0.000200</td>\n      <td>-0.000114</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000010</td>\n      <td>-0.000010</td>\n      <td>-9.536743e-07</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>-9.536743e-07</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000043</td>\n      <td>0.000886</td>\n      <td>-0.000200</td>\n      <td>0.000760</td>\n      <td>-0.000200</td>\n      <td>-0.000114</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>0.000914</td>\n      <td>0.000914</td>\n      <td>-0.000043</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000010</td>\n      <td>-0.000010</td>\n      <td>-9.536743e-07</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>-9.536743e-07</td>\n      <td>-1.536743e-06</td>\n      <td>0.000007</td>\n      <td>0.000129</td>\n      <td>0.000268</td>\n      <td>0.000270</td>\n      <td>0.000243</td>\n      <td>0.000125</td>\n      <td>0.000001</td>\n      <td>...</td>\n      <td>0.000042</td>\n      <td>0.000084</td>\n      <td>0.000048</td>\n      <td>0.000081</td>\n      <td>0.000106</td>\n      <td>0.000072</td>\n      <td>1.046326e-05</td>\n      <td>0.000008</td>\n      <td>0.000019</td>\n      <td>1.046326e-06</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>4.632568e-08</td>\n      <td>-5.536743e-06</td>\n      <td>0.000012</td>\n      <td>0.000245</td>\n      <td>0.000492</td>\n      <td>0.000522</td>\n      <td>0.000396</td>\n      <td>0.000197</td>\n      <td>-0.000003</td>\n      <td>...</td>\n      <td>0.000068</td>\n      <td>0.000151</td>\n      <td>0.000100</td>\n      <td>0.000180</td>\n      <td>0.000202</td>\n      <td>0.000153</td>\n      <td>2.146326e-05</td>\n      <td>0.000015</td>\n      <td>0.000046</td>\n      <td>-9.536743e-07</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>-9.536743e-07</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000043</td>\n      <td>-0.000114</td>\n      <td>-0.000200</td>\n      <td>-0.000240</td>\n      <td>-0.000200</td>\n      <td>-0.000114</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000010</td>\n      <td>-0.000010</td>\n      <td>-9.536743e-07</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>199995</th>\n      <td>199995</td>\n      <td>-9.536743e-07</td>\n      <td>4.632568e-07</td>\n      <td>-0.000003</td>\n      <td>0.000176</td>\n      <td>0.000350</td>\n      <td>0.000290</td>\n      <td>0.000200</td>\n      <td>0.000206</td>\n      <td>-0.000023</td>\n      <td>...</td>\n      <td>0.000017</td>\n      <td>0.000124</td>\n      <td>0.000057</td>\n      <td>0.000104</td>\n      <td>0.000144</td>\n      <td>0.000027</td>\n      <td>4.632568e-07</td>\n      <td>0.000060</td>\n      <td>0.000020</td>\n      <td>-9.536743e-07</td>\n    </tr>\n    <tr>\n      <th>199996</th>\n      <td>199996</td>\n      <td>-9.536743e-07</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000043</td>\n      <td>-0.000114</td>\n      <td>-0.000200</td>\n      <td>-0.000240</td>\n      <td>-0.000200</td>\n      <td>-0.000114</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>0.000914</td>\n      <td>0.000914</td>\n      <td>-0.000043</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000010</td>\n      <td>-0.000010</td>\n      <td>-9.536743e-07</td>\n    </tr>\n    <tr>\n      <th>199997</th>\n      <td>199997</td>\n      <td>4.632568e-08</td>\n      <td>1.463257e-06</td>\n      <td>-0.000005</td>\n      <td>-0.000031</td>\n      <td>-0.000019</td>\n      <td>-0.000037</td>\n      <td>-0.000037</td>\n      <td>-0.000015</td>\n      <td>-0.000005</td>\n      <td>...</td>\n      <td>0.000028</td>\n      <td>0.000115</td>\n      <td>0.000131</td>\n      <td>0.000110</td>\n      <td>0.000213</td>\n      <td>0.000094</td>\n      <td>1.646326e-05</td>\n      <td>0.000035</td>\n      <td>0.000021</td>\n      <td>4.632568e-08</td>\n    </tr>\n    <tr>\n      <th>199998</th>\n      <td>199998</td>\n      <td>-9.536743e-07</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000043</td>\n      <td>-0.000114</td>\n      <td>-0.000200</td>\n      <td>-0.000240</td>\n      <td>-0.000200</td>\n      <td>-0.000114</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>0.001914</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000010</td>\n      <td>-0.000010</td>\n      <td>-9.536743e-07</td>\n    </tr>\n    <tr>\n      <th>199999</th>\n      <td>199999</td>\n      <td>1.046326e-06</td>\n      <td>-1.536743e-06</td>\n      <td>0.000069</td>\n      <td>0.000539</td>\n      <td>0.001329</td>\n      <td>0.001657</td>\n      <td>0.001328</td>\n      <td>0.000520</td>\n      <td>0.000063</td>\n      <td>...</td>\n      <td>0.000033</td>\n      <td>0.000065</td>\n      <td>0.000053</td>\n      <td>0.000082</td>\n      <td>0.000102</td>\n      <td>0.000078</td>\n      <td>1.446326e-05</td>\n      <td>0.000013</td>\n      <td>0.000033</td>\n      <td>-9.536743e-07</td>\n    </tr>\n  </tbody>\n</table>\n<p>200000 rows × 287 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# target_column = train['target']\n# train=train.drop(columns=['target']) ","metadata":{"execution":{"iopub.status.busy":"2023-12-18T11:42:07.339220Z","iopub.execute_input":"2023-12-18T11:42:07.340092Z","iopub.status.idle":"2023-12-18T11:42:07.477895Z","shell.execute_reply.started":"2023-12-18T11:42:07.340056Z","shell.execute_reply":"2023-12-18T11:42:07.476846Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"target_column","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:06:22.858166Z","iopub.execute_input":"2023-12-18T16:06:22.858934Z","iopub.status.idle":"2023-12-18T16:06:22.866444Z","shell.execute_reply.started":"2023-12-18T16:06:22.858901Z","shell.execute_reply":"2023-12-18T16:06:22.865441Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"0           Streptococcus_pyogenes\n1              Salmonella_enterica\n2              Salmonella_enterica\n3              Salmonella_enterica\n4               Enterococcus_hirae\n                    ...           \n199995         Salmonella_enterica\n199996      Streptococcus_pyogenes\n199997    Streptococcus_pneumoniae\n199998       Staphylococcus_aureus\n199999       Klebsiella_pneumoniae\nName: target, Length: 200000, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"# train","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:06:26.550347Z","iopub.execute_input":"2023-12-18T16:06:26.551068Z","iopub.status.idle":"2023-12-18T16:06:26.555038Z","shell.execute_reply.started":"2023-12-18T16:06:26.551030Z","shell.execute_reply":"2023-12-18T16:06:26.554027Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"scaled_data","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:06:30.648514Z","iopub.execute_input":"2023-12-18T16:06:30.648991Z","iopub.status.idle":"2023-12-18T16:06:30.656436Z","shell.execute_reply.started":"2023-12-18T16:06:30.648950Z","shell.execute_reply":"2023-12-18T16:06:30.655436Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"array([[0.000000e+00, 0.000000e+00, 0.000000e+00, ..., 0.000000e+00,\n        0.000000e+00, 0.000000e+00],\n       [5.000025e-06, 0.000000e+00, 0.000000e+00, ..., 0.000000e+00,\n        0.000000e+00, 0.000000e+00],\n       [1.000005e-05, 0.000000e+00, 8.000000e-04, ..., 1.800000e-03,\n        1.450000e-03, 2.000000e-03],\n       ...,\n       [9.999900e-01, 1.000000e-04, 1.100000e-03, ..., 4.500000e-03,\n        1.550000e-03, 1.000000e-03],\n       [9.999950e-01, 0.000000e+00, 0.000000e+00, ..., 0.000000e+00,\n        0.000000e+00, 0.000000e+00],\n       [1.000000e+00, 2.000000e-04, 8.000000e-04, ..., 2.300000e-03,\n        2.150000e-03, 0.000000e+00]])"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.decomposition import PCA\n\n# Assuming X_train_scaled is your scaled training data\n# You can use X_train_formatted if you've converted it to human-readable format X_train_formatted\n\n# Initialize the PCA model with the desired number of components\nn_components = 33  # Adjust this value as needed\npca = PCA(n_components=n_components)\n\n# Fit the PCA model to your scaled data\npca.fit(scaled_data)\n\n# Transform the data to its principal components\nX_train_pca = pca.transform(scaled_data)\n# Create a DataFrame for the PCA results using common columns\npca_df = pd.DataFrame(data=X_train_pca, columns=[f'PC{i}' for i in range(1, 34)])\n# Printing the PCA results\nprint(pca_df)\n\n# Now, X_train_pca contains your training data reduced to the specified number of principal components\n# You can use X_train_pca for classification","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:06:47.566524Z","iopub.execute_input":"2023-12-18T16:06:47.566891Z","iopub.status.idle":"2023-12-18T16:06:52.969871Z","shell.execute_reply.started":"2023-12-18T16:06:47.566864Z","shell.execute_reply":"2023-12-18T16:06:52.968550Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"             PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n0      -0.195312  1.450241 -0.493021 -0.572659 -0.297635  0.197050  0.409117   \n1      -0.455772  0.023449 -0.499954 -0.147320  0.226929  0.058249 -0.082594   \n2      -0.455364 -0.176181 -0.501369  0.009695 -0.088106 -0.045754 -0.005835   \n3      -0.514005 -0.202394 -0.502223  0.088732 -0.101303  0.066163 -0.007517   \n4       0.498484  1.020506 -0.501142  0.310237 -0.013752 -0.050951 -0.443789   \n...          ...       ...       ...       ...       ...       ...       ...   \n199995 -0.481202 -0.183816  0.498148  0.051616 -0.089788 -0.002521 -0.010074   \n199996 -0.196881 -0.019007  0.500695 -0.205747  0.337803 -0.063218 -0.172581   \n199997 -0.212165 -0.158487  0.500078 -0.081012 -0.065430 -0.176712 -0.001405   \n199998 -0.364806  0.009943  0.501534 -0.485663  0.894587  0.268230  0.036807   \n199999 -0.871026 -0.253236  0.495066  0.280512 -0.152346  0.362412 -0.034243   \n\n             PC8       PC9      PC10  ...      PC24      PC25      PC26  \\\n0      -0.055661  0.132696 -0.020633  ...  0.022853 -0.034065 -0.049979   \n1      -0.255567 -0.024214 -0.060199  ... -0.025985 -0.012940 -0.040103   \n2       0.039792 -0.008607 -0.046811  ... -0.001723  0.003601  0.003857   \n3       0.020169  0.002250  0.002056  ...  0.002255  0.009617 -0.007120   \n4       0.146972  0.394156  0.100479  ... -0.060237  0.036303  0.199551   \n...          ...       ...       ...  ...       ...       ...       ...   \n199995  0.040612 -0.002718 -0.023120  ... -0.000451 -0.005653 -0.006765   \n199996 -0.316241 -0.015530 -0.071131  ... -0.056091 -0.005123  0.020191   \n199997  0.050292 -0.012731 -0.063049  ... -0.000196 -0.004304  0.014964   \n199998  0.354251  0.002307  0.034540  ...  0.012271 -0.000127  0.008678   \n199999  0.010008  0.009321  0.037324  ... -0.029917  0.005204 -0.008498   \n\n            PC27      PC28      PC29      PC30      PC31      PC32      PC33  \n0      -0.063715  0.009424  0.024634 -0.045399 -0.011842 -0.021832 -0.064831  \n1       0.056004 -0.008834 -0.070801 -0.012537  0.058317  0.019378 -0.038456  \n2      -0.002821 -0.002350  0.000247  0.001112  0.007009 -0.000284  0.000803  \n3      -0.003542 -0.005330  0.006924 -0.009082 -0.000051 -0.004132  0.006491  \n4      -0.015065 -0.114270 -0.079333  0.049267 -0.011205  0.061179  0.051704  \n...          ...       ...       ...       ...       ...       ...       ...  \n199995  0.003439  0.003325  0.001006 -0.000084  0.001114  0.003677  0.006985  \n199996  0.018326  0.011389 -0.012123  0.038576 -0.023561  0.004369  0.002474  \n199997  0.001011 -0.000241 -0.007622  0.010461  0.010078  0.002753 -0.002383  \n199998 -0.005181 -0.011460  0.023772 -0.023821  0.005354 -0.014740  0.023635  \n199999 -0.003718 -0.027410 -0.001366 -0.007446  0.014950  0.011177  0.014811  \n\n[200000 rows x 33 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"                   # pca of test data","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.542434Z","iopub.status.idle":"2023-12-05T18:59:51.542785Z","shell.execute_reply.started":"2023-12-05T18:59:51.542615Z","shell.execute_reply":"2023-12-05T18:59:51.542632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\n# from sklearn.decomposition import PCA\n\n# # Assuming X_test_scaled is your scaled training data\n# # You can use X_test_formatted if you've converted it to human-readable format X_test_formatted\n\n# # Initialize the PCA model with the desired number of components\n# n_components = 33  # Adjust this value as needed\n# pca = PCA(n_components=n_components)\n\n# # Fit the PCA model to your scaled data\n# pca.fit(X_test_scaled)\n\n# # Transform the data to its principal components\n# pca_df_test = pca.transform(X_test_scaled)\n# # Create a DataFrame for the PCA results using common columns\n# pca_df_test = pd.DataFrame(pca_df_test, columns=[f'PC{i}' for i in range(1, 34)])\n# # Printing the PCA results\n# print(pca_df_test)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T10:02:06.955427Z","iopub.execute_input":"2023-12-18T10:02:06.956403Z","iopub.status.idle":"2023-12-18T10:02:06.961428Z","shell.execute_reply.started":"2023-12-18T10:02:06.956366Z","shell.execute_reply":"2023-12-18T10:02:06.960443Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Assuming you have a target_column, and pca_df is your DataFrame\n# target_column\n# Add the target_column to pca_df\n# pca_df['target'] = target_column\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T10:03:39.688032Z","iopub.execute_input":"2023-12-18T10:03:39.689316Z","iopub.status.idle":"2023-12-18T10:03:39.695829Z","shell.execute_reply.started":"2023-12-18T10:03:39.689262Z","shell.execute_reply":"2023-12-18T10:03:39.694710Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"print(pca_df)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:07:01.660337Z","iopub.execute_input":"2023-12-18T16:07:01.661090Z","iopub.status.idle":"2023-12-18T16:07:01.713007Z","shell.execute_reply.started":"2023-12-18T16:07:01.661059Z","shell.execute_reply":"2023-12-18T16:07:01.712015Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"             PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n0      -0.195312  1.450241 -0.493021 -0.572659 -0.297635  0.197050  0.409117   \n1      -0.455772  0.023449 -0.499954 -0.147320  0.226929  0.058249 -0.082594   \n2      -0.455364 -0.176181 -0.501369  0.009695 -0.088106 -0.045754 -0.005835   \n3      -0.514005 -0.202394 -0.502223  0.088732 -0.101303  0.066163 -0.007517   \n4       0.498484  1.020506 -0.501142  0.310237 -0.013752 -0.050951 -0.443789   \n...          ...       ...       ...       ...       ...       ...       ...   \n199995 -0.481202 -0.183816  0.498148  0.051616 -0.089788 -0.002521 -0.010074   \n199996 -0.196881 -0.019007  0.500695 -0.205747  0.337803 -0.063218 -0.172581   \n199997 -0.212165 -0.158487  0.500078 -0.081012 -0.065430 -0.176712 -0.001405   \n199998 -0.364806  0.009943  0.501534 -0.485663  0.894587  0.268230  0.036807   \n199999 -0.871026 -0.253236  0.495066  0.280512 -0.152346  0.362412 -0.034243   \n\n             PC8       PC9      PC10  ...      PC24      PC25      PC26  \\\n0      -0.055661  0.132696 -0.020633  ...  0.022853 -0.034065 -0.049979   \n1      -0.255567 -0.024214 -0.060199  ... -0.025985 -0.012940 -0.040103   \n2       0.039792 -0.008607 -0.046811  ... -0.001723  0.003601  0.003857   \n3       0.020169  0.002250  0.002056  ...  0.002255  0.009617 -0.007120   \n4       0.146972  0.394156  0.100479  ... -0.060237  0.036303  0.199551   \n...          ...       ...       ...  ...       ...       ...       ...   \n199995  0.040612 -0.002718 -0.023120  ... -0.000451 -0.005653 -0.006765   \n199996 -0.316241 -0.015530 -0.071131  ... -0.056091 -0.005123  0.020191   \n199997  0.050292 -0.012731 -0.063049  ... -0.000196 -0.004304  0.014964   \n199998  0.354251  0.002307  0.034540  ...  0.012271 -0.000127  0.008678   \n199999  0.010008  0.009321  0.037324  ... -0.029917  0.005204 -0.008498   \n\n            PC27      PC28      PC29      PC30      PC31      PC32      PC33  \n0      -0.063715  0.009424  0.024634 -0.045399 -0.011842 -0.021832 -0.064831  \n1       0.056004 -0.008834 -0.070801 -0.012537  0.058317  0.019378 -0.038456  \n2      -0.002821 -0.002350  0.000247  0.001112  0.007009 -0.000284  0.000803  \n3      -0.003542 -0.005330  0.006924 -0.009082 -0.000051 -0.004132  0.006491  \n4      -0.015065 -0.114270 -0.079333  0.049267 -0.011205  0.061179  0.051704  \n...          ...       ...       ...       ...       ...       ...       ...  \n199995  0.003439  0.003325  0.001006 -0.000084  0.001114  0.003677  0.006985  \n199996  0.018326  0.011389 -0.012123  0.038576 -0.023561  0.004369  0.002474  \n199997  0.001011 -0.000241 -0.007622  0.010461  0.010078  0.002753 -0.002383  \n199998 -0.005181 -0.011460  0.023772 -0.023821  0.005354 -0.014740  0.023635  \n199999 -0.003718 -0.027410 -0.001366 -0.007446  0.014950  0.011177  0.014811  \n\n[200000 rows x 33 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"pca_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:07:05.966867Z","iopub.execute_input":"2023-12-18T16:07:05.967761Z","iopub.status.idle":"2023-12-18T16:07:05.973353Z","shell.execute_reply.started":"2023-12-18T16:07:05.967727Z","shell.execute_reply":"2023-12-18T16:07:05.972368Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(200000, 33)"},"metadata":{}}]},{"cell_type":"code","source":"# pca_df\nX = pca_df  # Extract all feature columns except 'target'\ny = target_column","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:07:15.351837Z","iopub.execute_input":"2023-12-18T16:07:15.352577Z","iopub.status.idle":"2023-12-18T16:07:15.356705Z","shell.execute_reply.started":"2023-12-18T16:07:15.352545Z","shell.execute_reply":"2023-12-18T16:07:15.355749Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"target_column","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:07:11.655100Z","iopub.execute_input":"2023-12-18T16:07:11.655796Z","iopub.status.idle":"2023-12-18T16:07:11.663705Z","shell.execute_reply.started":"2023-12-18T16:07:11.655762Z","shell.execute_reply":"2023-12-18T16:07:11.662671Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"0           Streptococcus_pyogenes\n1              Salmonella_enterica\n2              Salmonella_enterica\n3              Salmonella_enterica\n4               Enterococcus_hirae\n                    ...           \n199995         Salmonella_enterica\n199996      Streptococcus_pyogenes\n199997    Streptococcus_pneumoniae\n199998       Staphylococcus_aureus\n199999       Klebsiella_pneumoniae\nName: target, Length: 200000, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"X","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:07:19.353902Z","iopub.execute_input":"2023-12-18T16:07:19.354501Z","iopub.status.idle":"2023-12-18T16:07:19.448279Z","shell.execute_reply.started":"2023-12-18T16:07:19.354473Z","shell.execute_reply":"2023-12-18T16:07:19.447260Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"             PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n0      -0.195312  1.450241 -0.493021 -0.572659 -0.297635  0.197050  0.409117   \n1      -0.455772  0.023449 -0.499954 -0.147320  0.226929  0.058249 -0.082594   \n2      -0.455364 -0.176181 -0.501369  0.009695 -0.088106 -0.045754 -0.005835   \n3      -0.514005 -0.202394 -0.502223  0.088732 -0.101303  0.066163 -0.007517   \n4       0.498484  1.020506 -0.501142  0.310237 -0.013752 -0.050951 -0.443789   \n...          ...       ...       ...       ...       ...       ...       ...   \n199995 -0.481202 -0.183816  0.498148  0.051616 -0.089788 -0.002521 -0.010074   \n199996 -0.196881 -0.019007  0.500695 -0.205747  0.337803 -0.063218 -0.172581   \n199997 -0.212165 -0.158487  0.500078 -0.081012 -0.065430 -0.176712 -0.001405   \n199998 -0.364806  0.009943  0.501534 -0.485663  0.894587  0.268230  0.036807   \n199999 -0.871026 -0.253236  0.495066  0.280512 -0.152346  0.362412 -0.034243   \n\n             PC8       PC9      PC10  ...      PC24      PC25      PC26  \\\n0      -0.055661  0.132696 -0.020633  ...  0.022853 -0.034065 -0.049979   \n1      -0.255567 -0.024214 -0.060199  ... -0.025985 -0.012940 -0.040103   \n2       0.039792 -0.008607 -0.046811  ... -0.001723  0.003601  0.003857   \n3       0.020169  0.002250  0.002056  ...  0.002255  0.009617 -0.007120   \n4       0.146972  0.394156  0.100479  ... -0.060237  0.036303  0.199551   \n...          ...       ...       ...  ...       ...       ...       ...   \n199995  0.040612 -0.002718 -0.023120  ... -0.000451 -0.005653 -0.006765   \n199996 -0.316241 -0.015530 -0.071131  ... -0.056091 -0.005123  0.020191   \n199997  0.050292 -0.012731 -0.063049  ... -0.000196 -0.004304  0.014964   \n199998  0.354251  0.002307  0.034540  ...  0.012271 -0.000127  0.008678   \n199999  0.010008  0.009321  0.037324  ... -0.029917  0.005204 -0.008498   \n\n            PC27      PC28      PC29      PC30      PC31      PC32      PC33  \n0      -0.063715  0.009424  0.024634 -0.045399 -0.011842 -0.021832 -0.064831  \n1       0.056004 -0.008834 -0.070801 -0.012537  0.058317  0.019378 -0.038456  \n2      -0.002821 -0.002350  0.000247  0.001112  0.007009 -0.000284  0.000803  \n3      -0.003542 -0.005330  0.006924 -0.009082 -0.000051 -0.004132  0.006491  \n4      -0.015065 -0.114270 -0.079333  0.049267 -0.011205  0.061179  0.051704  \n...          ...       ...       ...       ...       ...       ...       ...  \n199995  0.003439  0.003325  0.001006 -0.000084  0.001114  0.003677  0.006985  \n199996  0.018326  0.011389 -0.012123  0.038576 -0.023561  0.004369  0.002474  \n199997  0.001011 -0.000241 -0.007622  0.010461  0.010078  0.002753 -0.002383  \n199998 -0.005181 -0.011460  0.023772 -0.023821  0.005354 -0.014740  0.023635  \n199999 -0.003718 -0.027410 -0.001366 -0.007446  0.014950  0.011177  0.014811  \n\n[200000 rows x 33 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PC1</th>\n      <th>PC2</th>\n      <th>PC3</th>\n      <th>PC4</th>\n      <th>PC5</th>\n      <th>PC6</th>\n      <th>PC7</th>\n      <th>PC8</th>\n      <th>PC9</th>\n      <th>PC10</th>\n      <th>...</th>\n      <th>PC24</th>\n      <th>PC25</th>\n      <th>PC26</th>\n      <th>PC27</th>\n      <th>PC28</th>\n      <th>PC29</th>\n      <th>PC30</th>\n      <th>PC31</th>\n      <th>PC32</th>\n      <th>PC33</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.195312</td>\n      <td>1.450241</td>\n      <td>-0.493021</td>\n      <td>-0.572659</td>\n      <td>-0.297635</td>\n      <td>0.197050</td>\n      <td>0.409117</td>\n      <td>-0.055661</td>\n      <td>0.132696</td>\n      <td>-0.020633</td>\n      <td>...</td>\n      <td>0.022853</td>\n      <td>-0.034065</td>\n      <td>-0.049979</td>\n      <td>-0.063715</td>\n      <td>0.009424</td>\n      <td>0.024634</td>\n      <td>-0.045399</td>\n      <td>-0.011842</td>\n      <td>-0.021832</td>\n      <td>-0.064831</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.455772</td>\n      <td>0.023449</td>\n      <td>-0.499954</td>\n      <td>-0.147320</td>\n      <td>0.226929</td>\n      <td>0.058249</td>\n      <td>-0.082594</td>\n      <td>-0.255567</td>\n      <td>-0.024214</td>\n      <td>-0.060199</td>\n      <td>...</td>\n      <td>-0.025985</td>\n      <td>-0.012940</td>\n      <td>-0.040103</td>\n      <td>0.056004</td>\n      <td>-0.008834</td>\n      <td>-0.070801</td>\n      <td>-0.012537</td>\n      <td>0.058317</td>\n      <td>0.019378</td>\n      <td>-0.038456</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.455364</td>\n      <td>-0.176181</td>\n      <td>-0.501369</td>\n      <td>0.009695</td>\n      <td>-0.088106</td>\n      <td>-0.045754</td>\n      <td>-0.005835</td>\n      <td>0.039792</td>\n      <td>-0.008607</td>\n      <td>-0.046811</td>\n      <td>...</td>\n      <td>-0.001723</td>\n      <td>0.003601</td>\n      <td>0.003857</td>\n      <td>-0.002821</td>\n      <td>-0.002350</td>\n      <td>0.000247</td>\n      <td>0.001112</td>\n      <td>0.007009</td>\n      <td>-0.000284</td>\n      <td>0.000803</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.514005</td>\n      <td>-0.202394</td>\n      <td>-0.502223</td>\n      <td>0.088732</td>\n      <td>-0.101303</td>\n      <td>0.066163</td>\n      <td>-0.007517</td>\n      <td>0.020169</td>\n      <td>0.002250</td>\n      <td>0.002056</td>\n      <td>...</td>\n      <td>0.002255</td>\n      <td>0.009617</td>\n      <td>-0.007120</td>\n      <td>-0.003542</td>\n      <td>-0.005330</td>\n      <td>0.006924</td>\n      <td>-0.009082</td>\n      <td>-0.000051</td>\n      <td>-0.004132</td>\n      <td>0.006491</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.498484</td>\n      <td>1.020506</td>\n      <td>-0.501142</td>\n      <td>0.310237</td>\n      <td>-0.013752</td>\n      <td>-0.050951</td>\n      <td>-0.443789</td>\n      <td>0.146972</td>\n      <td>0.394156</td>\n      <td>0.100479</td>\n      <td>...</td>\n      <td>-0.060237</td>\n      <td>0.036303</td>\n      <td>0.199551</td>\n      <td>-0.015065</td>\n      <td>-0.114270</td>\n      <td>-0.079333</td>\n      <td>0.049267</td>\n      <td>-0.011205</td>\n      <td>0.061179</td>\n      <td>0.051704</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>199995</th>\n      <td>-0.481202</td>\n      <td>-0.183816</td>\n      <td>0.498148</td>\n      <td>0.051616</td>\n      <td>-0.089788</td>\n      <td>-0.002521</td>\n      <td>-0.010074</td>\n      <td>0.040612</td>\n      <td>-0.002718</td>\n      <td>-0.023120</td>\n      <td>...</td>\n      <td>-0.000451</td>\n      <td>-0.005653</td>\n      <td>-0.006765</td>\n      <td>0.003439</td>\n      <td>0.003325</td>\n      <td>0.001006</td>\n      <td>-0.000084</td>\n      <td>0.001114</td>\n      <td>0.003677</td>\n      <td>0.006985</td>\n    </tr>\n    <tr>\n      <th>199996</th>\n      <td>-0.196881</td>\n      <td>-0.019007</td>\n      <td>0.500695</td>\n      <td>-0.205747</td>\n      <td>0.337803</td>\n      <td>-0.063218</td>\n      <td>-0.172581</td>\n      <td>-0.316241</td>\n      <td>-0.015530</td>\n      <td>-0.071131</td>\n      <td>...</td>\n      <td>-0.056091</td>\n      <td>-0.005123</td>\n      <td>0.020191</td>\n      <td>0.018326</td>\n      <td>0.011389</td>\n      <td>-0.012123</td>\n      <td>0.038576</td>\n      <td>-0.023561</td>\n      <td>0.004369</td>\n      <td>0.002474</td>\n    </tr>\n    <tr>\n      <th>199997</th>\n      <td>-0.212165</td>\n      <td>-0.158487</td>\n      <td>0.500078</td>\n      <td>-0.081012</td>\n      <td>-0.065430</td>\n      <td>-0.176712</td>\n      <td>-0.001405</td>\n      <td>0.050292</td>\n      <td>-0.012731</td>\n      <td>-0.063049</td>\n      <td>...</td>\n      <td>-0.000196</td>\n      <td>-0.004304</td>\n      <td>0.014964</td>\n      <td>0.001011</td>\n      <td>-0.000241</td>\n      <td>-0.007622</td>\n      <td>0.010461</td>\n      <td>0.010078</td>\n      <td>0.002753</td>\n      <td>-0.002383</td>\n    </tr>\n    <tr>\n      <th>199998</th>\n      <td>-0.364806</td>\n      <td>0.009943</td>\n      <td>0.501534</td>\n      <td>-0.485663</td>\n      <td>0.894587</td>\n      <td>0.268230</td>\n      <td>0.036807</td>\n      <td>0.354251</td>\n      <td>0.002307</td>\n      <td>0.034540</td>\n      <td>...</td>\n      <td>0.012271</td>\n      <td>-0.000127</td>\n      <td>0.008678</td>\n      <td>-0.005181</td>\n      <td>-0.011460</td>\n      <td>0.023772</td>\n      <td>-0.023821</td>\n      <td>0.005354</td>\n      <td>-0.014740</td>\n      <td>0.023635</td>\n    </tr>\n    <tr>\n      <th>199999</th>\n      <td>-0.871026</td>\n      <td>-0.253236</td>\n      <td>0.495066</td>\n      <td>0.280512</td>\n      <td>-0.152346</td>\n      <td>0.362412</td>\n      <td>-0.034243</td>\n      <td>0.010008</td>\n      <td>0.009321</td>\n      <td>0.037324</td>\n      <td>...</td>\n      <td>-0.029917</td>\n      <td>0.005204</td>\n      <td>-0.008498</td>\n      <td>-0.003718</td>\n      <td>-0.027410</td>\n      <td>-0.001366</td>\n      <td>-0.007446</td>\n      <td>0.014950</td>\n      <td>0.011177</td>\n      <td>0.014811</td>\n    </tr>\n  </tbody>\n</table>\n<p>200000 rows × 33 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:07:24.350387Z","iopub.execute_input":"2023-12-18T16:07:24.351021Z","iopub.status.idle":"2023-12-18T16:07:24.358523Z","shell.execute_reply.started":"2023-12-18T16:07:24.350992Z","shell.execute_reply":"2023-12-18T16:07:24.357630Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"0           Streptococcus_pyogenes\n1              Salmonella_enterica\n2              Salmonella_enterica\n3              Salmonella_enterica\n4               Enterococcus_hirae\n                    ...           \n199995         Salmonella_enterica\n199996      Streptococcus_pyogenes\n199997    Streptococcus_pneumoniae\n199998       Staphylococcus_aureus\n199999       Klebsiella_pneumoniae\nName: target, Length: 200000, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train_new, X_val, y_train_new, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:07:36.469311Z","iopub.execute_input":"2023-12-18T16:07:36.469962Z","iopub.status.idle":"2023-12-18T16:07:36.514595Z","shell.execute_reply.started":"2023-12-18T16:07:36.469929Z","shell.execute_reply":"2023-12-18T16:07:36.513786Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"X_train_new.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:07:39.547048Z","iopub.execute_input":"2023-12-18T16:07:39.547377Z","iopub.status.idle":"2023-12-18T16:07:39.553366Z","shell.execute_reply.started":"2023-12-18T16:07:39.547351Z","shell.execute_reply":"2023-12-18T16:07:39.552346Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"(180000, 33)"},"metadata":{}}]},{"cell_type":"code","source":"X_val","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:07:45.453184Z","iopub.execute_input":"2023-12-18T16:07:45.453854Z","iopub.status.idle":"2023-12-18T16:07:45.488429Z","shell.execute_reply.started":"2023-12-18T16:07:45.453824Z","shell.execute_reply":"2023-12-18T16:07:45.487424Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"             PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n119737 -0.386470 -0.182775  0.097533  0.019170 -0.081876 -0.061948  0.015088   \n72272  -0.105635 -0.159313 -0.138383 -0.071882 -0.068798 -0.080831 -0.012779   \n158154  0.175043 -0.177288  0.292008 -0.097076 -0.046034 -0.155100  0.003885   \n65426  -0.389168 -0.183872 -0.174027  0.017031 -0.083768 -0.064640  0.019399   \n30074  -0.507506  0.098146 -0.353935  0.326891 -0.259413  0.228391 -0.064639   \n...          ...       ...       ...       ...       ...       ...       ...   \n193188 -0.196705 -0.154964  0.466160 -0.086962 -0.063075 -0.162100  0.002073   \n35956  -0.417475 -0.183279 -0.322112  0.081710  0.004382 -0.053517  0.079085   \n149399 -0.315960 -0.052447  0.245334  0.231740 -0.322613 -0.098963  0.086759   \n97701   0.016852 -0.168015 -0.010703 -0.092272 -0.053644 -0.159632  0.001139   \n51732   0.871030 -0.193312 -0.238802 -0.017837 -0.045964  0.359398  0.033662   \n\n             PC8       PC9      PC10  ...      PC24      PC25      PC26  \\\n119737  0.036640  0.011090 -0.006318  ...  0.031962  0.001317  0.000929   \n72272   0.050981 -0.028005 -0.116536  ...  0.000048 -0.011507  0.002599   \n158154  0.039681 -0.000279 -0.027084  ... -0.005959  0.000899  0.006707   \n65426   0.033571  0.007549 -0.000463  ...  0.023846  0.002622 -0.002832   \n30074  -0.036469 -0.295749  0.295501  ... -0.226465  0.098249 -0.154382   \n...          ...       ...       ...  ...       ...       ...       ...   \n193188  0.052265 -0.020806 -0.077996  ... -0.009308 -0.007170  0.001600   \n35956  -0.094336  0.006505  0.076265  ...  0.071428  0.089642 -0.040043   \n149399  0.344536 -0.476490  0.083378  ...  0.265437  0.185058 -0.020303   \n97701   0.046004 -0.008243 -0.049238  ... -0.005137 -0.002077  0.008148   \n51732  -0.091906  0.021779  0.030990  ...  0.080344  0.014940  0.170484   \n\n            PC27      PC28      PC29      PC30      PC31      PC32      PC33  \n119737 -0.000437  0.008540  0.004626 -0.001166 -0.015511 -0.014988 -0.003926  \n72272   0.011756 -0.000979 -0.011044  0.019457  0.000982  0.008589 -0.005906  \n158154 -0.004270 -0.015735  0.002599  0.003049 -0.007224  0.001811  0.002649  \n65426   0.000865  0.001688  0.001568 -0.003126 -0.013896 -0.012058 -0.009572  \n30074  -0.123414 -0.087712 -0.033500  0.186009  0.048538  0.157973 -0.023531  \n...          ...       ...       ...       ...       ...       ...       ...  \n193188  0.002653 -0.000991 -0.011181  0.014245  0.003337  0.003712 -0.012623  \n35956   0.042594 -0.011574 -0.043051  0.032918 -0.002719 -0.010835  0.002037  \n149399 -0.121947  0.149085 -0.117611 -0.041608  0.109438  0.030327  0.008249  \n97701  -0.004469 -0.012784 -0.001383  0.003051 -0.000997  0.002039 -0.001446  \n51732  -0.036986 -0.028099 -0.004366 -0.042329  0.007897  0.038774  0.014692  \n\n[20000 rows x 33 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PC1</th>\n      <th>PC2</th>\n      <th>PC3</th>\n      <th>PC4</th>\n      <th>PC5</th>\n      <th>PC6</th>\n      <th>PC7</th>\n      <th>PC8</th>\n      <th>PC9</th>\n      <th>PC10</th>\n      <th>...</th>\n      <th>PC24</th>\n      <th>PC25</th>\n      <th>PC26</th>\n      <th>PC27</th>\n      <th>PC28</th>\n      <th>PC29</th>\n      <th>PC30</th>\n      <th>PC31</th>\n      <th>PC32</th>\n      <th>PC33</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>119737</th>\n      <td>-0.386470</td>\n      <td>-0.182775</td>\n      <td>0.097533</td>\n      <td>0.019170</td>\n      <td>-0.081876</td>\n      <td>-0.061948</td>\n      <td>0.015088</td>\n      <td>0.036640</td>\n      <td>0.011090</td>\n      <td>-0.006318</td>\n      <td>...</td>\n      <td>0.031962</td>\n      <td>0.001317</td>\n      <td>0.000929</td>\n      <td>-0.000437</td>\n      <td>0.008540</td>\n      <td>0.004626</td>\n      <td>-0.001166</td>\n      <td>-0.015511</td>\n      <td>-0.014988</td>\n      <td>-0.003926</td>\n    </tr>\n    <tr>\n      <th>72272</th>\n      <td>-0.105635</td>\n      <td>-0.159313</td>\n      <td>-0.138383</td>\n      <td>-0.071882</td>\n      <td>-0.068798</td>\n      <td>-0.080831</td>\n      <td>-0.012779</td>\n      <td>0.050981</td>\n      <td>-0.028005</td>\n      <td>-0.116536</td>\n      <td>...</td>\n      <td>0.000048</td>\n      <td>-0.011507</td>\n      <td>0.002599</td>\n      <td>0.011756</td>\n      <td>-0.000979</td>\n      <td>-0.011044</td>\n      <td>0.019457</td>\n      <td>0.000982</td>\n      <td>0.008589</td>\n      <td>-0.005906</td>\n    </tr>\n    <tr>\n      <th>158154</th>\n      <td>0.175043</td>\n      <td>-0.177288</td>\n      <td>0.292008</td>\n      <td>-0.097076</td>\n      <td>-0.046034</td>\n      <td>-0.155100</td>\n      <td>0.003885</td>\n      <td>0.039681</td>\n      <td>-0.000279</td>\n      <td>-0.027084</td>\n      <td>...</td>\n      <td>-0.005959</td>\n      <td>0.000899</td>\n      <td>0.006707</td>\n      <td>-0.004270</td>\n      <td>-0.015735</td>\n      <td>0.002599</td>\n      <td>0.003049</td>\n      <td>-0.007224</td>\n      <td>0.001811</td>\n      <td>0.002649</td>\n    </tr>\n    <tr>\n      <th>65426</th>\n      <td>-0.389168</td>\n      <td>-0.183872</td>\n      <td>-0.174027</td>\n      <td>0.017031</td>\n      <td>-0.083768</td>\n      <td>-0.064640</td>\n      <td>0.019399</td>\n      <td>0.033571</td>\n      <td>0.007549</td>\n      <td>-0.000463</td>\n      <td>...</td>\n      <td>0.023846</td>\n      <td>0.002622</td>\n      <td>-0.002832</td>\n      <td>0.000865</td>\n      <td>0.001688</td>\n      <td>0.001568</td>\n      <td>-0.003126</td>\n      <td>-0.013896</td>\n      <td>-0.012058</td>\n      <td>-0.009572</td>\n    </tr>\n    <tr>\n      <th>30074</th>\n      <td>-0.507506</td>\n      <td>0.098146</td>\n      <td>-0.353935</td>\n      <td>0.326891</td>\n      <td>-0.259413</td>\n      <td>0.228391</td>\n      <td>-0.064639</td>\n      <td>-0.036469</td>\n      <td>-0.295749</td>\n      <td>0.295501</td>\n      <td>...</td>\n      <td>-0.226465</td>\n      <td>0.098249</td>\n      <td>-0.154382</td>\n      <td>-0.123414</td>\n      <td>-0.087712</td>\n      <td>-0.033500</td>\n      <td>0.186009</td>\n      <td>0.048538</td>\n      <td>0.157973</td>\n      <td>-0.023531</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>193188</th>\n      <td>-0.196705</td>\n      <td>-0.154964</td>\n      <td>0.466160</td>\n      <td>-0.086962</td>\n      <td>-0.063075</td>\n      <td>-0.162100</td>\n      <td>0.002073</td>\n      <td>0.052265</td>\n      <td>-0.020806</td>\n      <td>-0.077996</td>\n      <td>...</td>\n      <td>-0.009308</td>\n      <td>-0.007170</td>\n      <td>0.001600</td>\n      <td>0.002653</td>\n      <td>-0.000991</td>\n      <td>-0.011181</td>\n      <td>0.014245</td>\n      <td>0.003337</td>\n      <td>0.003712</td>\n      <td>-0.012623</td>\n    </tr>\n    <tr>\n      <th>35956</th>\n      <td>-0.417475</td>\n      <td>-0.183279</td>\n      <td>-0.322112</td>\n      <td>0.081710</td>\n      <td>0.004382</td>\n      <td>-0.053517</td>\n      <td>0.079085</td>\n      <td>-0.094336</td>\n      <td>0.006505</td>\n      <td>0.076265</td>\n      <td>...</td>\n      <td>0.071428</td>\n      <td>0.089642</td>\n      <td>-0.040043</td>\n      <td>0.042594</td>\n      <td>-0.011574</td>\n      <td>-0.043051</td>\n      <td>0.032918</td>\n      <td>-0.002719</td>\n      <td>-0.010835</td>\n      <td>0.002037</td>\n    </tr>\n    <tr>\n      <th>149399</th>\n      <td>-0.315960</td>\n      <td>-0.052447</td>\n      <td>0.245334</td>\n      <td>0.231740</td>\n      <td>-0.322613</td>\n      <td>-0.098963</td>\n      <td>0.086759</td>\n      <td>0.344536</td>\n      <td>-0.476490</td>\n      <td>0.083378</td>\n      <td>...</td>\n      <td>0.265437</td>\n      <td>0.185058</td>\n      <td>-0.020303</td>\n      <td>-0.121947</td>\n      <td>0.149085</td>\n      <td>-0.117611</td>\n      <td>-0.041608</td>\n      <td>0.109438</td>\n      <td>0.030327</td>\n      <td>0.008249</td>\n    </tr>\n    <tr>\n      <th>97701</th>\n      <td>0.016852</td>\n      <td>-0.168015</td>\n      <td>-0.010703</td>\n      <td>-0.092272</td>\n      <td>-0.053644</td>\n      <td>-0.159632</td>\n      <td>0.001139</td>\n      <td>0.046004</td>\n      <td>-0.008243</td>\n      <td>-0.049238</td>\n      <td>...</td>\n      <td>-0.005137</td>\n      <td>-0.002077</td>\n      <td>0.008148</td>\n      <td>-0.004469</td>\n      <td>-0.012784</td>\n      <td>-0.001383</td>\n      <td>0.003051</td>\n      <td>-0.000997</td>\n      <td>0.002039</td>\n      <td>-0.001446</td>\n    </tr>\n    <tr>\n      <th>51732</th>\n      <td>0.871030</td>\n      <td>-0.193312</td>\n      <td>-0.238802</td>\n      <td>-0.017837</td>\n      <td>-0.045964</td>\n      <td>0.359398</td>\n      <td>0.033662</td>\n      <td>-0.091906</td>\n      <td>0.021779</td>\n      <td>0.030990</td>\n      <td>...</td>\n      <td>0.080344</td>\n      <td>0.014940</td>\n      <td>0.170484</td>\n      <td>-0.036986</td>\n      <td>-0.028099</td>\n      <td>-0.004366</td>\n      <td>-0.042329</td>\n      <td>0.007897</td>\n      <td>0.038774</td>\n      <td>0.014692</td>\n    </tr>\n  </tbody>\n</table>\n<p>20000 rows × 33 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X_train_new","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:07:52.865775Z","iopub.execute_input":"2023-12-18T16:07:52.866196Z","iopub.status.idle":"2023-12-18T16:07:52.947437Z","shell.execute_reply.started":"2023-12-18T16:07:52.866166Z","shell.execute_reply":"2023-12-18T16:07:52.946482Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"             PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n38762  -0.387754 -0.179544 -0.307261  0.005502 -0.083125 -0.075855  0.013105   \n76883  -0.447848 -0.157481 -0.116366 -0.052780 -0.074742 -0.113374 -0.005894   \n2018    0.174330 -0.176383 -0.488638 -0.106370 -0.037568 -0.149143  0.007158   \n133899  1.052958 -0.247346  0.172211 -0.018864 -0.111708  0.378535 -0.055296   \n170373 -0.531421 -0.007551  0.352724 -0.450606  0.890268  0.287516  0.035857   \n...          ...       ...       ...       ...       ...       ...       ...   \n119879  0.040257  1.326085  0.101818 -0.244504 -0.204954 -0.000720 -0.516811   \n103694 -0.430906 -0.170642  0.017309  0.001839 -0.084718 -0.071504  0.004567   \n131932  0.270503 -0.192393  0.160677 -0.049149 -0.092770  0.083745 -0.027371   \n146867  0.596427 -0.217094  0.236906 -0.087065 -0.000230 -0.083391  0.056255   \n121958  0.176430 -0.177690  0.111048 -0.099110 -0.046072 -0.154966  0.003600   \n\n             PC8       PC9      PC10  ...      PC24      PC25      PC26  \\\n38762   0.037369  0.003686 -0.013009  ...  0.019375  0.002832 -0.004338   \n76883   0.059995 -0.023750 -0.088320  ... -0.009947 -0.008838  0.000467   \n2018    0.039391  0.002777 -0.026415  ... -0.003014 -0.002793 -0.009720   \n133899  0.011147  0.020262  0.001541  ...  0.016233 -0.008901 -0.002986   \n170373  0.342573 -0.022159  0.056706  ...  0.006478  0.023627  0.012857   \n...          ...       ...       ...  ...       ...       ...       ...   \n119879  0.044313 -0.321465  0.138502  ... -0.111737 -0.039275 -0.026533   \n103694  0.050981 -0.009432 -0.027497  ...  0.004676 -0.003527 -0.004970   \n131932  0.039421 -0.004432 -0.055591  ...  0.008553 -0.006253  0.005661   \n146867  0.009120 -0.016778  0.021120  ... -0.114646 -0.062275 -0.043891   \n121958  0.039020  0.000798 -0.027285  ... -0.004415  0.001123  0.005724   \n\n            PC27      PC28      PC29      PC30      PC31      PC32      PC33  \n38762  -0.001978  0.001167  0.000759  0.001539 -0.011899 -0.012244 -0.010960  \n76883   0.003741  0.004839 -0.011771  0.020994  0.007224  0.007783 -0.008084  \n2018    0.003231 -0.009156  0.005211 -0.001288 -0.008947  0.004727  0.000822  \n133899  0.010563  0.015419 -0.017168 -0.003350 -0.006343  0.013677 -0.011666  \n170373 -0.024299 -0.000357  0.006838  0.011784 -0.001417 -0.014321 -0.013619  \n...          ...       ...       ...       ...       ...       ...       ...  \n119879  0.110822  0.118313 -0.015854  0.004991  0.177177 -0.094105  0.010459  \n103694  0.003683  0.003081  0.005589  0.000009 -0.007730 -0.000199 -0.009041  \n131932  0.004572  0.006198 -0.010724  0.008576  0.005099  0.005388 -0.011558  \n146867 -0.089426 -0.014326 -0.002734 -0.035707 -0.020839  0.015417  0.040340  \n121958 -0.003694 -0.016650  0.002535  0.001118 -0.004394  0.001741  0.001484  \n\n[180000 rows x 33 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PC1</th>\n      <th>PC2</th>\n      <th>PC3</th>\n      <th>PC4</th>\n      <th>PC5</th>\n      <th>PC6</th>\n      <th>PC7</th>\n      <th>PC8</th>\n      <th>PC9</th>\n      <th>PC10</th>\n      <th>...</th>\n      <th>PC24</th>\n      <th>PC25</th>\n      <th>PC26</th>\n      <th>PC27</th>\n      <th>PC28</th>\n      <th>PC29</th>\n      <th>PC30</th>\n      <th>PC31</th>\n      <th>PC32</th>\n      <th>PC33</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>38762</th>\n      <td>-0.387754</td>\n      <td>-0.179544</td>\n      <td>-0.307261</td>\n      <td>0.005502</td>\n      <td>-0.083125</td>\n      <td>-0.075855</td>\n      <td>0.013105</td>\n      <td>0.037369</td>\n      <td>0.003686</td>\n      <td>-0.013009</td>\n      <td>...</td>\n      <td>0.019375</td>\n      <td>0.002832</td>\n      <td>-0.004338</td>\n      <td>-0.001978</td>\n      <td>0.001167</td>\n      <td>0.000759</td>\n      <td>0.001539</td>\n      <td>-0.011899</td>\n      <td>-0.012244</td>\n      <td>-0.010960</td>\n    </tr>\n    <tr>\n      <th>76883</th>\n      <td>-0.447848</td>\n      <td>-0.157481</td>\n      <td>-0.116366</td>\n      <td>-0.052780</td>\n      <td>-0.074742</td>\n      <td>-0.113374</td>\n      <td>-0.005894</td>\n      <td>0.059995</td>\n      <td>-0.023750</td>\n      <td>-0.088320</td>\n      <td>...</td>\n      <td>-0.009947</td>\n      <td>-0.008838</td>\n      <td>0.000467</td>\n      <td>0.003741</td>\n      <td>0.004839</td>\n      <td>-0.011771</td>\n      <td>0.020994</td>\n      <td>0.007224</td>\n      <td>0.007783</td>\n      <td>-0.008084</td>\n    </tr>\n    <tr>\n      <th>2018</th>\n      <td>0.174330</td>\n      <td>-0.176383</td>\n      <td>-0.488638</td>\n      <td>-0.106370</td>\n      <td>-0.037568</td>\n      <td>-0.149143</td>\n      <td>0.007158</td>\n      <td>0.039391</td>\n      <td>0.002777</td>\n      <td>-0.026415</td>\n      <td>...</td>\n      <td>-0.003014</td>\n      <td>-0.002793</td>\n      <td>-0.009720</td>\n      <td>0.003231</td>\n      <td>-0.009156</td>\n      <td>0.005211</td>\n      <td>-0.001288</td>\n      <td>-0.008947</td>\n      <td>0.004727</td>\n      <td>0.000822</td>\n    </tr>\n    <tr>\n      <th>133899</th>\n      <td>1.052958</td>\n      <td>-0.247346</td>\n      <td>0.172211</td>\n      <td>-0.018864</td>\n      <td>-0.111708</td>\n      <td>0.378535</td>\n      <td>-0.055296</td>\n      <td>0.011147</td>\n      <td>0.020262</td>\n      <td>0.001541</td>\n      <td>...</td>\n      <td>0.016233</td>\n      <td>-0.008901</td>\n      <td>-0.002986</td>\n      <td>0.010563</td>\n      <td>0.015419</td>\n      <td>-0.017168</td>\n      <td>-0.003350</td>\n      <td>-0.006343</td>\n      <td>0.013677</td>\n      <td>-0.011666</td>\n    </tr>\n    <tr>\n      <th>170373</th>\n      <td>-0.531421</td>\n      <td>-0.007551</td>\n      <td>0.352724</td>\n      <td>-0.450606</td>\n      <td>0.890268</td>\n      <td>0.287516</td>\n      <td>0.035857</td>\n      <td>0.342573</td>\n      <td>-0.022159</td>\n      <td>0.056706</td>\n      <td>...</td>\n      <td>0.006478</td>\n      <td>0.023627</td>\n      <td>0.012857</td>\n      <td>-0.024299</td>\n      <td>-0.000357</td>\n      <td>0.006838</td>\n      <td>0.011784</td>\n      <td>-0.001417</td>\n      <td>-0.014321</td>\n      <td>-0.013619</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>119879</th>\n      <td>0.040257</td>\n      <td>1.326085</td>\n      <td>0.101818</td>\n      <td>-0.244504</td>\n      <td>-0.204954</td>\n      <td>-0.000720</td>\n      <td>-0.516811</td>\n      <td>0.044313</td>\n      <td>-0.321465</td>\n      <td>0.138502</td>\n      <td>...</td>\n      <td>-0.111737</td>\n      <td>-0.039275</td>\n      <td>-0.026533</td>\n      <td>0.110822</td>\n      <td>0.118313</td>\n      <td>-0.015854</td>\n      <td>0.004991</td>\n      <td>0.177177</td>\n      <td>-0.094105</td>\n      <td>0.010459</td>\n    </tr>\n    <tr>\n      <th>103694</th>\n      <td>-0.430906</td>\n      <td>-0.170642</td>\n      <td>0.017309</td>\n      <td>0.001839</td>\n      <td>-0.084718</td>\n      <td>-0.071504</td>\n      <td>0.004567</td>\n      <td>0.050981</td>\n      <td>-0.009432</td>\n      <td>-0.027497</td>\n      <td>...</td>\n      <td>0.004676</td>\n      <td>-0.003527</td>\n      <td>-0.004970</td>\n      <td>0.003683</td>\n      <td>0.003081</td>\n      <td>0.005589</td>\n      <td>0.000009</td>\n      <td>-0.007730</td>\n      <td>-0.000199</td>\n      <td>-0.009041</td>\n    </tr>\n    <tr>\n      <th>131932</th>\n      <td>0.270503</td>\n      <td>-0.192393</td>\n      <td>0.160677</td>\n      <td>-0.049149</td>\n      <td>-0.092770</td>\n      <td>0.083745</td>\n      <td>-0.027371</td>\n      <td>0.039421</td>\n      <td>-0.004432</td>\n      <td>-0.055591</td>\n      <td>...</td>\n      <td>0.008553</td>\n      <td>-0.006253</td>\n      <td>0.005661</td>\n      <td>0.004572</td>\n      <td>0.006198</td>\n      <td>-0.010724</td>\n      <td>0.008576</td>\n      <td>0.005099</td>\n      <td>0.005388</td>\n      <td>-0.011558</td>\n    </tr>\n    <tr>\n      <th>146867</th>\n      <td>0.596427</td>\n      <td>-0.217094</td>\n      <td>0.236906</td>\n      <td>-0.087065</td>\n      <td>-0.000230</td>\n      <td>-0.083391</td>\n      <td>0.056255</td>\n      <td>0.009120</td>\n      <td>-0.016778</td>\n      <td>0.021120</td>\n      <td>...</td>\n      <td>-0.114646</td>\n      <td>-0.062275</td>\n      <td>-0.043891</td>\n      <td>-0.089426</td>\n      <td>-0.014326</td>\n      <td>-0.002734</td>\n      <td>-0.035707</td>\n      <td>-0.020839</td>\n      <td>0.015417</td>\n      <td>0.040340</td>\n    </tr>\n    <tr>\n      <th>121958</th>\n      <td>0.176430</td>\n      <td>-0.177690</td>\n      <td>0.111048</td>\n      <td>-0.099110</td>\n      <td>-0.046072</td>\n      <td>-0.154966</td>\n      <td>0.003600</td>\n      <td>0.039020</td>\n      <td>0.000798</td>\n      <td>-0.027285</td>\n      <td>...</td>\n      <td>-0.004415</td>\n      <td>0.001123</td>\n      <td>0.005724</td>\n      <td>-0.003694</td>\n      <td>-0.016650</td>\n      <td>0.002535</td>\n      <td>0.001118</td>\n      <td>-0.004394</td>\n      <td>0.001741</td>\n      <td>0.001484</td>\n    </tr>\n  </tbody>\n</table>\n<p>180000 rows × 33 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X_val.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:08:00.248153Z","iopub.execute_input":"2023-12-18T16:08:00.248903Z","iopub.status.idle":"2023-12-18T16:08:00.254778Z","shell.execute_reply.started":"2023-12-18T16:08:00.248870Z","shell.execute_reply":"2023-12-18T16:08:00.253804Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"(20000, 33)"},"metadata":{}}]},{"cell_type":"code","source":"y_train_new.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:08:02.978202Z","iopub.execute_input":"2023-12-18T16:08:02.978825Z","iopub.status.idle":"2023-12-18T16:08:02.985504Z","shell.execute_reply.started":"2023-12-18T16:08:02.978789Z","shell.execute_reply":"2023-12-18T16:08:02.984334Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"(180000,)"},"metadata":{}}]},{"cell_type":"code","source":"y_val","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:08:05.759959Z","iopub.execute_input":"2023-12-18T16:08:05.760695Z","iopub.status.idle":"2023-12-18T16:08:05.768306Z","shell.execute_reply.started":"2023-12-18T16:08:05.760666Z","shell.execute_reply":"2023-12-18T16:08:05.767224Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"119737    Escherichia_fergusonii\n72272      Staphylococcus_aureus\n158154    Streptococcus_pyogenes\n65426     Escherichia_fergusonii\n30074      Klebsiella_pneumoniae\n                   ...          \n193188    Streptococcus_pyogenes\n35956           Escherichia_coli\n149399          Escherichia_coli\n97701     Streptococcus_pyogenes\n51732       Campylobacter_jejuni\nName: target, Length: 20000, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"X_train_new","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:08:12.066975Z","iopub.execute_input":"2023-12-18T16:08:12.067729Z","iopub.status.idle":"2023-12-18T16:08:12.151473Z","shell.execute_reply.started":"2023-12-18T16:08:12.067697Z","shell.execute_reply":"2023-12-18T16:08:12.150543Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"             PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n38762  -0.387754 -0.179544 -0.307261  0.005502 -0.083125 -0.075855  0.013105   \n76883  -0.447848 -0.157481 -0.116366 -0.052780 -0.074742 -0.113374 -0.005894   \n2018    0.174330 -0.176383 -0.488638 -0.106370 -0.037568 -0.149143  0.007158   \n133899  1.052958 -0.247346  0.172211 -0.018864 -0.111708  0.378535 -0.055296   \n170373 -0.531421 -0.007551  0.352724 -0.450606  0.890268  0.287516  0.035857   \n...          ...       ...       ...       ...       ...       ...       ...   \n119879  0.040257  1.326085  0.101818 -0.244504 -0.204954 -0.000720 -0.516811   \n103694 -0.430906 -0.170642  0.017309  0.001839 -0.084718 -0.071504  0.004567   \n131932  0.270503 -0.192393  0.160677 -0.049149 -0.092770  0.083745 -0.027371   \n146867  0.596427 -0.217094  0.236906 -0.087065 -0.000230 -0.083391  0.056255   \n121958  0.176430 -0.177690  0.111048 -0.099110 -0.046072 -0.154966  0.003600   \n\n             PC8       PC9      PC10  ...      PC24      PC25      PC26  \\\n38762   0.037369  0.003686 -0.013009  ...  0.019375  0.002832 -0.004338   \n76883   0.059995 -0.023750 -0.088320  ... -0.009947 -0.008838  0.000467   \n2018    0.039391  0.002777 -0.026415  ... -0.003014 -0.002793 -0.009720   \n133899  0.011147  0.020262  0.001541  ...  0.016233 -0.008901 -0.002986   \n170373  0.342573 -0.022159  0.056706  ...  0.006478  0.023627  0.012857   \n...          ...       ...       ...  ...       ...       ...       ...   \n119879  0.044313 -0.321465  0.138502  ... -0.111737 -0.039275 -0.026533   \n103694  0.050981 -0.009432 -0.027497  ...  0.004676 -0.003527 -0.004970   \n131932  0.039421 -0.004432 -0.055591  ...  0.008553 -0.006253  0.005661   \n146867  0.009120 -0.016778  0.021120  ... -0.114646 -0.062275 -0.043891   \n121958  0.039020  0.000798 -0.027285  ... -0.004415  0.001123  0.005724   \n\n            PC27      PC28      PC29      PC30      PC31      PC32      PC33  \n38762  -0.001978  0.001167  0.000759  0.001539 -0.011899 -0.012244 -0.010960  \n76883   0.003741  0.004839 -0.011771  0.020994  0.007224  0.007783 -0.008084  \n2018    0.003231 -0.009156  0.005211 -0.001288 -0.008947  0.004727  0.000822  \n133899  0.010563  0.015419 -0.017168 -0.003350 -0.006343  0.013677 -0.011666  \n170373 -0.024299 -0.000357  0.006838  0.011784 -0.001417 -0.014321 -0.013619  \n...          ...       ...       ...       ...       ...       ...       ...  \n119879  0.110822  0.118313 -0.015854  0.004991  0.177177 -0.094105  0.010459  \n103694  0.003683  0.003081  0.005589  0.000009 -0.007730 -0.000199 -0.009041  \n131932  0.004572  0.006198 -0.010724  0.008576  0.005099  0.005388 -0.011558  \n146867 -0.089426 -0.014326 -0.002734 -0.035707 -0.020839  0.015417  0.040340  \n121958 -0.003694 -0.016650  0.002535  0.001118 -0.004394  0.001741  0.001484  \n\n[180000 rows x 33 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PC1</th>\n      <th>PC2</th>\n      <th>PC3</th>\n      <th>PC4</th>\n      <th>PC5</th>\n      <th>PC6</th>\n      <th>PC7</th>\n      <th>PC8</th>\n      <th>PC9</th>\n      <th>PC10</th>\n      <th>...</th>\n      <th>PC24</th>\n      <th>PC25</th>\n      <th>PC26</th>\n      <th>PC27</th>\n      <th>PC28</th>\n      <th>PC29</th>\n      <th>PC30</th>\n      <th>PC31</th>\n      <th>PC32</th>\n      <th>PC33</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>38762</th>\n      <td>-0.387754</td>\n      <td>-0.179544</td>\n      <td>-0.307261</td>\n      <td>0.005502</td>\n      <td>-0.083125</td>\n      <td>-0.075855</td>\n      <td>0.013105</td>\n      <td>0.037369</td>\n      <td>0.003686</td>\n      <td>-0.013009</td>\n      <td>...</td>\n      <td>0.019375</td>\n      <td>0.002832</td>\n      <td>-0.004338</td>\n      <td>-0.001978</td>\n      <td>0.001167</td>\n      <td>0.000759</td>\n      <td>0.001539</td>\n      <td>-0.011899</td>\n      <td>-0.012244</td>\n      <td>-0.010960</td>\n    </tr>\n    <tr>\n      <th>76883</th>\n      <td>-0.447848</td>\n      <td>-0.157481</td>\n      <td>-0.116366</td>\n      <td>-0.052780</td>\n      <td>-0.074742</td>\n      <td>-0.113374</td>\n      <td>-0.005894</td>\n      <td>0.059995</td>\n      <td>-0.023750</td>\n      <td>-0.088320</td>\n      <td>...</td>\n      <td>-0.009947</td>\n      <td>-0.008838</td>\n      <td>0.000467</td>\n      <td>0.003741</td>\n      <td>0.004839</td>\n      <td>-0.011771</td>\n      <td>0.020994</td>\n      <td>0.007224</td>\n      <td>0.007783</td>\n      <td>-0.008084</td>\n    </tr>\n    <tr>\n      <th>2018</th>\n      <td>0.174330</td>\n      <td>-0.176383</td>\n      <td>-0.488638</td>\n      <td>-0.106370</td>\n      <td>-0.037568</td>\n      <td>-0.149143</td>\n      <td>0.007158</td>\n      <td>0.039391</td>\n      <td>0.002777</td>\n      <td>-0.026415</td>\n      <td>...</td>\n      <td>-0.003014</td>\n      <td>-0.002793</td>\n      <td>-0.009720</td>\n      <td>0.003231</td>\n      <td>-0.009156</td>\n      <td>0.005211</td>\n      <td>-0.001288</td>\n      <td>-0.008947</td>\n      <td>0.004727</td>\n      <td>0.000822</td>\n    </tr>\n    <tr>\n      <th>133899</th>\n      <td>1.052958</td>\n      <td>-0.247346</td>\n      <td>0.172211</td>\n      <td>-0.018864</td>\n      <td>-0.111708</td>\n      <td>0.378535</td>\n      <td>-0.055296</td>\n      <td>0.011147</td>\n      <td>0.020262</td>\n      <td>0.001541</td>\n      <td>...</td>\n      <td>0.016233</td>\n      <td>-0.008901</td>\n      <td>-0.002986</td>\n      <td>0.010563</td>\n      <td>0.015419</td>\n      <td>-0.017168</td>\n      <td>-0.003350</td>\n      <td>-0.006343</td>\n      <td>0.013677</td>\n      <td>-0.011666</td>\n    </tr>\n    <tr>\n      <th>170373</th>\n      <td>-0.531421</td>\n      <td>-0.007551</td>\n      <td>0.352724</td>\n      <td>-0.450606</td>\n      <td>0.890268</td>\n      <td>0.287516</td>\n      <td>0.035857</td>\n      <td>0.342573</td>\n      <td>-0.022159</td>\n      <td>0.056706</td>\n      <td>...</td>\n      <td>0.006478</td>\n      <td>0.023627</td>\n      <td>0.012857</td>\n      <td>-0.024299</td>\n      <td>-0.000357</td>\n      <td>0.006838</td>\n      <td>0.011784</td>\n      <td>-0.001417</td>\n      <td>-0.014321</td>\n      <td>-0.013619</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>119879</th>\n      <td>0.040257</td>\n      <td>1.326085</td>\n      <td>0.101818</td>\n      <td>-0.244504</td>\n      <td>-0.204954</td>\n      <td>-0.000720</td>\n      <td>-0.516811</td>\n      <td>0.044313</td>\n      <td>-0.321465</td>\n      <td>0.138502</td>\n      <td>...</td>\n      <td>-0.111737</td>\n      <td>-0.039275</td>\n      <td>-0.026533</td>\n      <td>0.110822</td>\n      <td>0.118313</td>\n      <td>-0.015854</td>\n      <td>0.004991</td>\n      <td>0.177177</td>\n      <td>-0.094105</td>\n      <td>0.010459</td>\n    </tr>\n    <tr>\n      <th>103694</th>\n      <td>-0.430906</td>\n      <td>-0.170642</td>\n      <td>0.017309</td>\n      <td>0.001839</td>\n      <td>-0.084718</td>\n      <td>-0.071504</td>\n      <td>0.004567</td>\n      <td>0.050981</td>\n      <td>-0.009432</td>\n      <td>-0.027497</td>\n      <td>...</td>\n      <td>0.004676</td>\n      <td>-0.003527</td>\n      <td>-0.004970</td>\n      <td>0.003683</td>\n      <td>0.003081</td>\n      <td>0.005589</td>\n      <td>0.000009</td>\n      <td>-0.007730</td>\n      <td>-0.000199</td>\n      <td>-0.009041</td>\n    </tr>\n    <tr>\n      <th>131932</th>\n      <td>0.270503</td>\n      <td>-0.192393</td>\n      <td>0.160677</td>\n      <td>-0.049149</td>\n      <td>-0.092770</td>\n      <td>0.083745</td>\n      <td>-0.027371</td>\n      <td>0.039421</td>\n      <td>-0.004432</td>\n      <td>-0.055591</td>\n      <td>...</td>\n      <td>0.008553</td>\n      <td>-0.006253</td>\n      <td>0.005661</td>\n      <td>0.004572</td>\n      <td>0.006198</td>\n      <td>-0.010724</td>\n      <td>0.008576</td>\n      <td>0.005099</td>\n      <td>0.005388</td>\n      <td>-0.011558</td>\n    </tr>\n    <tr>\n      <th>146867</th>\n      <td>0.596427</td>\n      <td>-0.217094</td>\n      <td>0.236906</td>\n      <td>-0.087065</td>\n      <td>-0.000230</td>\n      <td>-0.083391</td>\n      <td>0.056255</td>\n      <td>0.009120</td>\n      <td>-0.016778</td>\n      <td>0.021120</td>\n      <td>...</td>\n      <td>-0.114646</td>\n      <td>-0.062275</td>\n      <td>-0.043891</td>\n      <td>-0.089426</td>\n      <td>-0.014326</td>\n      <td>-0.002734</td>\n      <td>-0.035707</td>\n      <td>-0.020839</td>\n      <td>0.015417</td>\n      <td>0.040340</td>\n    </tr>\n    <tr>\n      <th>121958</th>\n      <td>0.176430</td>\n      <td>-0.177690</td>\n      <td>0.111048</td>\n      <td>-0.099110</td>\n      <td>-0.046072</td>\n      <td>-0.154966</td>\n      <td>0.003600</td>\n      <td>0.039020</td>\n      <td>0.000798</td>\n      <td>-0.027285</td>\n      <td>...</td>\n      <td>-0.004415</td>\n      <td>0.001123</td>\n      <td>0.005724</td>\n      <td>-0.003694</td>\n      <td>-0.016650</td>\n      <td>0.002535</td>\n      <td>0.001118</td>\n      <td>-0.004394</td>\n      <td>0.001741</td>\n      <td>0.001484</td>\n    </tr>\n  </tbody>\n</table>\n<p>180000 rows × 33 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X_train_new['target'] = y_train_new\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:08:29.357241Z","iopub.execute_input":"2023-12-18T16:08:29.358176Z","iopub.status.idle":"2023-12-18T16:08:29.363848Z","shell.execute_reply.started":"2023-12-18T16:08:29.358141Z","shell.execute_reply":"2023-12-18T16:08:29.362985Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"X_train_new","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:08:35.164122Z","iopub.execute_input":"2023-12-18T16:08:35.164804Z","iopub.status.idle":"2023-12-18T16:08:35.251552Z","shell.execute_reply.started":"2023-12-18T16:08:35.164769Z","shell.execute_reply":"2023-12-18T16:08:35.250675Z"},"trusted":true},"execution_count":37,"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"             PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n38762  -0.387754 -0.179544 -0.307261  0.005502 -0.083125 -0.075855  0.013105   \n76883  -0.447848 -0.157481 -0.116366 -0.052780 -0.074742 -0.113374 -0.005894   \n2018    0.174330 -0.176383 -0.488638 -0.106370 -0.037568 -0.149143  0.007158   \n133899  1.052958 -0.247346  0.172211 -0.018864 -0.111708  0.378535 -0.055296   \n170373 -0.531421 -0.007551  0.352724 -0.450606  0.890268  0.287516  0.035857   \n...          ...       ...       ...       ...       ...       ...       ...   \n119879  0.040257  1.326085  0.101818 -0.244504 -0.204954 -0.000720 -0.516811   \n103694 -0.430906 -0.170642  0.017309  0.001839 -0.084718 -0.071504  0.004567   \n131932  0.270503 -0.192393  0.160677 -0.049149 -0.092770  0.083745 -0.027371   \n146867  0.596427 -0.217094  0.236906 -0.087065 -0.000230 -0.083391  0.056255   \n121958  0.176430 -0.177690  0.111048 -0.099110 -0.046072 -0.154966  0.003600   \n\n             PC8       PC9      PC10  ...      PC25      PC26      PC27  \\\n38762   0.037369  0.003686 -0.013009  ...  0.002832 -0.004338 -0.001978   \n76883   0.059995 -0.023750 -0.088320  ... -0.008838  0.000467  0.003741   \n2018    0.039391  0.002777 -0.026415  ... -0.002793 -0.009720  0.003231   \n133899  0.011147  0.020262  0.001541  ... -0.008901 -0.002986  0.010563   \n170373  0.342573 -0.022159  0.056706  ...  0.023627  0.012857 -0.024299   \n...          ...       ...       ...  ...       ...       ...       ...   \n119879  0.044313 -0.321465  0.138502  ... -0.039275 -0.026533  0.110822   \n103694  0.050981 -0.009432 -0.027497  ... -0.003527 -0.004970  0.003683   \n131932  0.039421 -0.004432 -0.055591  ... -0.006253  0.005661  0.004572   \n146867  0.009120 -0.016778  0.021120  ... -0.062275 -0.043891 -0.089426   \n121958  0.039020  0.000798 -0.027285  ...  0.001123  0.005724 -0.003694   \n\n            PC28      PC29      PC30      PC31      PC32      PC33  \\\n38762   0.001167  0.000759  0.001539 -0.011899 -0.012244 -0.010960   \n76883   0.004839 -0.011771  0.020994  0.007224  0.007783 -0.008084   \n2018   -0.009156  0.005211 -0.001288 -0.008947  0.004727  0.000822   \n133899  0.015419 -0.017168 -0.003350 -0.006343  0.013677 -0.011666   \n170373 -0.000357  0.006838  0.011784 -0.001417 -0.014321 -0.013619   \n...          ...       ...       ...       ...       ...       ...   \n119879  0.118313 -0.015854  0.004991  0.177177 -0.094105  0.010459   \n103694  0.003081  0.005589  0.000009 -0.007730 -0.000199 -0.009041   \n131932  0.006198 -0.010724  0.008576  0.005099  0.005388 -0.011558   \n146867 -0.014326 -0.002734 -0.035707 -0.020839  0.015417  0.040340   \n121958 -0.016650  0.002535  0.001118 -0.004394  0.001741  0.001484   \n\n                          target  \n38762     Escherichia_fergusonii  \n76883      Klebsiella_pneumoniae  \n2018      Streptococcus_pyogenes  \n133899      Campylobacter_jejuni  \n170373     Klebsiella_pneumoniae  \n...                          ...  \n119879  Streptococcus_pneumoniae  \n103694          Escherichia_coli  \n131932      Campylobacter_jejuni  \n146867        Enterococcus_hirae  \n121958    Streptococcus_pyogenes  \n\n[180000 rows x 34 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PC1</th>\n      <th>PC2</th>\n      <th>PC3</th>\n      <th>PC4</th>\n      <th>PC5</th>\n      <th>PC6</th>\n      <th>PC7</th>\n      <th>PC8</th>\n      <th>PC9</th>\n      <th>PC10</th>\n      <th>...</th>\n      <th>PC25</th>\n      <th>PC26</th>\n      <th>PC27</th>\n      <th>PC28</th>\n      <th>PC29</th>\n      <th>PC30</th>\n      <th>PC31</th>\n      <th>PC32</th>\n      <th>PC33</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>38762</th>\n      <td>-0.387754</td>\n      <td>-0.179544</td>\n      <td>-0.307261</td>\n      <td>0.005502</td>\n      <td>-0.083125</td>\n      <td>-0.075855</td>\n      <td>0.013105</td>\n      <td>0.037369</td>\n      <td>0.003686</td>\n      <td>-0.013009</td>\n      <td>...</td>\n      <td>0.002832</td>\n      <td>-0.004338</td>\n      <td>-0.001978</td>\n      <td>0.001167</td>\n      <td>0.000759</td>\n      <td>0.001539</td>\n      <td>-0.011899</td>\n      <td>-0.012244</td>\n      <td>-0.010960</td>\n      <td>Escherichia_fergusonii</td>\n    </tr>\n    <tr>\n      <th>76883</th>\n      <td>-0.447848</td>\n      <td>-0.157481</td>\n      <td>-0.116366</td>\n      <td>-0.052780</td>\n      <td>-0.074742</td>\n      <td>-0.113374</td>\n      <td>-0.005894</td>\n      <td>0.059995</td>\n      <td>-0.023750</td>\n      <td>-0.088320</td>\n      <td>...</td>\n      <td>-0.008838</td>\n      <td>0.000467</td>\n      <td>0.003741</td>\n      <td>0.004839</td>\n      <td>-0.011771</td>\n      <td>0.020994</td>\n      <td>0.007224</td>\n      <td>0.007783</td>\n      <td>-0.008084</td>\n      <td>Klebsiella_pneumoniae</td>\n    </tr>\n    <tr>\n      <th>2018</th>\n      <td>0.174330</td>\n      <td>-0.176383</td>\n      <td>-0.488638</td>\n      <td>-0.106370</td>\n      <td>-0.037568</td>\n      <td>-0.149143</td>\n      <td>0.007158</td>\n      <td>0.039391</td>\n      <td>0.002777</td>\n      <td>-0.026415</td>\n      <td>...</td>\n      <td>-0.002793</td>\n      <td>-0.009720</td>\n      <td>0.003231</td>\n      <td>-0.009156</td>\n      <td>0.005211</td>\n      <td>-0.001288</td>\n      <td>-0.008947</td>\n      <td>0.004727</td>\n      <td>0.000822</td>\n      <td>Streptococcus_pyogenes</td>\n    </tr>\n    <tr>\n      <th>133899</th>\n      <td>1.052958</td>\n      <td>-0.247346</td>\n      <td>0.172211</td>\n      <td>-0.018864</td>\n      <td>-0.111708</td>\n      <td>0.378535</td>\n      <td>-0.055296</td>\n      <td>0.011147</td>\n      <td>0.020262</td>\n      <td>0.001541</td>\n      <td>...</td>\n      <td>-0.008901</td>\n      <td>-0.002986</td>\n      <td>0.010563</td>\n      <td>0.015419</td>\n      <td>-0.017168</td>\n      <td>-0.003350</td>\n      <td>-0.006343</td>\n      <td>0.013677</td>\n      <td>-0.011666</td>\n      <td>Campylobacter_jejuni</td>\n    </tr>\n    <tr>\n      <th>170373</th>\n      <td>-0.531421</td>\n      <td>-0.007551</td>\n      <td>0.352724</td>\n      <td>-0.450606</td>\n      <td>0.890268</td>\n      <td>0.287516</td>\n      <td>0.035857</td>\n      <td>0.342573</td>\n      <td>-0.022159</td>\n      <td>0.056706</td>\n      <td>...</td>\n      <td>0.023627</td>\n      <td>0.012857</td>\n      <td>-0.024299</td>\n      <td>-0.000357</td>\n      <td>0.006838</td>\n      <td>0.011784</td>\n      <td>-0.001417</td>\n      <td>-0.014321</td>\n      <td>-0.013619</td>\n      <td>Klebsiella_pneumoniae</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>119879</th>\n      <td>0.040257</td>\n      <td>1.326085</td>\n      <td>0.101818</td>\n      <td>-0.244504</td>\n      <td>-0.204954</td>\n      <td>-0.000720</td>\n      <td>-0.516811</td>\n      <td>0.044313</td>\n      <td>-0.321465</td>\n      <td>0.138502</td>\n      <td>...</td>\n      <td>-0.039275</td>\n      <td>-0.026533</td>\n      <td>0.110822</td>\n      <td>0.118313</td>\n      <td>-0.015854</td>\n      <td>0.004991</td>\n      <td>0.177177</td>\n      <td>-0.094105</td>\n      <td>0.010459</td>\n      <td>Streptococcus_pneumoniae</td>\n    </tr>\n    <tr>\n      <th>103694</th>\n      <td>-0.430906</td>\n      <td>-0.170642</td>\n      <td>0.017309</td>\n      <td>0.001839</td>\n      <td>-0.084718</td>\n      <td>-0.071504</td>\n      <td>0.004567</td>\n      <td>0.050981</td>\n      <td>-0.009432</td>\n      <td>-0.027497</td>\n      <td>...</td>\n      <td>-0.003527</td>\n      <td>-0.004970</td>\n      <td>0.003683</td>\n      <td>0.003081</td>\n      <td>0.005589</td>\n      <td>0.000009</td>\n      <td>-0.007730</td>\n      <td>-0.000199</td>\n      <td>-0.009041</td>\n      <td>Escherichia_coli</td>\n    </tr>\n    <tr>\n      <th>131932</th>\n      <td>0.270503</td>\n      <td>-0.192393</td>\n      <td>0.160677</td>\n      <td>-0.049149</td>\n      <td>-0.092770</td>\n      <td>0.083745</td>\n      <td>-0.027371</td>\n      <td>0.039421</td>\n      <td>-0.004432</td>\n      <td>-0.055591</td>\n      <td>...</td>\n      <td>-0.006253</td>\n      <td>0.005661</td>\n      <td>0.004572</td>\n      <td>0.006198</td>\n      <td>-0.010724</td>\n      <td>0.008576</td>\n      <td>0.005099</td>\n      <td>0.005388</td>\n      <td>-0.011558</td>\n      <td>Campylobacter_jejuni</td>\n    </tr>\n    <tr>\n      <th>146867</th>\n      <td>0.596427</td>\n      <td>-0.217094</td>\n      <td>0.236906</td>\n      <td>-0.087065</td>\n      <td>-0.000230</td>\n      <td>-0.083391</td>\n      <td>0.056255</td>\n      <td>0.009120</td>\n      <td>-0.016778</td>\n      <td>0.021120</td>\n      <td>...</td>\n      <td>-0.062275</td>\n      <td>-0.043891</td>\n      <td>-0.089426</td>\n      <td>-0.014326</td>\n      <td>-0.002734</td>\n      <td>-0.035707</td>\n      <td>-0.020839</td>\n      <td>0.015417</td>\n      <td>0.040340</td>\n      <td>Enterococcus_hirae</td>\n    </tr>\n    <tr>\n      <th>121958</th>\n      <td>0.176430</td>\n      <td>-0.177690</td>\n      <td>0.111048</td>\n      <td>-0.099110</td>\n      <td>-0.046072</td>\n      <td>-0.154966</td>\n      <td>0.003600</td>\n      <td>0.039020</td>\n      <td>0.000798</td>\n      <td>-0.027285</td>\n      <td>...</td>\n      <td>0.001123</td>\n      <td>0.005724</td>\n      <td>-0.003694</td>\n      <td>-0.016650</td>\n      <td>0.002535</td>\n      <td>0.001118</td>\n      <td>-0.004394</td>\n      <td>0.001741</td>\n      <td>0.001484</td>\n      <td>Streptococcus_pyogenes</td>\n    </tr>\n  </tbody>\n</table>\n<p>180000 rows × 34 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"                ##       K-MEAN\nimport pandas as pd\nimport cupy as cp  # Assuming you have CuPy installed\nfrom cuml.cluster import KMeans as cuKMeans  # Assuming you have cuML installed\n\n# Assuming you have your data in a DataFrame called df\n# Features used for clustering (adjust as needed)\n# features_for_clustering = ['feature1', 'feature2', 'feature3']\n\n# Number of clusters (adjust as needed)\nnum_clusters = 1000\n\n# Assuming you have a DataFrame called pca_df\n# Fit K-means model using cuML\nkmeans = cuKMeans(n_clusters=num_clusters, random_state=0, n_init=100)\nX_train_new['cluster_id'] = kmeans.fit_predict(cp.asarray(X_train_new.drop('target', axis=1))).get()\n\n# Initialize a new DataFrame for the optimized data\nnew_df = pd.DataFrame()\n\n# Loop through each cluster\nfor cluster_id in range(num_clusters):\n    each_cluster = X_train_new[X_train_new['cluster_id'].values == cluster_id]\n    \n    # Check if the cluster is not empty\n    if not each_cluster.empty:\n        # Calculate the predominant class in the cluster\n        predominant_class = each_cluster['target'].value_counts().idxmax()\n        \n        # Filter records of the predominant class\n        each_cluster_filtered = each_cluster[each_cluster['target'] == predominant_class]\n        \n        # Calculate the average of the records in the cluster\n        averaged_record = each_cluster_filtered.mean(numeric_only=True)\n        \n        # Assign the predominant class to the averaged record\n        averaged_record['target'] = predominant_class\n        \n        # Append the averaged record to the new DataFrame\n        new_df = pd.concat([new_df, averaged_record.to_frame().transpose()], ignore_index=True)\n\n# Display the new DataFrame\n# print(new_df)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:12:14.458344Z","iopub.execute_input":"2023-12-18T16:12:14.458715Z","iopub.status.idle":"2023-12-18T16:27:51.587432Z","shell.execute_reply.started":"2023-12-18T16:12:14.458680Z","shell.execute_reply":"2023-12-18T16:27:51.586559Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"new_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:29:53.347015Z","iopub.execute_input":"2023-12-18T16:29:53.347672Z","iopub.status.idle":"2023-12-18T16:29:53.353857Z","shell.execute_reply.started":"2023-12-18T16:29:53.347643Z","shell.execute_reply":"2023-12-18T16:29:53.352967Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"(1000, 35)"},"metadata":{}}]},{"cell_type":"code","source":"new_df","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:29:57.658818Z","iopub.execute_input":"2023-12-18T16:29:57.659159Z","iopub.status.idle":"2023-12-18T16:29:57.684824Z","shell.execute_reply.started":"2023-12-18T16:29:57.659132Z","shell.execute_reply":"2023-12-18T16:29:57.683777Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"          PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n0    0.785976   0.50309  0.198195  0.482415  0.246652 -0.040396  0.217061   \n1    0.532899  0.496166  0.169969  0.462912    0.2746 -0.257008  0.284317   \n2    0.082737 -0.066362 -0.100283 -0.081661  0.187028 -0.127311 -0.023701   \n3   -0.008497   0.42385  0.161494  0.569572  0.358063 -0.259363  0.223901   \n4   -0.268554  0.876711 -0.138526  0.588051  0.031966 -0.019329 -0.377922   \n..        ...       ...       ...       ...       ...       ...       ...   \n995  0.730362 -0.104258  0.031437 -0.070826 -0.047016  0.044075  0.027851   \n996 -0.210352  0.166974 -0.307955  0.248888 -0.063712 -0.052602  0.178131   \n997 -0.495831 -0.147776 -0.017177  0.124999 -0.108715 -0.087134 -0.018306   \n998  0.189642 -0.115956  -0.07823 -0.111868  0.109624  -0.19977 -0.057725   \n999 -0.366479  -0.23769  0.013608  0.072782 -0.167844  0.249494  0.084712   \n\n          PC8       PC9      PC10  ...      PC26      PC27      PC28  \\\n0    0.015569 -0.181787 -0.090103  ...  0.100143   0.15386 -0.067116   \n1   -0.023628 -0.198051 -0.057232  ...  0.075158  0.048967   0.05598   \n2   -0.260229  0.049308  0.013699  ...  0.022388  0.006293  0.013302   \n3    0.081972 -0.151949 -0.139223  ... -0.061519 -0.109166  0.001818   \n4    0.160385  0.414027  0.031031  ... -0.104005  0.086334 -0.163204   \n..        ...       ...       ...  ...       ...       ...       ...   \n995 -0.010321 -0.042574  0.230815  ...  -0.22262  0.235124 -0.118417   \n996 -0.012154 -0.019916  0.314165  ...  0.118524  0.114389 -0.231321   \n997  0.079046 -0.098513 -0.060328  ...  0.051045 -0.037086  0.006443   \n998 -0.171625 -0.037911  0.249202  ...  0.071815 -0.119955 -0.058446   \n999  0.128363 -0.160145   0.30148  ... -0.025332  0.140324  0.342542   \n\n         PC29      PC30      PC31      PC32      PC33 cluster_id  \\\n0    0.050709  0.027281 -0.077669  0.102086 -0.067866        0.0   \n1   -0.061085 -0.222276 -0.043654  0.055269 -0.075333        1.0   \n2   -0.007414 -0.004992 -0.014726  0.013096  0.008839        2.0   \n3   -0.252313 -0.062928  0.082873  0.080653 -0.036103        3.0   \n4   -0.192725   0.18161  0.005344   0.17716   -0.0266        4.0   \n..        ...       ...       ...       ...       ...        ...   \n995 -0.056489 -0.267788  0.003453 -0.034366 -0.071991      995.0   \n996 -0.276458 -0.137625 -0.087217  0.000994 -0.047622      996.0   \n997 -0.029451  0.076969 -0.008335 -0.088125 -0.052473      997.0   \n998 -0.195442  0.125183 -0.004472  0.148781 -0.080353      998.0   \n999  0.448241 -0.048224  0.167085  0.294912 -0.245609      999.0   \n\n                       target  \n0       Staphylococcus_aureus  \n1      Streptococcus_pyogenes  \n2    Streptococcus_pneumoniae  \n3            Escherichia_coli  \n4       Klebsiella_pneumoniae  \n..                        ...  \n995        Enterococcus_hirae  \n996          Escherichia_coli  \n997       Salmonella_enterica  \n998  Streptococcus_pneumoniae  \n999          Escherichia_coli  \n\n[1000 rows x 35 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PC1</th>\n      <th>PC2</th>\n      <th>PC3</th>\n      <th>PC4</th>\n      <th>PC5</th>\n      <th>PC6</th>\n      <th>PC7</th>\n      <th>PC8</th>\n      <th>PC9</th>\n      <th>PC10</th>\n      <th>...</th>\n      <th>PC26</th>\n      <th>PC27</th>\n      <th>PC28</th>\n      <th>PC29</th>\n      <th>PC30</th>\n      <th>PC31</th>\n      <th>PC32</th>\n      <th>PC33</th>\n      <th>cluster_id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.785976</td>\n      <td>0.50309</td>\n      <td>0.198195</td>\n      <td>0.482415</td>\n      <td>0.246652</td>\n      <td>-0.040396</td>\n      <td>0.217061</td>\n      <td>0.015569</td>\n      <td>-0.181787</td>\n      <td>-0.090103</td>\n      <td>...</td>\n      <td>0.100143</td>\n      <td>0.15386</td>\n      <td>-0.067116</td>\n      <td>0.050709</td>\n      <td>0.027281</td>\n      <td>-0.077669</td>\n      <td>0.102086</td>\n      <td>-0.067866</td>\n      <td>0.0</td>\n      <td>Staphylococcus_aureus</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.532899</td>\n      <td>0.496166</td>\n      <td>0.169969</td>\n      <td>0.462912</td>\n      <td>0.2746</td>\n      <td>-0.257008</td>\n      <td>0.284317</td>\n      <td>-0.023628</td>\n      <td>-0.198051</td>\n      <td>-0.057232</td>\n      <td>...</td>\n      <td>0.075158</td>\n      <td>0.048967</td>\n      <td>0.05598</td>\n      <td>-0.061085</td>\n      <td>-0.222276</td>\n      <td>-0.043654</td>\n      <td>0.055269</td>\n      <td>-0.075333</td>\n      <td>1.0</td>\n      <td>Streptococcus_pyogenes</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.082737</td>\n      <td>-0.066362</td>\n      <td>-0.100283</td>\n      <td>-0.081661</td>\n      <td>0.187028</td>\n      <td>-0.127311</td>\n      <td>-0.023701</td>\n      <td>-0.260229</td>\n      <td>0.049308</td>\n      <td>0.013699</td>\n      <td>...</td>\n      <td>0.022388</td>\n      <td>0.006293</td>\n      <td>0.013302</td>\n      <td>-0.007414</td>\n      <td>-0.004992</td>\n      <td>-0.014726</td>\n      <td>0.013096</td>\n      <td>0.008839</td>\n      <td>2.0</td>\n      <td>Streptococcus_pneumoniae</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.008497</td>\n      <td>0.42385</td>\n      <td>0.161494</td>\n      <td>0.569572</td>\n      <td>0.358063</td>\n      <td>-0.259363</td>\n      <td>0.223901</td>\n      <td>0.081972</td>\n      <td>-0.151949</td>\n      <td>-0.139223</td>\n      <td>...</td>\n      <td>-0.061519</td>\n      <td>-0.109166</td>\n      <td>0.001818</td>\n      <td>-0.252313</td>\n      <td>-0.062928</td>\n      <td>0.082873</td>\n      <td>0.080653</td>\n      <td>-0.036103</td>\n      <td>3.0</td>\n      <td>Escherichia_coli</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.268554</td>\n      <td>0.876711</td>\n      <td>-0.138526</td>\n      <td>0.588051</td>\n      <td>0.031966</td>\n      <td>-0.019329</td>\n      <td>-0.377922</td>\n      <td>0.160385</td>\n      <td>0.414027</td>\n      <td>0.031031</td>\n      <td>...</td>\n      <td>-0.104005</td>\n      <td>0.086334</td>\n      <td>-0.163204</td>\n      <td>-0.192725</td>\n      <td>0.18161</td>\n      <td>0.005344</td>\n      <td>0.17716</td>\n      <td>-0.0266</td>\n      <td>4.0</td>\n      <td>Klebsiella_pneumoniae</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>0.730362</td>\n      <td>-0.104258</td>\n      <td>0.031437</td>\n      <td>-0.070826</td>\n      <td>-0.047016</td>\n      <td>0.044075</td>\n      <td>0.027851</td>\n      <td>-0.010321</td>\n      <td>-0.042574</td>\n      <td>0.230815</td>\n      <td>...</td>\n      <td>-0.22262</td>\n      <td>0.235124</td>\n      <td>-0.118417</td>\n      <td>-0.056489</td>\n      <td>-0.267788</td>\n      <td>0.003453</td>\n      <td>-0.034366</td>\n      <td>-0.071991</td>\n      <td>995.0</td>\n      <td>Enterococcus_hirae</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>-0.210352</td>\n      <td>0.166974</td>\n      <td>-0.307955</td>\n      <td>0.248888</td>\n      <td>-0.063712</td>\n      <td>-0.052602</td>\n      <td>0.178131</td>\n      <td>-0.012154</td>\n      <td>-0.019916</td>\n      <td>0.314165</td>\n      <td>...</td>\n      <td>0.118524</td>\n      <td>0.114389</td>\n      <td>-0.231321</td>\n      <td>-0.276458</td>\n      <td>-0.137625</td>\n      <td>-0.087217</td>\n      <td>0.000994</td>\n      <td>-0.047622</td>\n      <td>996.0</td>\n      <td>Escherichia_coli</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>-0.495831</td>\n      <td>-0.147776</td>\n      <td>-0.017177</td>\n      <td>0.124999</td>\n      <td>-0.108715</td>\n      <td>-0.087134</td>\n      <td>-0.018306</td>\n      <td>0.079046</td>\n      <td>-0.098513</td>\n      <td>-0.060328</td>\n      <td>...</td>\n      <td>0.051045</td>\n      <td>-0.037086</td>\n      <td>0.006443</td>\n      <td>-0.029451</td>\n      <td>0.076969</td>\n      <td>-0.008335</td>\n      <td>-0.088125</td>\n      <td>-0.052473</td>\n      <td>997.0</td>\n      <td>Salmonella_enterica</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>0.189642</td>\n      <td>-0.115956</td>\n      <td>-0.07823</td>\n      <td>-0.111868</td>\n      <td>0.109624</td>\n      <td>-0.19977</td>\n      <td>-0.057725</td>\n      <td>-0.171625</td>\n      <td>-0.037911</td>\n      <td>0.249202</td>\n      <td>...</td>\n      <td>0.071815</td>\n      <td>-0.119955</td>\n      <td>-0.058446</td>\n      <td>-0.195442</td>\n      <td>0.125183</td>\n      <td>-0.004472</td>\n      <td>0.148781</td>\n      <td>-0.080353</td>\n      <td>998.0</td>\n      <td>Streptococcus_pneumoniae</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>-0.366479</td>\n      <td>-0.23769</td>\n      <td>0.013608</td>\n      <td>0.072782</td>\n      <td>-0.167844</td>\n      <td>0.249494</td>\n      <td>0.084712</td>\n      <td>0.128363</td>\n      <td>-0.160145</td>\n      <td>0.30148</td>\n      <td>...</td>\n      <td>-0.025332</td>\n      <td>0.140324</td>\n      <td>0.342542</td>\n      <td>0.448241</td>\n      <td>-0.048224</td>\n      <td>0.167085</td>\n      <td>0.294912</td>\n      <td>-0.245609</td>\n      <td>999.0</td>\n      <td>Escherichia_coli</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 35 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X_1 = new_df.drop(columns=['target','cluster_id'])  # Extract all feature columns except 'target'\ny_1 = new_df['target']","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:30:08.087089Z","iopub.execute_input":"2023-12-18T16:30:08.087738Z","iopub.status.idle":"2023-12-18T16:30:08.094007Z","shell.execute_reply.started":"2023-12-18T16:30:08.087708Z","shell.execute_reply":"2023-12-18T16:30:08.093017Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"X_1","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:57:11.796347Z","iopub.execute_input":"2023-12-18T16:57:11.797160Z","iopub.status.idle":"2023-12-18T16:57:11.822460Z","shell.execute_reply.started":"2023-12-18T16:57:11.797127Z","shell.execute_reply":"2023-12-18T16:57:11.821476Z"},"trusted":true},"execution_count":89,"outputs":[{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"          PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n0    0.785976   0.50309  0.198195  0.482415  0.246652 -0.040396  0.217061   \n1    0.532899  0.496166  0.169969  0.462912    0.2746 -0.257008  0.284317   \n2    0.082737 -0.066362 -0.100283 -0.081661  0.187028 -0.127311 -0.023701   \n3   -0.008497   0.42385  0.161494  0.569572  0.358063 -0.259363  0.223901   \n4   -0.268554  0.876711 -0.138526  0.588051  0.031966 -0.019329 -0.377922   \n..        ...       ...       ...       ...       ...       ...       ...   \n995  0.730362 -0.104258  0.031437 -0.070826 -0.047016  0.044075  0.027851   \n996 -0.210352  0.166974 -0.307955  0.248888 -0.063712 -0.052602  0.178131   \n997 -0.495831 -0.147776 -0.017177  0.124999 -0.108715 -0.087134 -0.018306   \n998  0.189642 -0.115956  -0.07823 -0.111868  0.109624  -0.19977 -0.057725   \n999 -0.366479  -0.23769  0.013608  0.072782 -0.167844  0.249494  0.084712   \n\n          PC8       PC9      PC10  ...      PC24      PC25      PC26  \\\n0    0.015569 -0.181787 -0.090103  ...  0.189049 -0.216528  0.100143   \n1   -0.023628 -0.198051 -0.057232  ...  0.017982  0.050963  0.075158   \n2   -0.260229  0.049308  0.013699  ...  0.012807 -0.001718  0.022388   \n3    0.081972 -0.151949 -0.139223  ...  0.078126 -0.097074 -0.061519   \n4    0.160385  0.414027  0.031031  ... -0.076328  0.197198 -0.104005   \n..        ...       ...       ...  ...       ...       ...       ...   \n995 -0.010321 -0.042574  0.230815  ... -0.070765 -0.103475  -0.22262   \n996 -0.012154 -0.019916  0.314165  ... -0.118009 -0.123828  0.118524   \n997  0.079046 -0.098513 -0.060328  ... -0.012696 -0.188808  0.051045   \n998 -0.171625 -0.037911  0.249202  ...  -0.00539  0.106479  0.071815   \n999  0.128363 -0.160145   0.30148  ...  0.238641  0.186978 -0.025332   \n\n         PC27      PC28      PC29      PC30      PC31      PC32      PC33  \n0     0.15386 -0.067116  0.050709  0.027281 -0.077669  0.102086 -0.067866  \n1    0.048967   0.05598 -0.061085 -0.222276 -0.043654  0.055269 -0.075333  \n2    0.006293  0.013302 -0.007414 -0.004992 -0.014726  0.013096  0.008839  \n3   -0.109166  0.001818 -0.252313 -0.062928  0.082873  0.080653 -0.036103  \n4    0.086334 -0.163204 -0.192725   0.18161  0.005344   0.17716   -0.0266  \n..        ...       ...       ...       ...       ...       ...       ...  \n995  0.235124 -0.118417 -0.056489 -0.267788  0.003453 -0.034366 -0.071991  \n996  0.114389 -0.231321 -0.276458 -0.137625 -0.087217  0.000994 -0.047622  \n997 -0.037086  0.006443 -0.029451  0.076969 -0.008335 -0.088125 -0.052473  \n998 -0.119955 -0.058446 -0.195442  0.125183 -0.004472  0.148781 -0.080353  \n999  0.140324  0.342542  0.448241 -0.048224  0.167085  0.294912 -0.245609  \n\n[1000 rows x 33 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PC1</th>\n      <th>PC2</th>\n      <th>PC3</th>\n      <th>PC4</th>\n      <th>PC5</th>\n      <th>PC6</th>\n      <th>PC7</th>\n      <th>PC8</th>\n      <th>PC9</th>\n      <th>PC10</th>\n      <th>...</th>\n      <th>PC24</th>\n      <th>PC25</th>\n      <th>PC26</th>\n      <th>PC27</th>\n      <th>PC28</th>\n      <th>PC29</th>\n      <th>PC30</th>\n      <th>PC31</th>\n      <th>PC32</th>\n      <th>PC33</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.785976</td>\n      <td>0.50309</td>\n      <td>0.198195</td>\n      <td>0.482415</td>\n      <td>0.246652</td>\n      <td>-0.040396</td>\n      <td>0.217061</td>\n      <td>0.015569</td>\n      <td>-0.181787</td>\n      <td>-0.090103</td>\n      <td>...</td>\n      <td>0.189049</td>\n      <td>-0.216528</td>\n      <td>0.100143</td>\n      <td>0.15386</td>\n      <td>-0.067116</td>\n      <td>0.050709</td>\n      <td>0.027281</td>\n      <td>-0.077669</td>\n      <td>0.102086</td>\n      <td>-0.067866</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.532899</td>\n      <td>0.496166</td>\n      <td>0.169969</td>\n      <td>0.462912</td>\n      <td>0.2746</td>\n      <td>-0.257008</td>\n      <td>0.284317</td>\n      <td>-0.023628</td>\n      <td>-0.198051</td>\n      <td>-0.057232</td>\n      <td>...</td>\n      <td>0.017982</td>\n      <td>0.050963</td>\n      <td>0.075158</td>\n      <td>0.048967</td>\n      <td>0.05598</td>\n      <td>-0.061085</td>\n      <td>-0.222276</td>\n      <td>-0.043654</td>\n      <td>0.055269</td>\n      <td>-0.075333</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.082737</td>\n      <td>-0.066362</td>\n      <td>-0.100283</td>\n      <td>-0.081661</td>\n      <td>0.187028</td>\n      <td>-0.127311</td>\n      <td>-0.023701</td>\n      <td>-0.260229</td>\n      <td>0.049308</td>\n      <td>0.013699</td>\n      <td>...</td>\n      <td>0.012807</td>\n      <td>-0.001718</td>\n      <td>0.022388</td>\n      <td>0.006293</td>\n      <td>0.013302</td>\n      <td>-0.007414</td>\n      <td>-0.004992</td>\n      <td>-0.014726</td>\n      <td>0.013096</td>\n      <td>0.008839</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.008497</td>\n      <td>0.42385</td>\n      <td>0.161494</td>\n      <td>0.569572</td>\n      <td>0.358063</td>\n      <td>-0.259363</td>\n      <td>0.223901</td>\n      <td>0.081972</td>\n      <td>-0.151949</td>\n      <td>-0.139223</td>\n      <td>...</td>\n      <td>0.078126</td>\n      <td>-0.097074</td>\n      <td>-0.061519</td>\n      <td>-0.109166</td>\n      <td>0.001818</td>\n      <td>-0.252313</td>\n      <td>-0.062928</td>\n      <td>0.082873</td>\n      <td>0.080653</td>\n      <td>-0.036103</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.268554</td>\n      <td>0.876711</td>\n      <td>-0.138526</td>\n      <td>0.588051</td>\n      <td>0.031966</td>\n      <td>-0.019329</td>\n      <td>-0.377922</td>\n      <td>0.160385</td>\n      <td>0.414027</td>\n      <td>0.031031</td>\n      <td>...</td>\n      <td>-0.076328</td>\n      <td>0.197198</td>\n      <td>-0.104005</td>\n      <td>0.086334</td>\n      <td>-0.163204</td>\n      <td>-0.192725</td>\n      <td>0.18161</td>\n      <td>0.005344</td>\n      <td>0.17716</td>\n      <td>-0.0266</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>0.730362</td>\n      <td>-0.104258</td>\n      <td>0.031437</td>\n      <td>-0.070826</td>\n      <td>-0.047016</td>\n      <td>0.044075</td>\n      <td>0.027851</td>\n      <td>-0.010321</td>\n      <td>-0.042574</td>\n      <td>0.230815</td>\n      <td>...</td>\n      <td>-0.070765</td>\n      <td>-0.103475</td>\n      <td>-0.22262</td>\n      <td>0.235124</td>\n      <td>-0.118417</td>\n      <td>-0.056489</td>\n      <td>-0.267788</td>\n      <td>0.003453</td>\n      <td>-0.034366</td>\n      <td>-0.071991</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>-0.210352</td>\n      <td>0.166974</td>\n      <td>-0.307955</td>\n      <td>0.248888</td>\n      <td>-0.063712</td>\n      <td>-0.052602</td>\n      <td>0.178131</td>\n      <td>-0.012154</td>\n      <td>-0.019916</td>\n      <td>0.314165</td>\n      <td>...</td>\n      <td>-0.118009</td>\n      <td>-0.123828</td>\n      <td>0.118524</td>\n      <td>0.114389</td>\n      <td>-0.231321</td>\n      <td>-0.276458</td>\n      <td>-0.137625</td>\n      <td>-0.087217</td>\n      <td>0.000994</td>\n      <td>-0.047622</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>-0.495831</td>\n      <td>-0.147776</td>\n      <td>-0.017177</td>\n      <td>0.124999</td>\n      <td>-0.108715</td>\n      <td>-0.087134</td>\n      <td>-0.018306</td>\n      <td>0.079046</td>\n      <td>-0.098513</td>\n      <td>-0.060328</td>\n      <td>...</td>\n      <td>-0.012696</td>\n      <td>-0.188808</td>\n      <td>0.051045</td>\n      <td>-0.037086</td>\n      <td>0.006443</td>\n      <td>-0.029451</td>\n      <td>0.076969</td>\n      <td>-0.008335</td>\n      <td>-0.088125</td>\n      <td>-0.052473</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>0.189642</td>\n      <td>-0.115956</td>\n      <td>-0.07823</td>\n      <td>-0.111868</td>\n      <td>0.109624</td>\n      <td>-0.19977</td>\n      <td>-0.057725</td>\n      <td>-0.171625</td>\n      <td>-0.037911</td>\n      <td>0.249202</td>\n      <td>...</td>\n      <td>-0.00539</td>\n      <td>0.106479</td>\n      <td>0.071815</td>\n      <td>-0.119955</td>\n      <td>-0.058446</td>\n      <td>-0.195442</td>\n      <td>0.125183</td>\n      <td>-0.004472</td>\n      <td>0.148781</td>\n      <td>-0.080353</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>-0.366479</td>\n      <td>-0.23769</td>\n      <td>0.013608</td>\n      <td>0.072782</td>\n      <td>-0.167844</td>\n      <td>0.249494</td>\n      <td>0.084712</td>\n      <td>0.128363</td>\n      <td>-0.160145</td>\n      <td>0.30148</td>\n      <td>...</td>\n      <td>0.238641</td>\n      <td>0.186978</td>\n      <td>-0.025332</td>\n      <td>0.140324</td>\n      <td>0.342542</td>\n      <td>0.448241</td>\n      <td>-0.048224</td>\n      <td>0.167085</td>\n      <td>0.294912</td>\n      <td>-0.245609</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 33 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"y_1","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:56:50.410633Z","iopub.execute_input":"2023-12-18T16:56:50.411009Z","iopub.status.idle":"2023-12-18T16:56:50.419354Z","shell.execute_reply.started":"2023-12-18T16:56:50.410980Z","shell.execute_reply":"2023-12-18T16:56:50.418305Z"},"trusted":true},"execution_count":87,"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"0         Staphylococcus_aureus\n1        Streptococcus_pyogenes\n2      Streptococcus_pneumoniae\n3              Escherichia_coli\n4         Klebsiella_pneumoniae\n                 ...           \n995          Enterococcus_hirae\n996            Escherichia_coli\n997         Salmonella_enterica\n998    Streptococcus_pneumoniae\n999            Escherichia_coli\nName: target, Length: 1000, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n\n# X_trainnew, X_val, y_trainnew, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T06:03:32.258556Z","iopub.execute_input":"2023-12-18T06:03:32.259381Z","iopub.status.idle":"2023-12-18T06:03:32.265979Z","shell.execute_reply.started":"2023-12-18T06:03:32.259347Z","shell.execute_reply":"2023-12-18T06:03:32.264944Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# y_trainnew","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:26:53.481423Z","iopub.execute_input":"2023-12-18T08:26:53.482251Z","iopub.status.idle":"2023-12-18T08:26:53.486248Z","shell.execute_reply.started":"2023-12-18T08:26:53.482215Z","shell.execute_reply":"2023-12-18T08:26:53.485250Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"# y_val","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:26:51.314749Z","iopub.execute_input":"2023-12-18T08:26:51.315091Z","iopub.status.idle":"2023-12-18T08:26:51.319785Z","shell.execute_reply.started":"2023-12-18T08:26:51.315065Z","shell.execute_reply":"2023-12-18T08:26:51.318700Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# X_trainnew","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:26:57.277973Z","iopub.execute_input":"2023-12-18T08:26:57.279137Z","iopub.status.idle":"2023-12-18T08:26:57.283047Z","shell.execute_reply.started":"2023-12-18T08:26:57.279105Z","shell.execute_reply":"2023-12-18T08:26:57.282277Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# X_val   X_val, , y_val,X_1, y_1","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:27:06.634450Z","iopub.execute_input":"2023-12-18T08:27:06.635151Z","iopub.status.idle":"2023-12-18T08:27:06.638967Z","shell.execute_reply.started":"2023-12-18T08:27:06.635118Z","shell.execute_reply":"2023-12-18T08:27:06.638056Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# X_val,  y_val","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\n  # Initialize the Random Forest Classifier\nrf_classifier = RandomForestClassifier(n_estimators = 30, max_depth = 6)  # You can adjust n_estimators\n # You can adjust n_estimators\n# Train the Random Forest Model\nrf_classifier.fit(X_1, y_1)\n# Step 4: Model Evaluation\n# y_pred = rf_classifier.predict(pca_df_test)  # Predict on Test Data\ny_pred = rf_classifier.predict(X_val)  # Predict on Test Data\n\naccuracy = accuracy_score(y_val, y_pred,)\naccuracy_percent = accuracy * 100\nprint(f\"Accuracy: {accuracy_percent:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-12-18T17:02:36.516376Z","iopub.execute_input":"2023-12-18T17:02:36.517279Z","iopub.status.idle":"2023-12-18T17:02:36.762548Z","shell.execute_reply.started":"2023-12-18T17:02:36.517245Z","shell.execute_reply":"2023-12-18T17:02:36.761644Z"},"trusted":true},"execution_count":106,"outputs":[{"name":"stdout","text":"Accuracy: 52.55%\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\n  # Initialize the Random Forest Classifier\nrf_classifier = RandomForestClassifier( n_estimators=30, max_depth=6)  # You can adjust n_estimators\n # You can adjust n_estimators\n# Train the Random Forest Model\nrf_classifier.fit(X_1, y_1)\n# Step 4: Model Evaluation\n# y_pred = rf_classifier.predict(pca_df_test)  # Predict on Test Data\ny_pred = rf_classifier.predict(X_1)  # Predict on Test Data\n\naccuracy = accuracy_score(y_1, y_pred,)\naccuracy_percent = accuracy * 100\nprint(f\"Accuracy: {accuracy_percent:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-12-18T17:01:46.377062Z","iopub.execute_input":"2023-12-18T17:01:46.377472Z","iopub.status.idle":"2023-12-18T17:01:46.532875Z","shell.execute_reply.started":"2023-12-18T17:01:46.377440Z","shell.execute_reply":"2023-12-18T17:01:46.531747Z"},"trusted":true},"execution_count":105,"outputs":[{"name":"stdout","text":"Accuracy: 90.60%\n","output_type":"stream"}]},{"cell_type":"code","source":"# X_val, , y_val,X_1, y_1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" ## 2. AdaBoost Algorithm\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n # Step 3: Initialize the base estimator (Decision Tree)\nbase_estimator = DecisionTreeClassifier(max_depth=3)  # You can adjust max_depth\n # Step 4: Initialize the AdaBoost Classifier\nadaboost_classifier = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=50,random_state=32)\n# You can adjust n_estimators (number of weak learners)max_depth=3,random_state=32\n # Step 5: Train the AdaBoost Model\nadaboost_classifier.fit(X_1, y_1)\n # Step 6: Model Evaluation\ny_pred = adaboost_classifier.predict(X_val)\naccuracy = accuracy_score(y_val, y_pred)\n# report = classification_report(y_true, y_pred,zero_division=1)\n\naccuracy_percent = accuracy * 100\nprint(f\"Accuracy_train: {accuracy_percent:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:32:34.750288Z","iopub.execute_input":"2023-12-18T16:32:34.751158Z","iopub.status.idle":"2023-12-18T16:32:36.033017Z","shell.execute_reply.started":"2023-12-18T16:32:34.751124Z","shell.execute_reply":"2023-12-18T16:32:36.032095Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Accuracy_train: 47.98%\n","output_type":"stream"}]},{"cell_type":"code","source":" ## 2. AdaBoost Algorithm\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n # Step 3: Initialize the base estimator (Decision Tree)\nbase_estimator = DecisionTreeClassifier(max_depth=3)  # You can adjust max_depth\n # Step 4: Initialize the AdaBoost Classifier\nadaboost_classifier = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=50,random_state=32)\n# You can adjust n_estimators (number of weak learners)max_depth=3,random_state=32\n # Step 5: Train the AdaBoost Model\nadaboost_classifier.fit(X_1, y_1)\n # Step 6: Model Evaluation\ny_pred = adaboost_classifier.predict(X_1)\naccuracy_test_2 = accuracy_score(y_1, y_pred)\n# report = classification_report(y_true, y_pred,zero_division=1)\n\naccuracy_percent_test = accuracy_test_2 * 100\nprint(f\"Accuracy: {accuracy_percent_test:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:36:18.415601Z","iopub.execute_input":"2023-12-18T16:36:18.415940Z","iopub.status.idle":"2023-12-18T16:36:19.578087Z","shell.execute_reply.started":"2023-12-18T16:36:18.415916Z","shell.execute_reply":"2023-12-18T16:36:19.577220Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 73.50%\n","output_type":"stream"}]},{"cell_type":"code","source":"# X_val, , y_val,X_1, y_1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3. ************  Naive Bayes Algorithm  ************\n#     for test\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score\n# Create a pipeline with MinMaxScaler and Gaussian Naive Bayes\npipeline = Pipeline([\n        ('scaler', StandardScaler()),  # Change the scaler\n        ('classifier', GaussianNB())  # Gaussian Naive Bayes classifier\n])\n\n# Train the model using the pipeline\npipeline.fit(X_1, y_1)\n\n# Make predictions on the test set\ny_pred = pipeline.predict(X_1)\n\n# Evaluate the model\naccuracy = accuracy_score(y_1, y_pred)\n\naccuracy_percent = accuracy * 100\nprint(f\"Accuracy_3: {accuracy_percent:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:36:33.818965Z","iopub.execute_input":"2023-12-18T16:36:33.819307Z","iopub.status.idle":"2023-12-18T16:36:33.865658Z","shell.execute_reply.started":"2023-12-18T16:36:33.819282Z","shell.execute_reply":"2023-12-18T16:36:33.864743Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Accuracy_3: 68.50%\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score\n# Step 2: Create and train the Gaussian Naive Bayes model\nnaive_bayes_model = GaussianNB()\nnaive_bayes_model.fit(X_1, y_1)\n\n# Step 3: Make predictions on the test set\ny_pred_test = naive_bayes_model.predict(X_val)\n\n# Step 4: Evaluate the model\ntest_accuracy = accuracy_score(y_val, y_pred_test)\n\naccuracy_percent = test_accuracy * 100\nprint(f\"Accuracy_3: {accuracy_percent:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-12-18T16:37:41.464417Z","iopub.execute_input":"2023-12-18T16:37:41.464777Z","iopub.status.idle":"2023-12-18T16:37:41.542710Z","shell.execute_reply.started":"2023-12-18T16:37:41.464751Z","shell.execute_reply":"2023-12-18T16:37:41.541767Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"Accuracy_3: 43.75%\n","output_type":"stream"}]},{"cell_type":"code","source":"# X_val   y_val,","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## 4. SVM - Support Vector Machines code\n\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Initialize the Support Vector Machine classifier\n# You can adjust the kernel (linear, polynomial, radial basis function, etc.) and other hyperparameters\n\n# svm_classifier = SVC(kernel='linear', random_state=42,C=1.0)\nsvm_classifier = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n# svm_classifier = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n\n\n# Train the classifier on the training data\nsvm_classifier.fit(X_1, y_1)\n\n# Make predictions on the test data\ny_pred = svm_classifier.predict(X_val)\n\n# Evaluate the model\n# accuracy_4 = accuracy_score(y_1, y_pred)\naccuracy_4 = accuracy_score(y_val, y_pred)\n\naccuracy_percent_4 = accuracy_4 * 100\nprint(f\"Accuracy: {accuracy_percent_4:.2f}%\") ","metadata":{"execution":{"iopub.status.busy":"2023-12-18T17:11:03.555470Z","iopub.execute_input":"2023-12-18T17:11:03.556221Z","iopub.status.idle":"2023-12-18T17:11:05.595468Z","shell.execute_reply.started":"2023-12-18T17:11:03.556186Z","shell.execute_reply":"2023-12-18T17:11:05.594447Z"},"trusted":true},"execution_count":136,"outputs":[{"name":"stdout","text":"Accuracy: 51.59%\n","output_type":"stream"}]},{"cell_type":"code","source":"\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\n\n# Initialize the Support Vector Machine classifier\n# You can adjust the kernel (linear, polynomial, radial basis function, etc.) and other hyperparameters\n\n# svm_classifier = SVC(kernel='linear', random_state=42,C=1.0)\nsvm_classifier = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n\n# svm_classifier = SVC(kernel='rbf', C=1.0, gamma='auto', random_state=32)\n\n\n# Train the classifier on the training data\nsvm_classifier.fit(X_1, y_1)\n\n# Make predictions on the test data\ny_pred = svm_classifier.predict(X_1)\n\n# Evaluate the model\n# accuracy_4 = accuracy_score(y_1, y_pred)\naccuracy = accuracy_score(y_1, y_pred)\n\naccuracy_percent = accuracy * 100\nprint(f\"Accuracy: {accuracy_percent:.2f}%\") ","metadata":{"execution":{"iopub.status.busy":"2023-12-18T17:12:54.012687Z","iopub.execute_input":"2023-12-18T17:12:54.013650Z","iopub.status.idle":"2023-12-18T17:12:54.189411Z","shell.execute_reply.started":"2023-12-18T17:12:54.013615Z","shell.execute_reply":"2023-12-18T17:12:54.188461Z"},"trusted":true},"execution_count":143,"outputs":[{"name":"stdout","text":"Accuracy: 88.40%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"                          # Agorithms","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.577932Z","iopub.status.idle":"2023-12-05T18:59:51.578294Z","shell.execute_reply.started":"2023-12-05T18:59:51.578124Z","shell.execute_reply":"2023-12-05T18:59:51.578141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Using SVM algorithm\nimport numpy as np\nfrom sklearn.svm import SVC","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.579283Z","iopub.status.idle":"2023-12-05T18:59:51.579630Z","shell.execute_reply.started":"2023-12-05T18:59:51.579461Z","shell.execute_reply":"2023-12-05T18:59:51.579478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nX_train = cluster_centers_df\ny_train = clustered_y_train  ","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.580410Z","iopub.status.idle":"2023-12-05T18:59:51.580752Z","shell.execute_reply.started":"2023-12-05T18:59:51.580585Z","shell.execute_reply":"2023-12-05T18:59:51.580601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.581547Z","iopub.status.idle":"2023-12-05T18:59:51.581886Z","shell.execute_reply.started":"2023-12-05T18:59:51.581719Z","shell.execute_reply":"2023-12-05T18:59:51.581735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a pipeline with MinMax scaling and Naive Bayes classifier\npipeline = Pipeline([\n    ('scaler', MinMaxScaler()),  # Scale features to the [0, 1] range\n    ('classifier', GaussianNB())  # Use Gaussian Naive Bayes classifier\n])\n# Perform hyperparameter tuning using GridSearchCV\n# param_grid = {\n    # You can try different Naive Bayes variations and hyperparameters here\n#     'classifier__var_smoothing': [1e-9, 1e-8, 1e-7],\n# }\n# Define a grid of hyperparameter values to search over\nparam_grid = {\n    'classifier__var_smoothing': np.logspace(-9, 0, 10)  # Adjust the range of values as needed -9 0 10\n}\ngrid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\ngrid_search.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.582943Z","iopub.status.idle":"2023-12-05T18:59:51.583298Z","shell.execute_reply.started":"2023-12-05T18:59:51.583127Z","shell.execute_reply":"2023-12-05T18:59:51.583144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Load the sample submission CSV file\nsubmission_df = pd.read_csv('../input/tabular-playground-series-feb-2022/sample_submission.csv')\n\n# Extract the target labels for the first 100k rows (assuming your test data has 100k rows)\ny_true = submission_df['target'][:100000]","metadata":{"execution":{"iopub.status.busy":"2023-12-15T19:00:40.651262Z","iopub.execute_input":"2023-12-15T19:00:40.651687Z","iopub.status.idle":"2023-12-15T19:00:40.734414Z","shell.execute_reply.started":"2023-12-15T19:00:40.651656Z","shell.execute_reply":"2023-12-15T19:00:40.732866Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# Assuming you have a trained SVM model named 'clf'\n\n# Evaluate the model's performance on the test data\naccuracy = accuracy_score(y_true, y_pred)\nreport = classification_report(y_true, y_pred)\nconf_matrix = confusion_matrix(y_true, y_pred)\n\nprint(\"Accuracy:\", accuracy)\nprint(\"Classification Report:\\n\", report)\nprint(\"Confusion Matrix:\\n\", conf_matrix)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.586063Z","iopub.status.idle":"2023-12-05T18:59:51.586444Z","shell.execute_reply.started":"2023-12-05T18:59:51.586267Z","shell.execute_reply":"2023-12-05T18:59:51.586284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.587753Z","iopub.status.idle":"2023-12-05T18:59:51.588120Z","shell.execute_reply.started":"2023-12-05T18:59:51.587927Z","shell.execute_reply":"2023-12-05T18:59:51.587943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pca_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.589365Z","iopub.status.idle":"2023-12-05T18:59:51.589714Z","shell.execute_reply.started":"2023-12-05T18:59:51.589546Z","shell.execute_reply":"2023-12-05T18:59:51.589563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import numpy as np\n# from sklearn.cluster import KMeans\n\n# # Assuming X_train_pca is the PCA-transformed training data\n# # n_clusters is the number of clusters you want to create\n# n_clusters = 3  # You can adjust this number based on your problem\n\n# # Create a K-Means clustering model\n# kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n\n# # Fit the model to your PCA-transformed training data\n# kmeans.fit(X_train_pca)\n\n# # Get the cluster labels for each data point\n# cluster_labels = kmeans.labels_\n\n# You can now use cluster_labels for classification or analysis\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.590726Z","iopub.status.idle":"2023-12-05T18:59:51.591070Z","shell.execute_reply.started":"2023-12-05T18:59:51.590897Z","shell.execute_reply":"2023-12-05T18:59:51.590913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n\n# # Split the PCA-transformed data into training and test sets\n# X_train_pca, X_test_pca, = train_test_split(X_projected, test_size=0.3333333, random_state=42)\n\n# # Convert NumPy arrays to Pandas DataFrames\n# X_train_pca_df = pd.DataFrame(data=X_train_pca, columns=[f'PC{i}' for i in range(1, 34)])\n# X_test_pca_df = pd.DataFrame(data=X_test_pca, columns=[f'PC{i}' for i in range(1, 34)])\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.592467Z","iopub.status.idle":"2023-12-05T18:59:51.592818Z","shell.execute_reply.started":"2023-12-05T18:59:51.592649Z","shell.execute_reply":"2023-12-05T18:59:51.592666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_pca.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.594064Z","iopub.status.idle":"2023-12-05T18:59:51.594445Z","shell.execute_reply.started":"2023-12-05T18:59:51.594270Z","shell.execute_reply":"2023-12-05T18:59:51.594287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_test_pca_df","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.595478Z","iopub.status.idle":"2023-12-05T18:59:51.595825Z","shell.execute_reply.started":"2023-12-05T18:59:51.595650Z","shell.execute_reply":"2023-12-05T18:59:51.595666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_pca.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.597034Z","iopub.status.idle":"2023-12-05T18:59:51.597406Z","shell.execute_reply.started":"2023-12-05T18:59:51.597238Z","shell.execute_reply":"2023-12-05T18:59:51.597255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install --upgrade threadpoolctl\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.598599Z","iopub.status.idle":"2023-12-05T18:59:51.598945Z","shell.execute_reply.started":"2023-12-05T18:59:51.598785Z","shell.execute_reply":"2023-12-05T18:59:51.598801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Columns in pca_df:\", pca_df.columns)\nprint(\"Columns in train:\", train.columns)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T19:23:56.039853Z","iopub.execute_input":"2023-12-05T19:23:56.040226Z","iopub.status.idle":"2023-12-05T19:23:56.045979Z","shell.execute_reply.started":"2023-12-05T19:23:56.040195Z","shell.execute_reply":"2023-12-05T19:23:56.045133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Index of pca_df:\", pca_df.index)\nprint(\"Index of train:\", train.index)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T19:25:51.643140Z","iopub.execute_input":"2023-12-05T19:25:51.643508Z","iopub.status.idle":"2023-12-05T19:25:51.648464Z","shell.execute_reply.started":"2023-12-05T19:25:51.643476Z","shell.execute_reply":"2023-12-05T19:25:51.647624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Columns in train:\", train.columns)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T19:26:57.467591Z","iopub.execute_input":"2023-12-05T19:26:57.467946Z","iopub.status.idle":"2023-12-05T19:26:57.473553Z","shell.execute_reply.started":"2023-12-05T19:26:57.467909Z","shell.execute_reply":"2023-12-05T19:26:57.472438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#K-means algorithm\n    \nK-means algorithm\n    \nimport pandas as pd\nimport numpy as np\nfrom cuml.cluster import KMeans as cuKMeans\nfrom cudf import DataFrame as cudf_DatamFrame\n\n# Assuming df is your original DataFrame with PC1 to PC33 and the target column\n# The target column should be named 'target'\n\n# Extract numerical features for clustering\nfeatures = pca_df.columns[:-1]  # Exclude the target column\ndata_for_clustering = pca_df[features]\n\n# Define the number of clusters\nnum_clusters = 10000\n\n# Initialize the KMeans model on GPU\nkmeans = cuKMeans(n_clusters=num_clusters, random_state=0, n_init=1)\n\n# Fit KMeans model\ncluster_assignments_gpu = kmeans.fit_predict(data_for_clustering)\n\n# Transfer cuML Series to cuDF DataFrame\ncluster_assignments_cudf = cudf.Series(cluster_assignments_gpu)\n\n# Convert cuDF Series to a NumPy array\ncluster_assignments_cpu = cluster_assignments_cudf.to_pandas().values\n\n# Add cluster assignments to the original DataFrame\ndf_with_clusters = pd.concat([pca_df, pd.DataFrame({'cluster': cluster_assignments_cpu})], axis=1)\n\n# Initialize a new DataFrame for the reduced dataset\nreduced_data = pd.DataFrame(columns=pca_df.columns)\n\n# Randomly select 10,000 rows from the entire DataFrame with replacement\nselected_rows = df_with_clusters.sample(n=10000, replace=True, random_state=0)\n\n# Concatenate the selected rows to the reduced_data DataFrame\nreduced_data = pd.concat([reduced_data, selected_rows], ignore_index=True)\n\n  # Extract class labels from the \"cluster\" column\nclass_labels = reduced_data[\"cluster\"].values\n\n# Drop the \"cluster\" column from the reduced dataset\nreduced_data = reduced_data.drop(columns=[\"cluster\"])\n\n# Save the reduced data\nreduced_data.to_csv(\"reduced_data.csv\", index=False)\n\nprint(f\"Reduced data size: {len(reduced_data)}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-17T08:31:41.555272Z","iopub.execute_input":"2023-12-17T08:31:41.555654Z","iopub.status.idle":"2023-12-17T08:31:41.579937Z","shell.execute_reply.started":"2023-12-17T08:31:41.555624Z","shell.execute_reply":"2023-12-17T08:31:41.578672Z"},"trusted":true},"execution_count":99,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mSyntaxError\u001b[0m                               Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/IPython/core/compilerop.py:86\u001b[0m, in \u001b[0;36mCachingCompiler.ast_parse\u001b[0;34m(self, source, filename, symbol)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mast_parse\u001b[39m(\u001b[38;5;28mself\u001b[39m, source, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<unknown>\u001b[39m\u001b[38;5;124m'\u001b[39m, symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexec\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     82\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Parse code to an AST with the current compiler flags active.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    Arguments are exactly the same as ast.parse (in the standard library),\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    and are passed to the built-in compile function.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mPyCF_ONLY_AST\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n","\u001b[0;31mSyntaxError\u001b[0m: invalid syntax (1862913539.py, line 3)"],"ename":"SyntaxError","evalue":"invalid syntax (1862913539.py, line 3)","output_type":"error"}]},{"cell_type":"code","source":"print(reduced_df.columns)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.601562Z","iopub.status.idle":"2023-12-05T18:59:51.601888Z","shell.execute_reply.started":"2023-12-05T18:59:51.601727Z","shell.execute_reply":"2023-12-05T18:59:51.601743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reducing rows using K-means Clustering\nfrom sklearn.cluster import KMeans\n\n# Extracting numeric columns from pca_df\nnumeric_columns = pca_df.select_dtypes(include=[np.number])\nnum_clusters = 10000\n\n# Initialize KMeans with 'num_clusters' clusters\nkmeans = KMeans(n_clusters=num_clusters, random_state=0, n_init=1)  #random_state is a parameter that controls the random number generator used by the algorithm.\n                                                                   #n_init controls the number of times the algorithm will be run with different centroid initializations, and in your code, it's set to 1, meaning only one run.\ncluster_assignments = kmeans.fit_predict(numeric_columns)\npca_df['cluster'] = cluster_assignments\n# Assuming 'target_df' contains the target column and shares the same index as 'pca_df'\nmerged_df = pd.merge(pca_df, target_column, left_index=True, right_index=True)\n\n\naveraged_records = []\n\n# Loop through each unique cluster\nfor cluster_id in merged_df['cluster'].unique():\n    cluster_records = merged_df[merged_df['cluster'] == cluster_id]\n    \n    # Counting occurrences of each class in the cluster\n    class_counts = cluster_records['target'].value_counts()\n    \n    #class with the most occurrences (predominant class)\n    predominant_class = class_counts.idxmax()\n    \n    # Select records of the predominant class and calculate their mean\n    predominant_records = cluster_records[cluster_records['target'] == predominant_class]\n    averaged_record = predominant_records.drop(columns=['cluster', 'target']).mean()\n    \n    # Assigning the predominant class to the averaged record\n    averaged_record['target'] = predominant_class\n    \n    # Appending the averaged record to the list\n    averaged_records.append(averaged_record)\n\n# Create the 'reduced_df' DataFrame from the list of averaged records\nreduced_df = pd.DataFrame(averaged_records)\n\n# 'reduced_df'contains the reduced and averaged records with the predominant class\n","metadata":{"execution":{"iopub.status.busy":"2023-12-16T07:32:10.792769Z","iopub.execute_input":"2023-12-16T07:32:10.793138Z","iopub.status.idle":"2023-12-16T07:36:31.414206Z","shell.execute_reply.started":"2023-12-16T07:32:10.793106Z","shell.execute_reply":"2023-12-16T07:36:31.412277Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1033: ConvergenceWarning: Number of distinct clusters (4386) found smaller than n_clusters (10000). Possibly due to duplicate points in X.\n  return self.fit(X, sample_weight=sample_weight).labels_\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'target'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[29], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m cluster_records \u001b[38;5;241m=\u001b[39m merged_df[merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m cluster_id]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Counting occurrences of each class in the cluster\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m class_counts \u001b[38;5;241m=\u001b[39m \u001b[43mcluster_records\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#class with the most occurrences (predominant class)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m predominant_class \u001b[38;5;241m=\u001b[39m class_counts\u001b[38;5;241m.\u001b[39midxmax()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n","\u001b[0;31mKeyError\u001b[0m: 'target'"],"ename":"KeyError","evalue":"'target'","output_type":"error"}]},{"cell_type":"code","source":"reduced_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.602693Z","iopub.status.idle":"2023-12-05T18:59:51.603051Z","shell.execute_reply.started":"2023-12-05T18:59:51.602883Z","shell.execute_reply":"2023-12-05T18:59:51.602900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduced_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.604384Z","iopub.status.idle":"2023-12-05T18:59:51.604734Z","shell.execute_reply.started":"2023-12-05T18:59:51.604565Z","shell.execute_reply":"2023-12-05T18:59:51.604581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming your target column is named 'target' and you want to use all 33 feature columns\nX_train = reduced_df.drop(columns=['target'])  # Extract all feature columns except 'target'\ny_train = reduced_df['target']  # Extract the 'target' column as labels\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.605731Z","iopub.status.idle":"2023-12-05T18:59:51.606068Z","shell.execute_reply.started":"2023-12-05T18:59:51.605901Z","shell.execute_reply":"2023-12-05T18:59:51.605917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVC\n\n# Assuming you have your training data X_train and y_train\n# clf = SVC(kernel='poly')  # Example with a linear kernel\n# clf.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.607365Z","iopub.status.idle":"2023-12-05T18:59:51.607719Z","shell.execute_reply.started":"2023-12-05T18:59:51.607548Z","shell.execute_reply":"2023-12-05T18:59:51.607564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on the test data\ny_pred = clf.predict(X_test_pca)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.615716Z","iopub.status.idle":"2023-12-05T18:59:51.616091Z","shell.execute_reply.started":"2023-12-05T18:59:51.615895Z","shell.execute_reply":"2023-12-05T18:59:51.615912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Load the sample submission CSV file\nsubmission_df = pd.read_csv('../input/tabular-playground-series-feb-2022/sample_submission.csv')\n\n# Extract the target labels for the first 100k rows (assuming your test data has 100k rows)\ny_true = submission_df['target'][:100000]\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.617158Z","iopub.status.idle":"2023-12-05T18:59:51.617503Z","shell.execute_reply.started":"2023-12-05T18:59:51.617331Z","shell.execute_reply":"2023-12-05T18:59:51.617347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# Assuming you have a trained SVM model named 'clf'\n\n# Evaluate the model's performance on the test data\naccuracy = accuracy_score(y_true, y_pred)\nreport = classification_report(y_true, y_pred)\nconf_matrix = confusion_matrix(y_true, y_pred)\n\nprint(\"Accuracy:\", accuracy)\nprint(\"Classification Report:\\n\", report)\nprint(\"Confusion Matrix:\\n\", conf_matrix)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.618956Z","iopub.status.idle":"2023-12-05T18:59:51.619295Z","shell.execute_reply.started":"2023-12-05T18:59:51.619134Z","shell.execute_reply":"2023-12-05T18:59:51.619150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y=reduced_df['target']","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.620425Z","iopub.status.idle":"2023-12-05T18:59:51.621193Z","shell.execute_reply.started":"2023-12-05T18:59:51.620929Z","shell.execute_reply":"2023-12-05T18:59:51.620958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.622322Z","iopub.status.idle":"2023-12-05T18:59:51.622676Z","shell.execute_reply.started":"2023-12-05T18:59:51.622507Z","shell.execute_reply":"2023-12-05T18:59:51.622523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Initialize the Random Forest classifier\nrf_classifier = RandomForestClassifier(n_estimators=1000,max_depth=6, random_state=42)\n# rf_classifier = RandomForestClassifier(\n#     n_estimators=1000,\n#     max_depth=6,\n#     min_samples_split=5,\n#     class_weight=\"balanced\",\n#     random_state=42\n# )\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.624444Z","iopub.status.idle":"2023-12-05T18:59:51.624805Z","shell.execute_reply.started":"2023-12-05T18:59:51.624637Z","shell.execute_reply":"2023-12-05T18:59:51.624653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the classifier on the training data\nrf_classifier.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.625788Z","iopub.status.idle":"2023-12-05T18:59:51.626145Z","shell.execute_reply.started":"2023-12-05T18:59:51.625956Z","shell.execute_reply":"2023-12-05T18:59:51.625971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on the test data\ny_pred = rf_classifier.predict(X_test_pca)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.627380Z","iopub.status.idle":"2023-12-05T18:59:51.627722Z","shell.execute_reply.started":"2023-12-05T18:59:51.627562Z","shell.execute_reply":"2023-12-05T18:59:51.627578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model\naccuracy = accuracy_score(y_true, y_pred)\nprint(f\"Accuracy: {accuracy}\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.629857Z","iopub.status.idle":"2023-12-05T18:59:51.630246Z","shell.execute_reply.started":"2023-12-05T18:59:51.630031Z","shell.execute_reply":"2023-12-05T18:59:51.630046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# You can also print a detailed classification report\nreport = classification_report(y_true, y_pred )\nprint(\"Classification Report:\\n\", report)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.631324Z","iopub.status.idle":"2023-12-05T18:59:51.631649Z","shell.execute_reply.started":"2023-12-05T18:59:51.631489Z","shell.execute_reply":"2023-12-05T18:59:51.631504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(\"Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.632709Z","iopub.status.idle":"2023-12-05T18:59:51.633089Z","shell.execute_reply.started":"2023-12-05T18:59:51.632872Z","shell.execute_reply":"2023-12-05T18:59:51.632887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Naive Bayes classifier","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.634455Z","iopub.status.idle":"2023-12-05T18:59:51.634776Z","shell.execute_reply.started":"2023-12-05T18:59:51.634618Z","shell.execute_reply":"2023-12-05T18:59:51.634634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.636300Z","iopub.status.idle":"2023-12-05T18:59:51.636661Z","shell.execute_reply.started":"2023-12-05T18:59:51.636492Z","shell.execute_reply":"2023-12-05T18:59:51.636508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a pipeline with MinMax scaling and Naive Bayes classifier\npipeline = Pipeline([\n    ('scaler', MinMaxScaler()),  # Scale features to the [0, 1] range\n    ('classifier', GaussianNB())  # Use Gaussian Naive Bayes classifier\n])","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.637772Z","iopub.status.idle":"2023-12-05T18:59:51.638132Z","shell.execute_reply.started":"2023-12-05T18:59:51.637943Z","shell.execute_reply":"2023-12-05T18:59:51.637959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a pipeline with MinMax scaling and Naive Bayes classifier\npipeline = Pipeline([\n    ('scaler', MinMaxScaler()),  # Scale features to the [0, 1] range\n    ('classifier', GaussianNB())  # Use Gaussian Naive Bayes classifier\n])\n# Perform hyperparameter tuning using GridSearchCV\n# param_grid = {\n    # You can try different Naive Bayes variations and hyperparameters here\n#     'classifier__var_smoothing': [1e-9, 1e-8, 1e-7],\n# }\n# Define a grid of hyperparameter values to search over\nparam_grid = {\n    'classifier__var_smoothing': np.logspace(-9, 0, 10)  # Adjust the range of values as needed -9 0 10\n}\ngrid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\ngrid_search.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.639299Z","iopub.status.idle":"2023-12-05T18:59:51.639623Z","shell.execute_reply.started":"2023-12-05T18:59:51.639463Z","shell.execute_reply":"2023-12-05T18:59:51.639479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\ngrid_search.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.640756Z","iopub.status.idle":"2023-12-05T18:59:51.641131Z","shell.execute_reply.started":"2023-12-05T18:59:51.640929Z","shell.execute_reply":"2023-12-05T18:59:51.640945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the best estimator from the grid search\nbest_pipeline = grid_search.best_estimator_","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.642301Z","iopub.status.idle":"2023-12-05T18:59:51.642629Z","shell.execute_reply.started":"2023-12-05T18:59:51.642469Z","shell.execute_reply":"2023-12-05T18:59:51.642485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the best pipeline on the training data\nbest_pipeline.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.643782Z","iopub.status.idle":"2023-12-05T18:59:51.644165Z","shell.execute_reply.started":"2023-12-05T18:59:51.643967Z","shell.execute_reply":"2023-12-05T18:59:51.643984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on the test data\ny_pred = best_pipeline.predict(X_test_pca)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.645409Z","iopub.status.idle":"2023-12-05T18:59:51.645749Z","shell.execute_reply.started":"2023-12-05T18:59:51.645586Z","shell.execute_reply":"2023-12-05T18:59:51.645602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model\naccuracy = accuracy_score(y_true, y_pred)\nprint( accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.646953Z","iopub.status.idle":"2023-12-05T18:59:51.647316Z","shell.execute_reply.started":"2023-12-05T18:59:51.647143Z","shell.execute_reply":"2023-12-05T18:59:51.647160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize a Gaussian Naive Bayes classifier\n# nb_classifier = GaussianNB()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.648331Z","iopub.status.idle":"2023-12-05T18:59:51.648677Z","shell.execute_reply.started":"2023-12-05T18:59:51.648502Z","shell.execute_reply":"2023-12-05T18:59:51.648518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the classifier\n# nb_classifier.fit(X_train, y_train)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.649863Z","iopub.status.idle":"2023-12-05T18:59:51.650229Z","shell.execute_reply.started":"2023-12-05T18:59:51.650038Z","shell.execute_reply":"2023-12-05T18:59:51.650053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the pipeline (scaling and classification)\npipeline.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.651382Z","iopub.status.idle":"2023-12-05T18:59:51.651713Z","shell.execute_reply.started":"2023-12-05T18:59:51.651548Z","shell.execute_reply":"2023-12-05T18:59:51.651563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on the test data\ny_pred = pipeline.predict(X_test_pca)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.652845Z","iopub.status.idle":"2023-12-05T18:59:51.653206Z","shell.execute_reply.started":"2023-12-05T18:59:51.653015Z","shell.execute_reply":"2023-12-05T18:59:51.653030Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_column_numpy = np.array(target_column)\ntrain=train.drop(columns=['target']) ","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:04:30.894956Z","iopub.execute_input":"2023-12-18T08:04:30.895776Z","iopub.status.idle":"2023-12-18T08:04:30.926862Z","shell.execute_reply.started":"2023-12-18T08:04:30.895741Z","shell.execute_reply":"2023-12-18T08:04:30.925802Z"},"trusted":true},"execution_count":16,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m target_column_numpy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mtarget_column\u001b[49m)\n\u001b[1;32m      2\u001b[0m train\u001b[38;5;241m=\u001b[39mtrain\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]) \n","\u001b[0;31mNameError\u001b[0m: name 'target_column' is not defined"],"ename":"NameError","evalue":"name 'target_column' is not defined","output_type":"error"}]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:04:05.662387Z","iopub.execute_input":"2023-12-18T08:04:05.663166Z","iopub.status.idle":"2023-12-18T08:04:05.725265Z","shell.execute_reply.started":"2023-12-18T08:04:05.663132Z","shell.execute_reply":"2023-12-18T08:04:05.724388Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"        row_id     A0T0G0C10      A0T0G1C9  A0T0G2C8  A0T0G3C7  A0T0G4C6  \\\n0            0 -9.536743e-07 -9.536743e-06 -0.000043 -0.000114 -0.000200   \n1            1 -9.536743e-07 -9.536743e-06 -0.000043  0.000886 -0.000200   \n2            2 -9.536743e-07 -1.536743e-06  0.000007  0.000129  0.000268   \n3            3  4.632568e-08 -5.536743e-06  0.000012  0.000245  0.000492   \n4            4 -9.536743e-07 -9.536743e-06 -0.000043 -0.000114 -0.000200   \n...        ...           ...           ...       ...       ...       ...   \n199995  199995 -9.536743e-07  4.632568e-07 -0.000003  0.000176  0.000350   \n199996  199996 -9.536743e-07 -9.536743e-06 -0.000043 -0.000114 -0.000200   \n199997  199997  4.632568e-08  1.463257e-06 -0.000005 -0.000031 -0.000019   \n199998  199998 -9.536743e-07 -9.536743e-06 -0.000043 -0.000114 -0.000200   \n199999  199999  1.046326e-06 -1.536743e-06  0.000069  0.000539  0.001329   \n\n        A0T0G5C5  A0T0G6C4  A0T0G7C3  A0T0G8C2  ...  A8T0G1C1  A8T0G2C0  \\\n0      -0.000240 -0.000200 -0.000114 -0.000043  ... -0.000086 -0.000043   \n1       0.000760 -0.000200 -0.000114 -0.000043  ... -0.000086 -0.000043   \n2       0.000270  0.000243  0.000125  0.000001  ...  0.000084  0.000048   \n3       0.000522  0.000396  0.000197 -0.000003  ...  0.000151  0.000100   \n4      -0.000240 -0.000200 -0.000114 -0.000043  ... -0.000086 -0.000043   \n...          ...       ...       ...       ...  ...       ...       ...   \n199995  0.000290  0.000200  0.000206 -0.000023  ...  0.000124  0.000057   \n199996 -0.000240 -0.000200 -0.000114 -0.000043  ... -0.000086 -0.000043   \n199997 -0.000037 -0.000037 -0.000015 -0.000005  ...  0.000115  0.000131   \n199998 -0.000240 -0.000200 -0.000114 -0.000043  ... -0.000086 -0.000043   \n199999  0.001657  0.001328  0.000520  0.000063  ...  0.000065  0.000053   \n\n        A8T1G0C1  A8T1G1C0  A8T2G0C0      A9T0G0C1  A9T0G1C0  A9T1G0C0  \\\n0      -0.000086 -0.000086 -0.000043 -9.536743e-06 -0.000010 -0.000010   \n1       0.000914  0.000914 -0.000043 -9.536743e-06 -0.000010 -0.000010   \n2       0.000081  0.000106  0.000072  1.046326e-05  0.000008  0.000019   \n3       0.000180  0.000202  0.000153  2.146326e-05  0.000015  0.000046   \n4      -0.000086 -0.000086 -0.000043 -9.536743e-06 -0.000010 -0.000010   \n...          ...       ...       ...           ...       ...       ...   \n199995  0.000104  0.000144  0.000027  4.632568e-07  0.000060  0.000020   \n199996  0.000914  0.000914 -0.000043 -9.536743e-06 -0.000010 -0.000010   \n199997  0.000110  0.000213  0.000094  1.646326e-05  0.000035  0.000021   \n199998  0.001914 -0.000086 -0.000043 -9.536743e-06 -0.000010 -0.000010   \n199999  0.000082  0.000102  0.000078  1.446326e-05  0.000013  0.000033   \n\n           A10T0G0C0                    target  \n0      -9.536743e-07    Streptococcus_pyogenes  \n1      -9.536743e-07       Salmonella_enterica  \n2       1.046326e-06       Salmonella_enterica  \n3      -9.536743e-07       Salmonella_enterica  \n4      -9.536743e-07        Enterococcus_hirae  \n...              ...                       ...  \n199995 -9.536743e-07       Salmonella_enterica  \n199996 -9.536743e-07    Streptococcus_pyogenes  \n199997  4.632568e-08  Streptococcus_pneumoniae  \n199998 -9.536743e-07     Staphylococcus_aureus  \n199999 -9.536743e-07     Klebsiella_pneumoniae  \n\n[200000 rows x 288 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>A0T0G0C10</th>\n      <th>A0T0G1C9</th>\n      <th>A0T0G2C8</th>\n      <th>A0T0G3C7</th>\n      <th>A0T0G4C6</th>\n      <th>A0T0G5C5</th>\n      <th>A0T0G6C4</th>\n      <th>A0T0G7C3</th>\n      <th>A0T0G8C2</th>\n      <th>...</th>\n      <th>A8T0G1C1</th>\n      <th>A8T0G2C0</th>\n      <th>A8T1G0C1</th>\n      <th>A8T1G1C0</th>\n      <th>A8T2G0C0</th>\n      <th>A9T0G0C1</th>\n      <th>A9T0G1C0</th>\n      <th>A9T1G0C0</th>\n      <th>A10T0G0C0</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>-9.536743e-07</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000043</td>\n      <td>-0.000114</td>\n      <td>-0.000200</td>\n      <td>-0.000240</td>\n      <td>-0.000200</td>\n      <td>-0.000114</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000010</td>\n      <td>-0.000010</td>\n      <td>-9.536743e-07</td>\n      <td>Streptococcus_pyogenes</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>-9.536743e-07</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000043</td>\n      <td>0.000886</td>\n      <td>-0.000200</td>\n      <td>0.000760</td>\n      <td>-0.000200</td>\n      <td>-0.000114</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>0.000914</td>\n      <td>0.000914</td>\n      <td>-0.000043</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000010</td>\n      <td>-0.000010</td>\n      <td>-9.536743e-07</td>\n      <td>Salmonella_enterica</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>-9.536743e-07</td>\n      <td>-1.536743e-06</td>\n      <td>0.000007</td>\n      <td>0.000129</td>\n      <td>0.000268</td>\n      <td>0.000270</td>\n      <td>0.000243</td>\n      <td>0.000125</td>\n      <td>0.000001</td>\n      <td>...</td>\n      <td>0.000084</td>\n      <td>0.000048</td>\n      <td>0.000081</td>\n      <td>0.000106</td>\n      <td>0.000072</td>\n      <td>1.046326e-05</td>\n      <td>0.000008</td>\n      <td>0.000019</td>\n      <td>1.046326e-06</td>\n      <td>Salmonella_enterica</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>4.632568e-08</td>\n      <td>-5.536743e-06</td>\n      <td>0.000012</td>\n      <td>0.000245</td>\n      <td>0.000492</td>\n      <td>0.000522</td>\n      <td>0.000396</td>\n      <td>0.000197</td>\n      <td>-0.000003</td>\n      <td>...</td>\n      <td>0.000151</td>\n      <td>0.000100</td>\n      <td>0.000180</td>\n      <td>0.000202</td>\n      <td>0.000153</td>\n      <td>2.146326e-05</td>\n      <td>0.000015</td>\n      <td>0.000046</td>\n      <td>-9.536743e-07</td>\n      <td>Salmonella_enterica</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>-9.536743e-07</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000043</td>\n      <td>-0.000114</td>\n      <td>-0.000200</td>\n      <td>-0.000240</td>\n      <td>-0.000200</td>\n      <td>-0.000114</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000010</td>\n      <td>-0.000010</td>\n      <td>-9.536743e-07</td>\n      <td>Enterococcus_hirae</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>199995</th>\n      <td>199995</td>\n      <td>-9.536743e-07</td>\n      <td>4.632568e-07</td>\n      <td>-0.000003</td>\n      <td>0.000176</td>\n      <td>0.000350</td>\n      <td>0.000290</td>\n      <td>0.000200</td>\n      <td>0.000206</td>\n      <td>-0.000023</td>\n      <td>...</td>\n      <td>0.000124</td>\n      <td>0.000057</td>\n      <td>0.000104</td>\n      <td>0.000144</td>\n      <td>0.000027</td>\n      <td>4.632568e-07</td>\n      <td>0.000060</td>\n      <td>0.000020</td>\n      <td>-9.536743e-07</td>\n      <td>Salmonella_enterica</td>\n    </tr>\n    <tr>\n      <th>199996</th>\n      <td>199996</td>\n      <td>-9.536743e-07</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000043</td>\n      <td>-0.000114</td>\n      <td>-0.000200</td>\n      <td>-0.000240</td>\n      <td>-0.000200</td>\n      <td>-0.000114</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>0.000914</td>\n      <td>0.000914</td>\n      <td>-0.000043</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000010</td>\n      <td>-0.000010</td>\n      <td>-9.536743e-07</td>\n      <td>Streptococcus_pyogenes</td>\n    </tr>\n    <tr>\n      <th>199997</th>\n      <td>199997</td>\n      <td>4.632568e-08</td>\n      <td>1.463257e-06</td>\n      <td>-0.000005</td>\n      <td>-0.000031</td>\n      <td>-0.000019</td>\n      <td>-0.000037</td>\n      <td>-0.000037</td>\n      <td>-0.000015</td>\n      <td>-0.000005</td>\n      <td>...</td>\n      <td>0.000115</td>\n      <td>0.000131</td>\n      <td>0.000110</td>\n      <td>0.000213</td>\n      <td>0.000094</td>\n      <td>1.646326e-05</td>\n      <td>0.000035</td>\n      <td>0.000021</td>\n      <td>4.632568e-08</td>\n      <td>Streptococcus_pneumoniae</td>\n    </tr>\n    <tr>\n      <th>199998</th>\n      <td>199998</td>\n      <td>-9.536743e-07</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000043</td>\n      <td>-0.000114</td>\n      <td>-0.000200</td>\n      <td>-0.000240</td>\n      <td>-0.000200</td>\n      <td>-0.000114</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>0.001914</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000010</td>\n      <td>-0.000010</td>\n      <td>-9.536743e-07</td>\n      <td>Staphylococcus_aureus</td>\n    </tr>\n    <tr>\n      <th>199999</th>\n      <td>199999</td>\n      <td>1.046326e-06</td>\n      <td>-1.536743e-06</td>\n      <td>0.000069</td>\n      <td>0.000539</td>\n      <td>0.001329</td>\n      <td>0.001657</td>\n      <td>0.001328</td>\n      <td>0.000520</td>\n      <td>0.000063</td>\n      <td>...</td>\n      <td>0.000065</td>\n      <td>0.000053</td>\n      <td>0.000082</td>\n      <td>0.000102</td>\n      <td>0.000078</td>\n      <td>1.446326e-05</td>\n      <td>0.000013</td>\n      <td>0.000033</td>\n      <td>-9.536743e-07</td>\n      <td>Klebsiella_pneumoniae</td>\n    </tr>\n  </tbody>\n</table>\n<p>200000 rows × 288 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_trainnew_1, X_val_1, y_trainnew_1, y_val_1 = train_test_split(train, target_column, test_size=0.3, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T08:04:16.712798Z","iopub.execute_input":"2023-12-18T08:04:16.713661Z","iopub.status.idle":"2023-12-18T08:04:17.385896Z","shell.execute_reply.started":"2023-12-18T08:04:16.713627Z","shell.execute_reply":"2023-12-18T08:04:17.384728Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m----> 3\u001b[0m X_trainnew_1, X_val_1, y_trainnew_1, y_val_1 \u001b[38;5;241m=\u001b[39m train_test_split(train, \u001b[43mtarget_column\u001b[49m, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'target_column' is not defined"],"ename":"NameError","evalue":"name 'target_column' is not defined","output_type":"error"}]},{"cell_type":"code","source":"X_trainnew_1","metadata":{"execution":{"iopub.status.busy":"2023-12-18T06:34:38.539571Z","iopub.execute_input":"2023-12-18T06:34:38.539963Z","iopub.status.idle":"2023-12-18T06:34:38.592973Z","shell.execute_reply.started":"2023-12-18T06:34:38.539933Z","shell.execute_reply":"2023-12-18T06:34:38.592031Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"        row_id     A0T0G0C10      A0T0G1C9      A0T0G2C8  A0T0G3C7  A0T0G4C6  \\\n21269    21269 -9.536743e-07  1.046326e-05  7.084656e-06 -0.000004 -0.000030   \n187660  187660  4.632568e-08  2.463257e-06  4.808466e-05  0.000348  0.000822   \n774        774  4.632568e-08  3.463257e-06  8.465576e-08 -0.000015  0.000007   \n184577  184577 -9.536743e-07 -9.536743e-06 -4.291534e-05 -0.000114 -0.000200   \n37127    37127 -9.536743e-07 -9.536743e-06 -4.291534e-05 -0.000114 -0.000200   \n...        ...           ...           ...           ...       ...       ...   \n119879  119879 -9.536743e-07 -9.536743e-06 -4.291534e-05 -0.000114 -0.000200   \n103694  103694 -9.536743e-07  4.632568e-07 -2.915344e-06  0.000036  0.000110   \n131932  131932  2.046326e-06 -5.367432e-07 -1.391534e-05 -0.000056 -0.000067   \n146867  146867 -9.536743e-07 -9.536743e-06 -4.291534e-05 -0.000114 -0.000200   \n121958  121958 -9.536743e-07 -6.536743e-06 -2.291534e-05 -0.000071 -0.000114   \n\n        A0T0G5C5  A0T0G6C4  A0T0G7C3  A0T0G8C2  ...  A8T0G0C2  A8T0G1C1  \\\n21269   0.000020 -0.000050  0.000016 -0.000043  ...  0.000117  0.000184   \n187660  0.001119  0.000856  0.000343  0.000032  ...  0.000022  0.000035   \n774    -0.000004 -0.000005  0.000003  0.000003  ...  0.000018  0.000064   \n184577 -0.000240 -0.000200 -0.000114 -0.000043  ... -0.000043 -0.000086   \n37127  -0.000240 -0.000200 -0.000114 -0.000043  ... -0.000043 -0.000086   \n...          ...       ...       ...       ...  ...       ...       ...   \n119879 -0.000240 -0.000200 -0.000114 -0.000043  ... -0.000043 -0.000086   \n103694  0.000030  0.000010  0.000036 -0.000023  ...  0.000077  0.000104   \n131932 -0.000104 -0.000085 -0.000048 -0.000015  ...  0.000283  0.000648   \n146867 -0.000240 -0.000200 -0.000114 -0.000043  ...  0.000957  0.000914   \n121958 -0.000146 -0.000113 -0.000066 -0.000021  ...  0.000198  0.000488   \n\n        A8T0G2C0  A8T1G0C1  A8T1G1C0  A8T2G0C0      A9T0G0C1  A9T0G1C0  \\\n21269   0.000137  0.000234  0.000224  0.000137  2.046326e-05  0.000010   \n187660  0.000033  0.000050  0.000067  0.000042  1.246326e-05  0.000008   \n774     0.000034  0.000066  0.000069  0.000041  1.246326e-05  0.000016   \n184577  0.000957 -0.000086 -0.000086 -0.000043 -9.536743e-06 -0.000010   \n37127  -0.000043 -0.000086 -0.000086 -0.000043 -9.536743e-06 -0.000010   \n...          ...       ...       ...       ...           ...       ...   \n119879 -0.000043 -0.000086 -0.000086 -0.000043 -9.536743e-06 -0.000010   \n103694  0.000037  0.000134  0.000114  0.000007  4.632568e-07  0.000020   \n131932  0.000390  0.000902  0.001207  0.000885  1.334633e-04  0.000203   \n146867 -0.000043  0.000914  0.001914 -0.000043  9.904633e-04  0.000990   \n121958  0.000281  0.000497  0.000588  0.000333  7.246326e-05  0.000096   \n\n        A9T1G0C0     A10T0G0C0  \n21269   0.000030 -9.536743e-07  \n187660  0.000018  4.632568e-08  \n774     0.000009  4.632568e-08  \n184577 -0.000010 -9.536743e-07  \n37127  -0.000010 -9.536743e-07  \n...          ...           ...  \n119879 -0.000010 -9.536743e-07  \n103694  0.000010 -9.536743e-07  \n131932  0.000227  1.046326e-06  \n146867 -0.000010 -9.536743e-07  \n121958  0.000086  4.632568e-08  \n\n[140000 rows x 287 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>A0T0G0C10</th>\n      <th>A0T0G1C9</th>\n      <th>A0T0G2C8</th>\n      <th>A0T0G3C7</th>\n      <th>A0T0G4C6</th>\n      <th>A0T0G5C5</th>\n      <th>A0T0G6C4</th>\n      <th>A0T0G7C3</th>\n      <th>A0T0G8C2</th>\n      <th>...</th>\n      <th>A8T0G0C2</th>\n      <th>A8T0G1C1</th>\n      <th>A8T0G2C0</th>\n      <th>A8T1G0C1</th>\n      <th>A8T1G1C0</th>\n      <th>A8T2G0C0</th>\n      <th>A9T0G0C1</th>\n      <th>A9T0G1C0</th>\n      <th>A9T1G0C0</th>\n      <th>A10T0G0C0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>21269</th>\n      <td>21269</td>\n      <td>-9.536743e-07</td>\n      <td>1.046326e-05</td>\n      <td>7.084656e-06</td>\n      <td>-0.000004</td>\n      <td>-0.000030</td>\n      <td>0.000020</td>\n      <td>-0.000050</td>\n      <td>0.000016</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>0.000117</td>\n      <td>0.000184</td>\n      <td>0.000137</td>\n      <td>0.000234</td>\n      <td>0.000224</td>\n      <td>0.000137</td>\n      <td>2.046326e-05</td>\n      <td>0.000010</td>\n      <td>0.000030</td>\n      <td>-9.536743e-07</td>\n    </tr>\n    <tr>\n      <th>187660</th>\n      <td>187660</td>\n      <td>4.632568e-08</td>\n      <td>2.463257e-06</td>\n      <td>4.808466e-05</td>\n      <td>0.000348</td>\n      <td>0.000822</td>\n      <td>0.001119</td>\n      <td>0.000856</td>\n      <td>0.000343</td>\n      <td>0.000032</td>\n      <td>...</td>\n      <td>0.000022</td>\n      <td>0.000035</td>\n      <td>0.000033</td>\n      <td>0.000050</td>\n      <td>0.000067</td>\n      <td>0.000042</td>\n      <td>1.246326e-05</td>\n      <td>0.000008</td>\n      <td>0.000018</td>\n      <td>4.632568e-08</td>\n    </tr>\n    <tr>\n      <th>774</th>\n      <td>774</td>\n      <td>4.632568e-08</td>\n      <td>3.463257e-06</td>\n      <td>8.465576e-08</td>\n      <td>-0.000015</td>\n      <td>0.000007</td>\n      <td>-0.000004</td>\n      <td>-0.000005</td>\n      <td>0.000003</td>\n      <td>0.000003</td>\n      <td>...</td>\n      <td>0.000018</td>\n      <td>0.000064</td>\n      <td>0.000034</td>\n      <td>0.000066</td>\n      <td>0.000069</td>\n      <td>0.000041</td>\n      <td>1.246326e-05</td>\n      <td>0.000016</td>\n      <td>0.000009</td>\n      <td>4.632568e-08</td>\n    </tr>\n    <tr>\n      <th>184577</th>\n      <td>184577</td>\n      <td>-9.536743e-07</td>\n      <td>-9.536743e-06</td>\n      <td>-4.291534e-05</td>\n      <td>-0.000114</td>\n      <td>-0.000200</td>\n      <td>-0.000240</td>\n      <td>-0.000200</td>\n      <td>-0.000114</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>0.000957</td>\n      <td>-0.000086</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000010</td>\n      <td>-0.000010</td>\n      <td>-9.536743e-07</td>\n    </tr>\n    <tr>\n      <th>37127</th>\n      <td>37127</td>\n      <td>-9.536743e-07</td>\n      <td>-9.536743e-06</td>\n      <td>-4.291534e-05</td>\n      <td>-0.000114</td>\n      <td>-0.000200</td>\n      <td>-0.000240</td>\n      <td>-0.000200</td>\n      <td>-0.000114</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000010</td>\n      <td>-0.000010</td>\n      <td>-9.536743e-07</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>119879</th>\n      <td>119879</td>\n      <td>-9.536743e-07</td>\n      <td>-9.536743e-06</td>\n      <td>-4.291534e-05</td>\n      <td>-0.000114</td>\n      <td>-0.000200</td>\n      <td>-0.000240</td>\n      <td>-0.000200</td>\n      <td>-0.000114</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000010</td>\n      <td>-0.000010</td>\n      <td>-9.536743e-07</td>\n    </tr>\n    <tr>\n      <th>103694</th>\n      <td>103694</td>\n      <td>-9.536743e-07</td>\n      <td>4.632568e-07</td>\n      <td>-2.915344e-06</td>\n      <td>0.000036</td>\n      <td>0.000110</td>\n      <td>0.000030</td>\n      <td>0.000010</td>\n      <td>0.000036</td>\n      <td>-0.000023</td>\n      <td>...</td>\n      <td>0.000077</td>\n      <td>0.000104</td>\n      <td>0.000037</td>\n      <td>0.000134</td>\n      <td>0.000114</td>\n      <td>0.000007</td>\n      <td>4.632568e-07</td>\n      <td>0.000020</td>\n      <td>0.000010</td>\n      <td>-9.536743e-07</td>\n    </tr>\n    <tr>\n      <th>131932</th>\n      <td>131932</td>\n      <td>2.046326e-06</td>\n      <td>-5.367432e-07</td>\n      <td>-1.391534e-05</td>\n      <td>-0.000056</td>\n      <td>-0.000067</td>\n      <td>-0.000104</td>\n      <td>-0.000085</td>\n      <td>-0.000048</td>\n      <td>-0.000015</td>\n      <td>...</td>\n      <td>0.000283</td>\n      <td>0.000648</td>\n      <td>0.000390</td>\n      <td>0.000902</td>\n      <td>0.001207</td>\n      <td>0.000885</td>\n      <td>1.334633e-04</td>\n      <td>0.000203</td>\n      <td>0.000227</td>\n      <td>1.046326e-06</td>\n    </tr>\n    <tr>\n      <th>146867</th>\n      <td>146867</td>\n      <td>-9.536743e-07</td>\n      <td>-9.536743e-06</td>\n      <td>-4.291534e-05</td>\n      <td>-0.000114</td>\n      <td>-0.000200</td>\n      <td>-0.000240</td>\n      <td>-0.000200</td>\n      <td>-0.000114</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>0.000957</td>\n      <td>0.000914</td>\n      <td>-0.000043</td>\n      <td>0.000914</td>\n      <td>0.001914</td>\n      <td>-0.000043</td>\n      <td>9.904633e-04</td>\n      <td>0.000990</td>\n      <td>-0.000010</td>\n      <td>-9.536743e-07</td>\n    </tr>\n    <tr>\n      <th>121958</th>\n      <td>121958</td>\n      <td>-9.536743e-07</td>\n      <td>-6.536743e-06</td>\n      <td>-2.291534e-05</td>\n      <td>-0.000071</td>\n      <td>-0.000114</td>\n      <td>-0.000146</td>\n      <td>-0.000113</td>\n      <td>-0.000066</td>\n      <td>-0.000021</td>\n      <td>...</td>\n      <td>0.000198</td>\n      <td>0.000488</td>\n      <td>0.000281</td>\n      <td>0.000497</td>\n      <td>0.000588</td>\n      <td>0.000333</td>\n      <td>7.246326e-05</td>\n      <td>0.000096</td>\n      <td>0.000086</td>\n      <td>4.632568e-08</td>\n    </tr>\n  </tbody>\n</table>\n<p>140000 rows × 287 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X_val_1","metadata":{"execution":{"iopub.status.busy":"2023-12-18T06:34:43.331110Z","iopub.execute_input":"2023-12-18T06:34:43.331924Z","iopub.status.idle":"2023-12-18T06:34:43.370367Z","shell.execute_reply.started":"2023-12-18T06:34:43.331890Z","shell.execute_reply":"2023-12-18T06:34:43.369463Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"        row_id     A0T0G0C10      A0T0G1C9  A0T0G2C8  A0T0G3C7  A0T0G4C6  \\\n119737  119737 -9.536743e-07  4.632568e-07 -0.000033  0.000016  0.000070   \n72272    72272 -9.536743e-07  1.046326e-05  0.000007 -0.000004 -0.000030   \n158154  158154 -9.536743e-07 -6.536743e-06 -0.000023 -0.000069 -0.000112   \n65426    65426  4.632568e-08 -8.536743e-06 -0.000018  0.000043  0.000030   \n30074    30074 -9.536743e-07 -9.536743e-06 -0.000043 -0.000114 -0.000200   \n...        ...           ...           ...       ...       ...       ...   \n97771    97771  4.632568e-08  1.463257e-06  0.000002  0.000002  0.000033   \n59813    59813 -9.536743e-07  1.046326e-05  0.000007 -0.000004 -0.000020   \n103735  103735 -9.536743e-07 -9.536743e-06 -0.000043 -0.000114 -0.000200   \n180226  180226 -9.536743e-07  1.046326e-05  0.000007  0.000056  0.000040   \n119389  119389 -9.536743e-07 -9.536743e-06 -0.000043 -0.000114 -0.000200   \n\n        A0T0G5C5  A0T0G6C4  A0T0G7C3  A0T0G8C2  ...  A8T0G0C2  A8T0G1C1  \\\n119737 -0.000030 -0.000010 -0.000034 -0.000003  ...  0.000087  0.000204   \n72272   0.000020 -0.000050  0.000016 -0.000043  ...  0.000077  0.000174   \n158154 -0.000146 -0.000113 -0.000066 -0.000021  ...  0.000166  0.000501   \n65426  -0.000007  0.000002  0.000047 -0.000019  ...  0.000097  0.000174   \n30074  -0.000240  0.009800  0.009886 -0.000043  ... -0.000043 -0.000086   \n...          ...       ...       ...       ...  ...       ...       ...   \n97771   0.000013  0.000020  0.000018  0.000004  ...  0.000023  0.000039   \n59813   0.000020 -0.000050  0.000016 -0.000043  ...  0.000157  0.000384   \n103735 -0.000240 -0.000200 -0.000114 -0.000043  ... -0.000043 -0.000086   \n180226  0.000090  0.000040  0.000106 -0.000033  ...  0.000017  0.000124   \n119389 -0.000240 -0.000200 -0.000114 -0.000043  ... -0.000043 -0.000086   \n\n        A8T0G2C0  A8T1G0C1  A8T1G1C0  A8T2G0C0  A9T0G0C1  A9T0G1C0  \\\n119737  0.000117  0.000254  0.000154  0.000177  0.000020  0.000030   \n72272   0.000137  0.000264  0.000324  0.000267  0.000010  0.000020   \n158154  0.000312  0.000505  0.000557  0.000322  0.000064  0.000099   \n65426   0.000099  0.000199  0.000229  0.000168  0.000023  0.000015   \n30074  -0.000043 -0.000086 -0.000086  0.009957 -0.000010 -0.000010   \n...          ...       ...       ...       ...       ...       ...   \n97771   0.000026  0.000041  0.000053  0.000028  0.000003  0.000003   \n59813   0.000257  0.000294  0.000414  0.000147  0.000020  0.000060   \n103735 -0.000043 -0.000086 -0.000086 -0.000043 -0.000010 -0.000010   \n180226  0.000107  0.000114  0.000164  0.000007  0.000010  0.000030   \n119389 -0.000043 -0.000086 -0.000086 -0.000043 -0.000010 -0.000010   \n\n            A9T1G0C0     A10T0G0C0  \n119737  4.046326e-05 -9.536743e-07  \n72272   5.046326e-05 -9.536743e-07  \n158154  8.646326e-05  1.046326e-06  \n65426   4.646326e-05 -9.536743e-07  \n30074  -9.536743e-06 -9.536743e-07  \n...              ...           ...  \n97771   1.046326e-05  4.632568e-08  \n59813   5.046326e-05 -9.536743e-07  \n103735 -9.536743e-06 -9.536743e-07  \n180226  4.632568e-07 -9.536743e-07  \n119389 -9.536743e-06 -9.536743e-07  \n\n[60000 rows x 287 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>A0T0G0C10</th>\n      <th>A0T0G1C9</th>\n      <th>A0T0G2C8</th>\n      <th>A0T0G3C7</th>\n      <th>A0T0G4C6</th>\n      <th>A0T0G5C5</th>\n      <th>A0T0G6C4</th>\n      <th>A0T0G7C3</th>\n      <th>A0T0G8C2</th>\n      <th>...</th>\n      <th>A8T0G0C2</th>\n      <th>A8T0G1C1</th>\n      <th>A8T0G2C0</th>\n      <th>A8T1G0C1</th>\n      <th>A8T1G1C0</th>\n      <th>A8T2G0C0</th>\n      <th>A9T0G0C1</th>\n      <th>A9T0G1C0</th>\n      <th>A9T1G0C0</th>\n      <th>A10T0G0C0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>119737</th>\n      <td>119737</td>\n      <td>-9.536743e-07</td>\n      <td>4.632568e-07</td>\n      <td>-0.000033</td>\n      <td>0.000016</td>\n      <td>0.000070</td>\n      <td>-0.000030</td>\n      <td>-0.000010</td>\n      <td>-0.000034</td>\n      <td>-0.000003</td>\n      <td>...</td>\n      <td>0.000087</td>\n      <td>0.000204</td>\n      <td>0.000117</td>\n      <td>0.000254</td>\n      <td>0.000154</td>\n      <td>0.000177</td>\n      <td>0.000020</td>\n      <td>0.000030</td>\n      <td>4.046326e-05</td>\n      <td>-9.536743e-07</td>\n    </tr>\n    <tr>\n      <th>72272</th>\n      <td>72272</td>\n      <td>-9.536743e-07</td>\n      <td>1.046326e-05</td>\n      <td>0.000007</td>\n      <td>-0.000004</td>\n      <td>-0.000030</td>\n      <td>0.000020</td>\n      <td>-0.000050</td>\n      <td>0.000016</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>0.000077</td>\n      <td>0.000174</td>\n      <td>0.000137</td>\n      <td>0.000264</td>\n      <td>0.000324</td>\n      <td>0.000267</td>\n      <td>0.000010</td>\n      <td>0.000020</td>\n      <td>5.046326e-05</td>\n      <td>-9.536743e-07</td>\n    </tr>\n    <tr>\n      <th>158154</th>\n      <td>158154</td>\n      <td>-9.536743e-07</td>\n      <td>-6.536743e-06</td>\n      <td>-0.000023</td>\n      <td>-0.000069</td>\n      <td>-0.000112</td>\n      <td>-0.000146</td>\n      <td>-0.000113</td>\n      <td>-0.000066</td>\n      <td>-0.000021</td>\n      <td>...</td>\n      <td>0.000166</td>\n      <td>0.000501</td>\n      <td>0.000312</td>\n      <td>0.000505</td>\n      <td>0.000557</td>\n      <td>0.000322</td>\n      <td>0.000064</td>\n      <td>0.000099</td>\n      <td>8.646326e-05</td>\n      <td>1.046326e-06</td>\n    </tr>\n    <tr>\n      <th>65426</th>\n      <td>65426</td>\n      <td>4.632568e-08</td>\n      <td>-8.536743e-06</td>\n      <td>-0.000018</td>\n      <td>0.000043</td>\n      <td>0.000030</td>\n      <td>-0.000007</td>\n      <td>0.000002</td>\n      <td>0.000047</td>\n      <td>-0.000019</td>\n      <td>...</td>\n      <td>0.000097</td>\n      <td>0.000174</td>\n      <td>0.000099</td>\n      <td>0.000199</td>\n      <td>0.000229</td>\n      <td>0.000168</td>\n      <td>0.000023</td>\n      <td>0.000015</td>\n      <td>4.646326e-05</td>\n      <td>-9.536743e-07</td>\n    </tr>\n    <tr>\n      <th>30074</th>\n      <td>30074</td>\n      <td>-9.536743e-07</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000043</td>\n      <td>-0.000114</td>\n      <td>-0.000200</td>\n      <td>-0.000240</td>\n      <td>0.009800</td>\n      <td>0.009886</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000086</td>\n      <td>0.009957</td>\n      <td>-0.000010</td>\n      <td>-0.000010</td>\n      <td>-9.536743e-06</td>\n      <td>-9.536743e-07</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>97771</th>\n      <td>97771</td>\n      <td>4.632568e-08</td>\n      <td>1.463257e-06</td>\n      <td>0.000002</td>\n      <td>0.000002</td>\n      <td>0.000033</td>\n      <td>0.000013</td>\n      <td>0.000020</td>\n      <td>0.000018</td>\n      <td>0.000004</td>\n      <td>...</td>\n      <td>0.000023</td>\n      <td>0.000039</td>\n      <td>0.000026</td>\n      <td>0.000041</td>\n      <td>0.000053</td>\n      <td>0.000028</td>\n      <td>0.000003</td>\n      <td>0.000003</td>\n      <td>1.046326e-05</td>\n      <td>4.632568e-08</td>\n    </tr>\n    <tr>\n      <th>59813</th>\n      <td>59813</td>\n      <td>-9.536743e-07</td>\n      <td>1.046326e-05</td>\n      <td>0.000007</td>\n      <td>-0.000004</td>\n      <td>-0.000020</td>\n      <td>0.000020</td>\n      <td>-0.000050</td>\n      <td>0.000016</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>0.000157</td>\n      <td>0.000384</td>\n      <td>0.000257</td>\n      <td>0.000294</td>\n      <td>0.000414</td>\n      <td>0.000147</td>\n      <td>0.000020</td>\n      <td>0.000060</td>\n      <td>5.046326e-05</td>\n      <td>-9.536743e-07</td>\n    </tr>\n    <tr>\n      <th>103735</th>\n      <td>103735</td>\n      <td>-9.536743e-07</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000043</td>\n      <td>-0.000114</td>\n      <td>-0.000200</td>\n      <td>-0.000240</td>\n      <td>-0.000200</td>\n      <td>-0.000114</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-0.000010</td>\n      <td>-0.000010</td>\n      <td>-9.536743e-06</td>\n      <td>-9.536743e-07</td>\n    </tr>\n    <tr>\n      <th>180226</th>\n      <td>180226</td>\n      <td>-9.536743e-07</td>\n      <td>1.046326e-05</td>\n      <td>0.000007</td>\n      <td>0.000056</td>\n      <td>0.000040</td>\n      <td>0.000090</td>\n      <td>0.000040</td>\n      <td>0.000106</td>\n      <td>-0.000033</td>\n      <td>...</td>\n      <td>0.000017</td>\n      <td>0.000124</td>\n      <td>0.000107</td>\n      <td>0.000114</td>\n      <td>0.000164</td>\n      <td>0.000007</td>\n      <td>0.000010</td>\n      <td>0.000030</td>\n      <td>4.632568e-07</td>\n      <td>-9.536743e-07</td>\n    </tr>\n    <tr>\n      <th>119389</th>\n      <td>119389</td>\n      <td>-9.536743e-07</td>\n      <td>-9.536743e-06</td>\n      <td>-0.000043</td>\n      <td>-0.000114</td>\n      <td>-0.000200</td>\n      <td>-0.000240</td>\n      <td>-0.000200</td>\n      <td>-0.000114</td>\n      <td>-0.000043</td>\n      <td>...</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-0.000086</td>\n      <td>-0.000086</td>\n      <td>-0.000043</td>\n      <td>-0.000010</td>\n      <td>-0.000010</td>\n      <td>-9.536743e-06</td>\n      <td>-9.536743e-07</td>\n    </tr>\n  </tbody>\n</table>\n<p>60000 rows × 287 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n# Convert a list of lists to a NumPy array\nX_train = np.array(X_trainnew_1)\n# Assuming X_train is your training data\n# X_train should be a 2D NumPy array\n\n# Initialize an empty array to store the scaled data\nX_train_scaled = np.zeros_like(X_train)\n\n\n# Iterate through each row of X_train\nfor i in range(X_train.shape[0]):\n    row = X_train[i, :]  # Get the current row\n    min_val = np.min(row)  # Calculate the minimum value in the row\n    max_val = np.max(row)  # Calculate the maximum value in the row\n\n    # Avoid division by zero\n    if max_val != min_val:\n        scaled_row = (row - min_val) / (max_val - min_val)\n    else:\n        scaled_row = np.zeros_like(row)  # If max and min are the same, set all values to 0\n         # Debugging: Print scaled_row for each row\n#     print(f\"Scaled Row {i}: {scaled_row}\")\n\n    X_train_scaled[i, :] = scaled_row  # Store the scaled row in the result array\n\n# Now, X_train_scaled contains your normalized training data with each row scaled individually between 0 and 1\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T06:35:00.883213Z","iopub.execute_input":"2023-12-18T06:35:00.883563Z","iopub.status.idle":"2023-12-18T06:35:04.229279Z","shell.execute_reply.started":"2023-12-18T06:35:00.883533Z","shell.execute_reply":"2023-12-18T06:35:04.228381Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"print(X_train_scaled)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T06:35:21.138785Z","iopub.execute_input":"2023-12-18T06:35:21.139139Z","iopub.status.idle":"2023-12-18T06:35:21.145220Z","shell.execute_reply.started":"2023-12-18T06:35:21.139110Z","shell.execute_reply":"2023-12-18T06:35:21.144284Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"[[1.00000000e+00 1.48179916e-07 1.48716703e-07 ... 1.48716703e-07\n  1.49657039e-07 1.48179916e-07]\n [1.00000000e+00 3.54291744e-08 3.54420537e-08 ... 3.54740264e-08\n  3.55273143e-08 3.54291744e-08]\n [1.00000000e+00 1.81219193e-06 1.81660657e-06 ... 1.83340240e-06\n  1.82435849e-06 1.81219193e-06]\n ...\n [1.00000000e+00 7.22920778e-08 7.22724990e-08 ... 7.38187500e-08\n  7.40006619e-08 7.22844981e-08]\n [1.00000000e+00 9.54842787e-08 9.54258377e-08 ... 1.02234719e-07\n  9.54258377e-08 9.54842787e-08]\n [1.00000000e+00 7.32681615e-08 7.32223829e-08 ... 7.40669359e-08\n  7.39849405e-08 7.32763611e-08]]\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\n# Assuming X_train_scaled is your scaled dataset\n# Create an empty array for the formatted data\nX_train_formatted = np.empty_like(X_train_scaled, dtype=np.float64)\n\n# Iterate through each row and column of X_train_scaled\nfor i in range(X_train_scaled.shape[0]):\n    for j in range(X_train_scaled.shape[1]):\n        scaled_value = X_train_scaled[i, j]\n        formatted_value = \"{:.5f}\".format(scaled_value)\n        X_train_formatted[i, j] = float(formatted_value)\n\n# Now, X_train_formatted c","metadata":{"execution":{"iopub.status.busy":"2023-12-18T06:35:28.900939Z","iopub.execute_input":"2023-12-18T06:35:28.901993Z","iopub.status.idle":"2023-12-18T06:36:48.824123Z","shell.execute_reply.started":"2023-12-18T06:35:28.901958Z","shell.execute_reply":"2023-12-18T06:36:48.823268Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"print(X_train_formatted)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T06:36:58.991094Z","iopub.execute_input":"2023-12-18T06:36:58.991452Z","iopub.status.idle":"2023-12-18T06:36:58.997782Z","shell.execute_reply.started":"2023-12-18T06:36:58.991420Z","shell.execute_reply":"2023-12-18T06:36:58.996731Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"[[1. 0. 0. ... 0. 0. 0.]\n [1. 0. 0. ... 0. 0. 0.]\n [1. 0. 0. ... 0. 0. 0.]\n ...\n [1. 0. 0. ... 0. 0. 0.]\n [1. 0. 0. ... 0. 0. 0.]\n [1. 0. 0. ... 0. 0. 0.]]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Convert a list of lists to a NumPy array\nX_test = np.array(X_val_1)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T06:39:37.446353Z","iopub.execute_input":"2023-12-18T06:39:37.447322Z","iopub.status.idle":"2023-12-18T06:39:37.547199Z","shell.execute_reply.started":"2023-12-18T06:39:37.447289Z","shell.execute_reply":"2023-12-18T06:39:37.546430Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"X_test.shape\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T06:40:36.852208Z","iopub.execute_input":"2023-12-18T06:40:36.852557Z","iopub.status.idle":"2023-12-18T06:40:36.858386Z","shell.execute_reply.started":"2023-12-18T06:40:36.852528Z","shell.execute_reply":"2023-12-18T06:40:36.857490Z"},"trusted":true},"execution_count":84,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"(60000, 287)"},"metadata":{}}]},{"cell_type":"code","source":"X_test = X_test.astype(np.float64)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T06:40:39.459662Z","iopub.execute_input":"2023-12-18T06:40:39.459970Z","iopub.status.idle":"2023-12-18T06:40:39.512292Z","shell.execute_reply.started":"2023-12-18T06:40:39.459946Z","shell.execute_reply":"2023-12-18T06:40:39.511346Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"X_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-18T06:40:51.277863Z","iopub.execute_input":"2023-12-18T06:40:51.278217Z","iopub.status.idle":"2023-12-18T06:40:51.284414Z","shell.execute_reply.started":"2023-12-18T06:40:51.278191Z","shell.execute_reply":"2023-12-18T06:40:51.283428Z"},"trusted":true},"execution_count":87,"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"(60000, 287)"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\n\n# Assuming X_train is your training data (a 2D NumPy array)\n# and X_test is your test data (a 2D NumPy array)\n\n# Initialize an empty array for scaled test data\nX_test_scaled = np.zeros_like(X_test)\n\n# Iterate through each row of X_test\nfor i in range(X_test.shape[0]):\n    row = X_test[i, :]  # Get the current row\n    min_val = np.min(X_train[i, :])  # Calculate the minimum value in the corresponding training data row\n    max_val = np.max(X_train[i, :])  # Calculate the maximum value in the corresponding training data row\n\n    # Scale the row to have values between 0 and 1 using training data's min and max\n    if max_val != min_val:\n        scaled_row = (row - min_val) / (max_val - min_val)\n    else:\n        scaled_row = np.zeros_like(row)  # If max and min are the same, set all values to 0\n\n    X_test_scaled[i, :] = scaled_row  # Store the scaled row in the result array\n\n# Now, X_test_scaled contains your scaled test data with each row scaled using training data's min and max\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T06:40:55.586770Z","iopub.execute_input":"2023-12-18T06:40:55.587530Z","iopub.status.idle":"2023-12-18T06:40:57.048649Z","shell.execute_reply.started":"2023-12-18T06:40:55.587499Z","shell.execute_reply":"2023-12-18T06:40:57.047690Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"X_test_scaled","metadata":{"execution":{"iopub.status.busy":"2023-12-18T06:41:07.224292Z","iopub.execute_input":"2023-12-18T06:41:07.225140Z","iopub.status.idle":"2023-12-18T06:41:07.231571Z","shell.execute_reply.started":"2023-12-18T06:41:07.225110Z","shell.execute_reply":"2023-12-18T06:41:07.230666Z"},"trusted":true},"execution_count":89,"outputs":[{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"array([[5.62964810e+00, 1.48179916e-07, 1.48246535e-07, ...,\n        1.49657039e-07, 1.50127207e-07, 1.48179916e-07],\n       [3.85122051e-01, 3.54238456e-08, 3.54846840e-08, ...,\n        3.55379718e-08, 3.56978354e-08, 3.54238456e-08],\n       [2.04332965e+02, 1.81089995e-06, 1.80368669e-06, ...,\n        1.94063735e-06, 1.92384151e-06, 1.81348392e-06],\n       ...,\n       [5.33778282e-01, 5.65585156e-08, 5.65143506e-08, ...,\n        5.65143506e-08, 5.65143506e-08, 5.65585156e-08],\n       [2.09392236e+00, 8.86667800e-08, 8.87994255e-08, ...,\n        8.90317918e-08, 8.86832424e-08, 8.86667800e-08],\n       [1.25031673e+00, 2.51674396e-07, 2.51584509e-07, ...,\n        2.51584509e-07, 2.51584509e-07, 2.51674396e-07]])"},"metadata":{}}]},{"cell_type":"code","source":"X_train_formatted.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-18T06:41:13.172043Z","iopub.execute_input":"2023-12-18T06:41:13.172399Z","iopub.status.idle":"2023-12-18T06:41:13.178667Z","shell.execute_reply.started":"2023-12-18T06:41:13.172373Z","shell.execute_reply":"2023-12-18T06:41:13.177788Z"},"trusted":true},"execution_count":90,"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"(140000, 287)"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.decomposition import PCA\n\n# Assuming X_train_scaled is your scaled training data\n# You can use X_train_formatted if you've converted it to human-readable format X_train_formatted\n\n# Initialize the PCA model with the desired number of components\nn_components = 33  # Adjust this value as needed\npca = PCA(n_components=n_components)\n\n# Fit the PCA model to your scaled data\npca.fit(X_train_formatted)\n\n# Transform the data to its principal components\nX_train_pca = pca.transform(X_train_formatted)\n# Create a DataFrame for the PCA results using common columns\npca_df = pd.DataFrame(data=X_train_pca, columns=[f'PC{i}' for i in range(1, 34)])\n# Printing the PCA results\nprint(pca_df)\n\n# Now, X_train_pca contains your training data reduced to the specified number of principal components\n# You can use X_train","metadata":{"execution":{"iopub.status.busy":"2023-12-18T06:41:36.207651Z","iopub.execute_input":"2023-12-18T06:41:36.208332Z","iopub.status.idle":"2023-12-18T06:41:39.537426Z","shell.execute_reply.started":"2023-12-18T06:41:36.208288Z","shell.execute_reply":"2023-12-18T06:41:39.536237Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stdout","text":"             PC1           PC2           PC3           PC4           PC5  \\\n0      -0.000008  9.523237e-07 -2.790328e-08 -9.923074e-08 -1.745966e-07   \n1      -0.000008  9.523237e-07 -2.790328e-08 -9.923074e-08 -1.745966e-07   \n2      -0.000008  9.523237e-07 -2.790328e-08 -9.923074e-08 -1.745966e-07   \n3      -0.000008  9.523237e-07 -2.790328e-08 -9.923074e-08 -1.745966e-07   \n4      -0.000008  9.523237e-07 -2.790328e-08 -9.923074e-08 -1.745966e-07   \n...          ...           ...           ...           ...           ...   \n139995 -0.000008  9.523237e-07 -2.790328e-08 -9.923074e-08 -1.745966e-07   \n139996 -0.000008  9.523237e-07 -2.790328e-08 -9.923074e-08 -1.745966e-07   \n139997 -0.000008  9.523237e-07 -2.790328e-08 -9.923074e-08 -1.745966e-07   \n139998 -0.000008  9.523237e-07 -2.790328e-08 -9.923074e-08 -1.745966e-07   \n139999 -0.000008  9.523237e-07 -2.790328e-08 -9.923074e-08 -1.745966e-07   \n\n                 PC6           PC7           PC8           PC9          PC10  \\\n0       4.747518e-08 -9.824666e-09 -2.893451e-08 -2.134909e-08  2.604474e-08   \n1       4.747518e-08 -9.824666e-09 -2.893451e-08 -2.134909e-08  2.604474e-08   \n2       4.747518e-08 -9.824666e-09 -2.893451e-08 -2.134909e-08  2.604474e-08   \n3       4.747518e-08 -9.824666e-09 -2.893451e-08 -2.134909e-08  2.604474e-08   \n4       4.747518e-08 -9.824666e-09 -2.893451e-08 -2.134909e-08  2.604474e-08   \n...              ...           ...           ...           ...           ...   \n139995  4.747518e-08 -9.824666e-09 -2.893451e-08 -2.134909e-08  2.604474e-08   \n139996  4.747518e-08 -9.824666e-09 -2.893451e-08 -2.134909e-08  2.604474e-08   \n139997  4.747518e-08 -9.824666e-09 -2.893451e-08 -2.134909e-08  2.604474e-08   \n139998  4.747518e-08 -9.824666e-09 -2.893451e-08 -2.134909e-08  2.604474e-08   \n139999  4.747518e-08 -9.824666e-09 -2.893451e-08 -2.134909e-08  2.604474e-08   \n\n        ...          PC24          PC25          PC26          PC27  \\\n0       ...  2.975754e-08 -4.047355e-08  1.677134e-08  9.168278e-10   \n1       ...  2.975754e-08 -4.047355e-08  1.677134e-08  9.168278e-10   \n2       ...  2.975754e-08 -4.047355e-08  1.677134e-08  9.168278e-10   \n3       ...  2.975754e-08 -4.047355e-08  1.677134e-08  9.168278e-10   \n4       ...  2.975754e-08 -4.047355e-08  1.677134e-08  9.168278e-10   \n...     ...           ...           ...           ...           ...   \n139995  ...  2.975754e-08 -4.047355e-08  1.677134e-08  9.168278e-10   \n139996  ...  2.975754e-08 -4.047355e-08  1.677134e-08  9.168278e-10   \n139997  ...  2.975754e-08 -4.047355e-08  1.677134e-08  9.168278e-10   \n139998  ...  2.975754e-08 -4.047355e-08  1.677134e-08  9.168278e-10   \n139999  ...  2.975754e-08 -4.047355e-08  1.677134e-08  9.168278e-10   \n\n                PC28          PC29          PC30          PC31          PC32  \\\n0      -4.756329e-10 -7.565748e-09 -3.018927e-09  1.569510e-08 -7.441233e-09   \n1      -4.756329e-10 -7.565748e-09 -3.018927e-09  1.569510e-08 -7.441233e-09   \n2      -4.756329e-10 -7.565748e-09 -3.018927e-09  1.569510e-08 -7.441233e-09   \n3      -4.756329e-10 -7.565748e-09 -3.018927e-09  1.569510e-08 -7.441233e-09   \n4      -4.756329e-10 -7.565748e-09 -3.018927e-09  1.569510e-08 -7.441233e-09   \n...              ...           ...           ...           ...           ...   \n139995 -4.756329e-10 -7.565748e-09 -3.018927e-09  1.569510e-08 -7.441233e-09   \n139996 -4.756329e-10 -7.565748e-09 -3.018927e-09  1.569510e-08 -7.441233e-09   \n139997 -4.756329e-10 -7.565748e-09 -3.018927e-09  1.569510e-08 -7.441233e-09   \n139998 -4.756329e-10 -7.565748e-09 -3.018927e-09  1.569510e-08 -7.441233e-09   \n139999 -4.756329e-10 -7.565748e-09 -3.018927e-09  1.569510e-08 -7.441233e-09   \n\n                PC33  \n0       1.231992e-08  \n1       1.231992e-08  \n2       1.231992e-08  \n3       1.231992e-08  \n4       1.231992e-08  \n...              ...  \n139995  1.231992e-08  \n139996  1.231992e-08  \n139997  1.231992e-08  \n139998  1.231992e-08  \n139999  1.231992e-08  \n\n[140000 rows x 33 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"                   # pca of test data\nimport numpy as np\nfrom sklearn.decomposition import PCA\n\n# Assuming X_test_scaled is your scaled training data\n# You can use X_test_formatted if you've converted it to human-readable format X_test_formatted\n\n# Initialize the PCA model with the desired number of components\nn_components = 33  # Adjust this value as needed\npca = PCA(n_components=n_components)\n\n# Fit the PCA model to your scaled data\npca.fit(X_test_scaled)\n\n# Transform the data to its principal components\npca_df_test = pca.transform(X_test_scaled)\n# Create a DataFrame for the PCA results using common columns\npca_df_test = pd.DataFrame(pca_df_test, columns=[f'PC{i}' for i in range(1, 34)])\n# Printing the PCA results\nprint(pca_df_test)","metadata":{"execution":{"iopub.status.busy":"2023-12-18T06:42:03.269597Z","iopub.execute_input":"2023-12-18T06:42:03.269943Z","iopub.status.idle":"2023-12-18T06:42:04.982349Z","shell.execute_reply.started":"2023-12-18T06:42:03.269918Z","shell.execute_reply":"2023-12-18T06:42:04.978800Z"},"trusted":true},"execution_count":92,"outputs":[{"name":"stdout","text":"              PC1           PC2           PC3           PC4           PC5  \\\n0       -2.855412 -8.429165e-06  3.276845e-07  9.681002e-07  3.831353e-08   \n1       -8.099938 -7.474848e-06  6.038454e-07  5.913135e-07  1.584211e-07   \n2      195.847904 -8.473639e-05  2.141763e-05 -2.625276e-05 -1.511080e-05   \n3       -8.130596 -7.241614e-06  5.115289e-07  6.730889e-07  1.729805e-07   \n4       -7.675030 -1.246280e-07 -5.208269e-07  6.931755e-07  2.871604e-07   \n...           ...           ...           ...           ...           ...   \n59995   -7.686982 -5.037773e-06  7.795984e-08  6.227715e-07  1.851122e-07   \n59996   -8.156311 -6.937412e-06  4.952560e-07  5.911518e-07  1.666011e-07   \n59997   -7.951282 -7.169528e-06  7.179156e-07  5.608076e-07  2.468376e-07   \n59998   -6.391138 -7.522186e-06  4.275331e-07  7.434147e-07  1.727079e-07   \n59999   -7.234744 -4.293104e-06  2.393909e-07  4.975833e-07  7.657401e-07   \n\n                PC6           PC7           PC8           PC9          PC10  \\\n0     -9.791441e-08  9.327437e-08  8.002337e-08  2.607208e-07  7.011394e-08   \n1     -3.897372e-07  1.228994e-07  1.290864e-08  1.225904e-07  5.014442e-08   \n2      9.232851e-06 -4.621843e-06 -2.282069e-06  1.884293e-06 -2.152674e-06   \n3     -3.912870e-07  1.257037e-07  2.878268e-08  1.208264e-07  5.137514e-08   \n4      3.177434e-07  2.343971e-07 -1.578936e-07  2.934988e-07 -3.164824e-07   \n...             ...           ...           ...           ...           ...   \n59995 -5.045690e-07  1.447628e-07  2.495478e-08  3.803425e-08  3.404359e-08   \n59996 -4.245096e-07  1.245981e-07  1.928404e-08  9.945348e-08  4.462714e-08   \n59997 -3.433357e-07  8.001680e-08  1.207842e-08  4.080107e-08  6.349800e-08   \n59998 -3.699710e-07  1.244061e-07  3.282322e-08  1.373804e-07  6.156306e-08   \n59999 -1.669359e-07  1.614118e-07 -2.576301e-08 -6.190961e-08 -1.229982e-08   \n\n       ...          PC24          PC25          PC26          PC27  \\\n0      ... -5.986913e-08 -6.896756e-09  5.276147e-08 -9.158769e-10   \n1      ... -1.184967e-08  7.112428e-09 -5.096431e-09  8.929180e-09   \n2      ...  5.072539e-07  1.129817e-06  6.579649e-07  9.613231e-07   \n3      ... -1.505613e-08  5.556912e-09  3.115616e-09  1.466681e-09   \n4      ...  4.433375e-07  1.202193e-07 -1.187205e-07 -4.025576e-07   \n...    ...           ...           ...           ...           ...   \n59995  ... -1.173500e-08  3.822972e-09 -2.217782e-10 -1.794822e-09   \n59996  ... -1.039215e-08  7.249656e-09 -2.012894e-09  5.765615e-09   \n59997  ... -1.147938e-09 -9.079555e-08  2.598813e-08 -8.755976e-09   \n59998  ... -2.069451e-08  5.366482e-09  6.934737e-09 -1.505610e-09   \n59999  ... -4.929648e-08 -2.030957e-09 -1.536004e-08 -6.576405e-08   \n\n               PC28          PC29          PC30          PC31          PC32  \\\n0      3.452376e-08  6.292403e-08  9.899797e-09  1.363875e-07 -9.903881e-08   \n1      1.446626e-08  4.147278e-08 -3.134164e-08  1.760934e-08  1.900011e-09   \n2      9.075976e-08  1.443813e-07 -7.657604e-07 -3.136636e-07 -4.245255e-07   \n3      1.699795e-08  4.695810e-08 -2.442641e-08  4.079775e-08 -1.255049e-08   \n4     -1.085931e-07 -1.892484e-07 -2.618753e-07  2.712258e-07  1.561231e-07   \n...             ...           ...           ...           ...           ...   \n59995  1.695665e-08  5.541806e-08 -2.309969e-08  2.278516e-08 -1.618075e-09   \n59996  1.365915e-08  4.497028e-08 -2.860301e-08  2.444449e-08 -1.381364e-09   \n59997 -5.804776e-09 -6.748164e-08  3.074041e-08  4.337964e-08 -4.154846e-08   \n59998  1.983064e-08  4.748324e-08 -2.311502e-08  4.893193e-08 -1.087220e-08   \n59999  4.088604e-08  5.260187e-08 -3.770253e-08  2.513260e-08  4.316194e-08   \n\n               PC33  \n0      6.849721e-09  \n1     -2.680693e-08  \n2     -6.310920e-07  \n3     -2.609576e-08  \n4     -1.059647e-07  \n...             ...  \n59995 -2.105752e-08  \n59996 -3.354697e-08  \n59997 -2.956581e-08  \n59998 -2.218231e-08  \n59999  6.408240e-08  \n\n[60000 rows x 33 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Add the target_column to pca_df\npca_df['target'] = y_trainnew_1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(pca_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"                ##       K-MEAN\nimport pandas as pd\nimport cupy as cp  # Assuming you have CuPy installed\nfrom cuml.cluster import KMeans as cuKMeans  # Assuming you have cuML installed\n\n# Assuming you have your data in a DataFrame called df\n# Features used for clustering (adjust as needed)\n# features_for_clustering = ['feature1', 'feature2', 'feature3']\n\n# Number of clusters (adjust as needed)\nnum_clusters = 1000\n\n# Assuming you have a DataFrame called pca_df\n# Fit K-means model using cuML\nkmeans = cuKMeans(n_clusters=num_clusters, random_state=0, n_init=100)\npca_df['cluster_id'] = kmeans.fit_predict(cp.asarray(pca_df.drop('target', axis=1))).get()\n\n# Initialize a new DataFrame for the optimized data\nnew_df = pd.DataFrame()\n\n# Loop through each cluster\nfor cluster_id in range(num_clusters):\n    each_cluster = pca_df[pca_df['cluster_id'].values == cluster_id]\n    \n    # Check if the cluster is not empty\n    if not each_cluster.empty:\n        # Calculate the predominant class in the cluster\n        predominant_class = each_cluster['target'].value_counts().idxmax()\n        \n        # Filter records of the predominant class\n        each_cluster_filtered = each_cluster[each_cluster['target'] == predominant_class]\n        \n        # Calculate the average of the records in the cluster\n        averaged_record = each_cluster_filtered.mean(numeric_only=True)\n        \n        # Assign the predominant class to the averaged record\n        averaged_record['target'] = predominant_class\n        \n        # Append the averaged record to the new DataFrame\n        new_df = pd.concat([new_df, averaged_record.to_frame().transpose()], ignore_index=True)\n\n# Display the new DataFrame\n# print(new_df)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-18T06:57:31.772557Z","iopub.execute_input":"2023-12-18T06:57:31.773347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_df.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-18T06:57:15.197941Z","iopub.execute_input":"2023-12-18T06:57:15.198668Z","iopub.status.idle":"2023-12-18T06:57:15.204321Z","shell.execute_reply.started":"2023-12-18T06:57:15.198612Z","shell.execute_reply":"2023-12-18T06:57:15.203422Z"},"trusted":true},"execution_count":101,"outputs":[{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"(100, 35)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# C4.5 Decision Tree classifier","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.654358Z","iopub.status.idle":"2023-12-05T18:59:51.654688Z","shell.execute_reply.started":"2023-12-05T18:59:51.654527Z","shell.execute_reply":"2023-12-05T18:59:51.654543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n# from sklearn.model_selection import  GridSearchCV\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.655589Z","iopub.status.idle":"2023-12-05T18:59:51.655975Z","shell.execute_reply.started":"2023-12-05T18:59:51.655781Z","shell.execute_reply":"2023-12-05T18:59:51.655799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a C4.5 Decision Tree classifier\n# c45_classifier = DecisionTreeClassifier(criterion='entropy',splitter='best')","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.657281Z","iopub.status.idle":"2023-12-05T18:59:51.657647Z","shell.execute_reply.started":"2023-12-05T18:59:51.657476Z","shell.execute_reply":"2023-12-05T18:59:51.657493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.658743Z","iopub.status.idle":"2023-12-05T18:59:51.659102Z","shell.execute_reply.started":"2023-12-05T18:59:51.658907Z","shell.execute_reply":"2023-12-05T18:59:51.658929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a DecisionTreeClassifier\ndt_classifier = DecisionTreeClassifier()","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.660378Z","iopub.status.idle":"2023-12-05T18:59:51.660709Z","shell.execute_reply.started":"2023-12-05T18:59:51.660548Z","shell.execute_reply":"2023-12-05T18:59:51.660564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the classifier on the training data\ndt_classifier.fit(X_train, y_train)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.661777Z","iopub.status.idle":"2023-12-05T18:59:51.662141Z","shell.execute_reply.started":"2023-12-05T18:59:51.661953Z","shell.execute_reply":"2023-12-05T18:59:51.661969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make predictions on the test data\ny_pred = dt_classifier.predict(X_test_pca)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.663525Z","iopub.status.idle":"2023-12-05T18:59:51.663874Z","shell.execute_reply.started":"2023-12-05T18:59:51.663704Z","shell.execute_reply":"2023-12-05T18:59:51.663721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model\naccuracy = accuracy_score(y_true, y_pred)\nprint(f\"Accuracy: {accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.665261Z","iopub.status.idle":"2023-12-05T18:59:51.665608Z","shell.execute_reply.started":"2023-12-05T18:59:51.665437Z","shell.execute_reply":"2023-12-05T18:59:51.665454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# accuracy = accuracy_score(y_true, y_pred)\n# print(\"Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.666707Z","iopub.status.idle":"2023-12-05T18:59:51.667055Z","shell.execute_reply.started":"2023-12-05T18:59:51.666879Z","shell.execute_reply":"2023-12-05T18:59:51.666895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using Gini impurity\n# c45_classifier_gini = DecisionTreeClassifier(criterion='gini')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.668116Z","iopub.status.idle":"2023-12-05T18:59:51.668459Z","shell.execute_reply.started":"2023-12-05T18:59:51.668291Z","shell.execute_reply":"2023-12-05T18:59:51.668307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# c45_classifier_gini.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.669444Z","iopub.status.idle":"2023-12-05T18:59:51.669823Z","shell.execute_reply.started":"2023-12-05T18:59:51.669645Z","shell.execute_reply":"2023-12-05T18:59:51.669662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 4: Make predictions on the test data\n# y_pred = c45_classifier_gini.predict(X_test_pca)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.670913Z","iopub.status.idle":"2023-12-05T18:59:51.671270Z","shell.execute_reply.started":"2023-12-05T18:59:51.671102Z","shell.execute_reply":"2023-12-05T18:59:51.671123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Step 5: Evaluate the model\naccuracy = accuracy_score(y_true, y_pred)\nprint(\"Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-12-05T18:59:51.672290Z","iopub.status.idle":"2023-12-05T18:59:51.672634Z","shell.execute_reply.started":"2023-12-05T18:59:51.672469Z","shell.execute_reply":"2023-12-05T18:59:51.672485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}